{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facebook_ut.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdhCdS_3O3ah",
        "outputId": "86e6397a-73df-45e0-c07e-ac734cb045b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml==5.1\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mWHa0_yI2do0",
        "outputId": "b9f4b5f5-4a5a-42fb-e39f-2ba83265a08d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 35.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 71 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 81 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 143 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 153 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 163 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 174 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 184 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 194 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 204 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 225 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 235 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 245 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 256 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 274 kB 4.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=2f2f9647b118ff06d1c582b91c8d714d38d6ca7b5352769726407d7559486bc0\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1\n",
            "torch:  1.10 ; cuda:  cu111\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html\n",
            "Collecting detectron2\n",
            "  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/detectron2-0.6%2Bcu111-cp37-cp37m-linux_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Collecting black==21.4b2\n",
            "  Downloading black-21.4b2-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)\n",
            "Collecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 47.3 MB/s \n",
            "\u001b[?25hCollecting fvcore<0.1.6,>=0.1.5\n",
            "  Downloading fvcore-0.1.5.post20220212.tar.gz (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 9.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.4)\n",
            "Collecting yacs>=0.1.8\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.62.3)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.8.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)\n",
            "Collecting omegaconf>=2.1\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (7.1.2)\n",
            "Collecting toml>=0.10.1\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (3.10.0.2)\n",
            "Collecting pathspec<1,>=0.8.1\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (7.1.2)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 72.3 MB/s \n",
            "\u001b[?25hCollecting regex>=2020.1.8\n",
            "  Downloading regex-2022.1.18-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
            "\u001b[K     |████████████████████████████████| 748 kB 62.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.4.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.21.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (5.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (5.4.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 90.2 MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (3.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2) (1.15.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2) (3.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.35.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.43.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (4.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.2.0)\n",
            "Building wheels for collected packages: fvcore, antlr4-python3-runtime\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20220212-py3-none-any.whl size=61216 sha256=94119c04f58dda3b59586655aad2fbe191d42eaec0eb49638aa3400b36f909a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/43/75/238d2a5d897274799f92b8938f3cd807a3ccd3c8f37c0a4725\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=70c388bafbb8bd1e326149668b41a600e2182597be5df608b08fb407f6aab4ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built fvcore antlr4-python3-runtime\n",
            "Installing collected packages: portalocker, antlr4-python3-runtime, yacs, typed-ast, toml, regex, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, fvcore, black, detectron2\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "Successfully installed antlr4-python3-runtime-4.8 black-21.4b2 detectron2-0.6+cu111 fvcore-0.1.5.post20220212 hydra-core-1.1.1 iopath-0.1.9 mypy-extensions-0.4.3 omegaconf-2.1.1 pathspec-0.9.0 portalocker-2.4.0 regex-2022.1.18 toml-0.10.2 typed-ast-1.5.2 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git\n"
      ],
      "metadata": {
        "id": "zlzpyRthSMV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datapath = '/content/drive/MyDrive/PyPSA_Africa_images/datasets'\n",
        "\n",
        "import sys\n",
        "sys.argv = ['']"
      ],
      "metadata": {
        "id": "WvNVQVtqTklA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add pypsa africa tool\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/PyPSA_Africa_images/unbiased-teacher/')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/PyPSA_Africa_images/detect_energy/src/')"
      ],
      "metadata": {
        "id": "dv9TOSlUhnab"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import detectron2.utils.comm as comm\n",
        "from detectron2.checkpoint import DetectionCheckpointer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import default_argument_parser, default_setup, launch\n",
        "\n",
        "from ubteacher import add_ubteacher_config\n",
        "from ubteacher.engine.trainer import UBTeacherTrainer, BaselineTrainer\n",
        "\n",
        "# hacky way to register\n",
        "from ubteacher.modeling.meta_arch.rcnn import TwoStagePseudoLabGeneralizedRCNN\n",
        "from ubteacher.modeling.proposal_generator.rpn import PseudoLabRPN\n",
        "from ubteacher.modeling.roi_heads.roi_heads import StandardROIHeadsPseudoLab\n",
        "from ubteacher.modeling.meta_arch.rcnn import TwoStagePseudoLabGeneralizedRCNN\n",
        "import ubteacher.data.datasets.builtin\n",
        "\n",
        "from ubteacher.modeling.meta_arch.ts_ensemble import EnsembleTSModel\n",
        "\n",
        "# import some of our own methods\n",
        "from utils.detectron_utils import eval_predictor\n",
        "from utils.image_utils import get_true_images"
      ],
      "metadata": {
        "id": "fmGq_Ys-Z8-Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(args):\n",
        "    cfg = setup(args)\n",
        "\n",
        "    if cfg.SEMISUPNET.Trainer == \"ubteacher\":\n",
        "        Trainer = UBTeacherTrainer\n",
        "    elif cfg.SEMISUPNET.Trainer == \"baseline\":\n",
        "        Trainer = BaselineTrainer\n",
        "    else:\n",
        "        raise ValueError(\"Trainer Name is not found.\")\n",
        "\n",
        "    trainer = Trainer(cfg)    \n",
        "    trainer.train()\n",
        "    \n",
        "    return None"
      ],
      "metadata": {
        "id": "6AEeIRH8Nucq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2 import model_zoo\n",
        "\n",
        "def setup(args):\n",
        "\n",
        "    \"\"\"\n",
        "    Create configs and perform basic setups.\n",
        "    \"\"\"\n",
        "    cfg = get_cfg()\n",
        "    # print(cfg)\n",
        "    add_ubteacher_config(cfg)\n",
        "    # print(cfg)\n",
        "    cfg.merge_from_file(args.config_file)\n",
        "    cfg.merge_from_list(args.opts)\n",
        "    # cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml'))\n",
        "    cfg.freeze()\n",
        "    default_setup(cfg, args)\n",
        "    return cfg\n"
      ],
      "metadata": {
        "id": "Otixly6SNMPi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import logging\n",
        "import torch\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "from fvcore.nn.precise_bn import get_bn_modules\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "\n",
        "import detectron2.utils.comm as comm\n",
        "from detectron2.checkpoint import DetectionCheckpointer\n",
        "from detectron2.engine import DefaultTrainer, SimpleTrainer, TrainerBase\n",
        "from detectron2.engine.train_loop import AMPTrainer\n",
        "from detectron2.utils.events import EventStorage\n",
        "from detectron2.evaluation import COCOEvaluator, verify_results, PascalVOCDetectionEvaluator, DatasetEvaluators\n",
        "from detectron2.data.dataset_mapper import DatasetMapper\n",
        "from detectron2.engine import hooks\n",
        "from detectron2.structures.boxes import Boxes\n",
        "from detectron2.structures.instances import Instances\n",
        "from detectron2.utils.env import TORCH_VERSION\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2 import model_zoo\n",
        "\n",
        "from ubteacher.data.build import (\n",
        "    build_detection_semisup_train_loader,\n",
        "    build_detection_test_loader,\n",
        "    build_detection_semisup_train_loader_two_crops,\n",
        ")\n",
        "from ubteacher.data.dataset_mapper import DatasetMapperTwoCropSeparate\n",
        "from ubteacher.engine.hooks import LossEvalHook\n",
        "from ubteacher.modeling.meta_arch.ts_ensemble import EnsembleTSModel\n",
        "from ubteacher.checkpoint.detection_checkpoint import DetectionTSCheckpointer\n",
        "from ubteacher.solver.build import build_lr_scheduler"
      ],
      "metadata": {
        "id": "aK7Ub6lkh5sI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import logging\n",
        "import operator\n",
        "\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data.build import get_detection_dataset_dicts, build_batch_data_loader\n",
        "from detectron2.data.common import DatasetFromList, MapDataset\n",
        "from detectron2.data.samplers import TrainingSampler\n",
        "from detectron2.data.dataset_mapper import DatasetMapper\n",
        "from detectron2.utils.comm import get_world_size\n",
        "from detectron2.data.build import (\n",
        "    trivial_batch_collator,\n",
        "    worker_init_reset_seed,\n",
        "    get_detection_dataset_dicts,\n",
        "    build_batch_data_loader,\n",
        ")\n",
        "\n",
        "\n",
        "from ubteacher.data.build import divide_label_unlabel\n",
        "from ubteacher.data.common import (\n",
        "    AspectRatioGroupedSemiSupDatasetTwoCrop,\n",
        ")\n",
        "from ubteacher.modeling.meta_arch.ts_ensemble import EnsembleTSModel\n",
        "\n",
        "from itertools import product\n",
        "\n",
        "\n",
        "# batch data loader\n",
        "def build_semisup_batch_data_loader_two_crop(\n",
        "    dataset,\n",
        "    sampler,\n",
        "    total_batch_size_label,\n",
        "    total_batch_size_unlabel,\n",
        "    *,\n",
        "    aspect_ratio_grouping=False,\n",
        "    num_workers=0\n",
        "):\n",
        "    world_size = get_world_size()\n",
        "    assert (\n",
        "        total_batch_size_label > 0 and total_batch_size_label % world_size == 0\n",
        "    ), \"Total label batch size ({}) must be divisible by the number of gpus ({}).\".format(\n",
        "        total_batch_size_label, world_size\n",
        "    )\n",
        "\n",
        "    assert (\n",
        "        total_batch_size_unlabel > 0 and total_batch_size_unlabel % world_size == 0\n",
        "    ), \"Total unlabel batch size ({}) must be divisible by the number of gpus ({}).\".format(\n",
        "        total_batch_size_label, world_size\n",
        "    )\n",
        "\n",
        "    batch_size_label = total_batch_size_label // world_size\n",
        "    batch_size_unlabel = total_batch_size_unlabel // world_size\n",
        "\n",
        "    label_dataset, unlabel_dataset = dataset\n",
        "    label_sampler, unlabel_sampler = sampler\n",
        "\n",
        "    if aspect_ratio_grouping:\n",
        "        label_data_loader = torch.utils.data.DataLoader(\n",
        "            label_dataset,\n",
        "            sampler=label_sampler,\n",
        "            num_workers=num_workers,\n",
        "            batch_sampler=None,\n",
        "            collate_fn=operator.itemgetter(\n",
        "                0\n",
        "            ),  # don't batch, but yield individual elements\n",
        "            worker_init_fn=worker_init_reset_seed,\n",
        "        )  # yield individual mapped dict\n",
        "        unlabel_data_loader = torch.utils.data.DataLoader(\n",
        "            unlabel_dataset,\n",
        "            sampler=unlabel_sampler,\n",
        "            num_workers=num_workers,\n",
        "            batch_sampler=None,\n",
        "            collate_fn=operator.itemgetter(\n",
        "                0\n",
        "            ),  # don't batch, but yield individual elements\n",
        "            worker_init_fn=worker_init_reset_seed,\n",
        "        )  # yield individual mapped dict\n",
        "        return AspectRatioGroupedSemiSupDatasetTwoCrop(\n",
        "            (label_data_loader, unlabel_data_loader),\n",
        "            (batch_size_label, batch_size_unlabel),\n",
        "        )\n",
        "    else:\n",
        "        raise NotImplementedError(\"ASPECT_RATIO_GROUPING = False is not supported yet\")\n",
        "\n",
        "\n",
        "def build_maxar_loader_semisup_two_crops(cfg, mapper=None):\n",
        "    '''\n",
        "    Sets up loader for custom maxar data\n",
        "    '''\n",
        "\n",
        "    # register used datasets\n",
        "    ds_names = ['fake_maxar', 'maxar']\n",
        "    modes = ['train', 'val']\n",
        "\n",
        "    for name, mode in product(ds_names, modes):\n",
        "\n",
        "        ds_name = f'{name}_{mode}'\n",
        "        json_path = f'/content/drive/My Drive/PyPSA_Africa_images/datasets/{ds_name}/labels.json'\n",
        "        ds_path = f'/content/drive/My Drive/PyPSA_Africa_images/datasets/{ds_name}/data/' \n",
        "    \n",
        "        if ds_name in DatasetCatalog.list():\n",
        "            DatasetCatalog.remove(ds_name)\n",
        "            MetadataCatalog.remove(ds_name)\n",
        "    \n",
        "        register_coco_instances(ds_name, {}, json_path, ds_path)\n",
        "    \n",
        "    unlabel_dicts = get_detection_dataset_dicts(\n",
        "                            ['maxar_train', 'maxar_val'],\n",
        "                            filter_empty=False,\n",
        "                            min_keypoints=0,\n",
        "                            proposal_files=None\n",
        "                        )\n",
        "\n",
        "    label_dicts = get_detection_dataset_dicts(\n",
        "                            ['fake_maxar_train', 'fake_maxar_val'],\n",
        "                            filter_empty=False,\n",
        "                            min_keypoints=0,\n",
        "                            proposal_files=None\n",
        "                        )\n",
        " \n",
        "    # cfg.DATASETS.SUP_PERCENT = int(100 * len(label_dicts) / (len(label_dicts) + len(unlabel_dicts)))\n",
        "     \n",
        "    label_dataset = DatasetFromList(label_dicts, copy=False)\n",
        "    unlabel_dataset = DatasetFromList(unlabel_dicts, copy=False)\n",
        "\n",
        "    if mapper is None:\n",
        "        mapper = DatasetMapper(cfg, True)\n",
        "    label_dataset = MapDataset(label_dataset, mapper)\n",
        "    unlabel_dataset = MapDataset(unlabel_dataset, mapper)\n",
        "\n",
        "    sampler_name = cfg.DATALOADER.SAMPLER_TRAIN\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.info(\"Using training sampler {}\".format(sampler_name))\n",
        "    if sampler_name == \"TrainingSampler\":\n",
        "        label_sampler = TrainingSampler(len(label_dataset))\n",
        "        unlabel_sampler = TrainingSampler(len(unlabel_dataset))\n",
        "    elif sampler_name == \"RepeatFactorTrainingSampler\":\n",
        "        raise NotImplementedError(\"{} not yet supported.\".format(sampler_name))\n",
        "    else:\n",
        "        raise ValueError(\"Unknown training sampler: {}\".format(sampler_name))\n",
        "    return build_semisup_batch_data_loader_two_crop(\n",
        "        (label_dataset, unlabel_dataset),\n",
        "        (label_sampler, unlabel_sampler),\n",
        "        cfg.SOLVER.IMG_PER_BATCH_LABEL,\n",
        "        cfg.SOLVER.IMG_PER_BATCH_UNLABEL,\n",
        "        aspect_ratio_grouping=cfg.DATALOADER.ASPECT_RATIO_GROUPING,\n",
        "        num_workers=cfg.DATALOADER.NUM_WORKERS,\n",
        "    )\n",
        "\n",
        "# cfg.DATASETS.TRAIN = ['maxar_train', 'maxar_val']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DegpQw46zRuG"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import torchvision.transforms as transforms\n",
        "from ubteacher.data.transforms.augmentation_impl import GaussianBlur\n",
        "\n",
        "def build_strong_maxar_augmentation(cfg, is_train):\n",
        "\n",
        "    logger = logging.getLogger(__name__)\n",
        "    augmentation = []\n",
        "\n",
        "    if is_train:\n",
        "        # This is simialr to SimCLR https://arxiv.org/abs/2002.05709\n",
        "        augmentation.append(\n",
        "            transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8)\n",
        "        )\n",
        "        augmentation.append(transforms.RandomGrayscale(p=0.2))\n",
        "        augmentation.append(transforms.RandomApply([GaussianBlur([0.1, 2.0])], p=0.5))\n",
        "\n",
        "        other_transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.ToTensor(),\n",
        "                # transforms.RandomErasing(\n",
        "                #     p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=\"random\"\n",
        "                # ),\n",
        "                # transforms.RandomErasing(\n",
        "                #     p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=\"random\"\n",
        "                # ),\n",
        "                # transforms.RandomErasing(\n",
        "                #     p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=\"random\"\n",
        "                # ),\n",
        "                transforms.ToPILImage(),\n",
        "            ]\n",
        "        )\n",
        "        augmentation.append(other_transform)\n",
        "\n",
        "        logger.info(\"Augmentations used in training: \" + str(augmentation))\n",
        "    return transforms.Compose(augmentation)\n"
      ],
      "metadata": {
        "id": "7S0u1XCKvM2O"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.data.dataset_mapper import DatasetMapper\n",
        "import detectron2.data.detection_utils as utils\n",
        "\n",
        "from ubteacher.data.dataset_mapper import DatasetMapperTwoCropSeparate\n",
        "\n",
        "\n",
        "class MaxarDatasetMapper(DatasetMapperTwoCropSeparate):\n",
        "    def __init__(self, cfg, is_train=True):\n",
        "        self.augmentation = utils.build_augmentation(cfg, is_train)\n",
        "        self.compute_tight_boxes = False\n",
        "        self.strong_augmentation = build_strong_maxar_augmentation(cfg, is_train)\n",
        "\n",
        "        # fmt: off\n",
        "        self.img_format = cfg.INPUT.FORMAT\n",
        "        self.mask_on = cfg.MODEL.MASK_ON\n",
        "        self.mask_format = cfg.INPUT.MASK_FORMAT\n",
        "        self.keypoint_on = cfg.MODEL.KEYPOINT_ON\n",
        "        self.load_proposals = cfg.MODEL.LOAD_PROPOSALS\n",
        "        # fmt: on\n",
        "        if self.keypoint_on and is_train:\n",
        "            self.keypoint_hflip_indices = utils.create_keypoint_hflip_indices(\n",
        "                cfg.DATASETS.TRAIN\n",
        "            )\n",
        "        else:\n",
        "            self.keypoint_hflip_indices = None\n",
        "\n",
        "        if self.load_proposals:\n",
        "            self.proposal_min_box_size = cfg.MODEL.PROPOSAL_GENERATOR.MIN_SIZE\n",
        "            self.proposal_topk = (\n",
        "                cfg.DATASETS.PRECOMPUTED_PROPOSAL_TOPK_TRAIN\n",
        "                if is_train\n",
        "                else cfg.DATASETS.PRECOMPUTED_PROPOSAL_TOPK_TEST\n",
        "            )\n",
        "        self.is_train = is_train\n",
        "\n"
      ],
      "metadata": {
        "id": "S_y9SwGpQn3O"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.modeling.meta_arch.build import META_ARCH_REGISTRY\n",
        "from detectron2.modeling.meta_arch.rcnn import GeneralizedRCNN\n",
        "import pprint\n",
        "\n",
        "if 'MaxarPseudoLabGeneralizedRCNN' in META_ARCH_REGISTRY:\n",
        "    META_ARCH_REGISTRY.__dict__['_obj_map'].pop('MaxarPseudoLabGeneralizedRCNN')\n",
        "\n",
        "@META_ARCH_REGISTRY.register()\n",
        "class MaxarPseudoLabGeneralizedRCNN(GeneralizedRCNN):\n",
        "\n",
        "    def forward(\n",
        "        self, batched_inputs, branch=\"supervised\", given_proposals=None, val_mode=False\n",
        "    ):\n",
        "        if (not self.training) and (not val_mode) and (not branch=='unsup_data_weak'):\n",
        "            print('actually we are doing this')\n",
        "            return self.inference(batched_inputs)\n",
        "\n",
        "        # print('input received in the forward')\n",
        "        # pprint.pprint(batched_inputs)\n",
        "\n",
        "        images = self.preprocess_image(batched_inputs)\n",
        "\n",
        "        if \"instances\" in batched_inputs[0]:\n",
        "            gt_instances = [x[\"instances\"].to(self.device) for x in batched_inputs]\n",
        "        else:\n",
        "            gt_instances = None\n",
        "\n",
        "        features = self.backbone(images.tensor)\n",
        "\n",
        "        if branch == \"supervised\":\n",
        "            # Region proposal network\n",
        "            proposals_rpn, proposal_losses = self.proposal_generator(\n",
        "                images, features, gt_instances\n",
        "            )\n",
        "\n",
        "            # # roi_head lower branch\n",
        "            _, detector_losses = self.roi_heads(\n",
        "                images, features, proposals_rpn, gt_instances, branch=branch\n",
        "            )\n",
        "\n",
        "            losses = {}\n",
        "            losses.update(detector_losses)\n",
        "            losses.update(proposal_losses)\n",
        "            return losses, [], [], None\n",
        "\n",
        "        elif branch == \"unsup_data_weak\":\n",
        "\n",
        "            # Region proposal network\n",
        "            # print('type proposal generator')\n",
        "            # print(type(self.proposal_generator))\n",
        "            proposals_rpn, _ = self.proposal_generator(\n",
        "                images, features, None, compute_loss=False\n",
        "            )\n",
        "\n",
        "            # roi_head lower branch (keep this for further production)  \n",
        "            # notice that we do not use any target in ROI head to do inference !\n",
        "\n",
        "            # if self.roi_heads.training:\n",
        "            #    kwargs = {'targets': None, 'compute_loss': False, 'branch': branch} \n",
        "            # else:\n",
        "            #    kwargs = {'targets': None, 'branch': branch} \n",
        "\n",
        "            proposals_roih, ROI_predictions = self.roi_heads(\n",
        "                images,\n",
        "                features,\n",
        "                proposals_rpn,\n",
        "                targets=None,\n",
        "                compute_loss=False,\n",
        "                branch=branch,\n",
        "            )\n",
        "\n",
        "            # print('Here still all is good?')\n",
        "            return {}, proposals_rpn, proposals_roih, ROI_predictions\n",
        "\n",
        "        elif branch == \"val_loss\":\n",
        " \n",
        "            # Region proposal network\n",
        "            proposals_rpn, proposal_losses = self.proposal_generator(\n",
        "                images, features, gt_instances, compute_val_loss=True\n",
        "            )\n",
        "\n",
        "            # roi_head lower branch\n",
        "            _, detector_losses = self.roi_heads(\n",
        "                images,\n",
        "                features,\n",
        "                proposals_rpn,\n",
        "                gt_instances,\n",
        "                branch=branch,\n",
        "                compute_val_loss=True,\n",
        "            )\n",
        "\n",
        "            losses = {}\n",
        "            losses.update(detector_losses)\n",
        "            losses.update(proposal_losses)\n",
        "            return losses, [], [], None"
      ],
      "metadata": {
        "id": "sydVSMVD1LUu"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data import detection_utils as utils\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import softmax\n",
        "from scipy.special import expit\n",
        "plt.style.use('bmh')\n",
        "\n",
        "\n",
        "def show_data(datalist, metadata=MetadataCatalog.get('fake_maxar_val'), final_output=True):\n",
        "\n",
        "    if final_output:\n",
        "        try:\n",
        "            datalist = change_classes(datalist)\n",
        "        except KeyError:\n",
        "            pass\n",
        "    \n",
        "    for data in datalist:\n",
        "        img = data[\"image\"].permute(1, 2, 0).cpu().detach().numpy()\n",
        "        img = utils.convert_image_to_rgb(img, cfg.INPUT.FORMAT)        \n",
        "\n",
        "        visualizer = Visualizer(img, metadata=metadata, scale=0.6)\n",
        "\n",
        "        if 'instances' in data:\n",
        "            target_fields = data[\"instances\"].get_fields()\n",
        "\n",
        "            if 'proposal_boxes' in target_fields:\n",
        "\n",
        "                objectness = [expit(val.cpu()) for val in target_fields['objectness_logits']]\n",
        "\n",
        "                for prob, (i, box) in zip(objectness, enumerate(target_fields['proposal_boxes'].to('cpu'))):\n",
        "\n",
        "                    if prob < max(objectness):\n",
        "                        continue\n",
        "\n",
        "                    visualizer.draw_box(box)\n",
        "                    visualizer.draw_text(prob.item(), tuple(box[:2].numpy()))\n",
        "\n",
        "                cv2_imshow(visualizer.get_output().get_image()[:,:,::-1])\n",
        "                return\n",
        "\n",
        "            elif 'gt_classes' in target_fields:\n",
        "                labels = [metadata.thing_classes[i] for i in target_fields[\"gt_classes\"]]\n",
        "                visualizer = visualizer.overlay_instances(\n",
        "                    labels=labels,\n",
        "                    boxes=target_fields.get(\"gt_boxes\", None),\n",
        "                    masks=target_fields.get(\"gt_masks\", None),\n",
        "                    keypoints=target_fields.get(\"gt_keypoints\", None),\n",
        "                )\n",
        "            else:\n",
        "                visualizer = visualizer.draw_instance_predictions(data['instances'])\n",
        "\n",
        "            cv2_imshow(visualizer.get_image()[:,:,::-1])\n",
        "        \n",
        "        else:\n",
        "            cv2_imshow(visualizer.get_output().get_image()[:,:,::-1])\n",
        "\n",
        "\n",
        "def filter_instances(data):\n",
        "    '''\n",
        "    Removes all instances in data that are faulty.\n",
        "    E.g. have no extent\n",
        "\n",
        "    Args:\n",
        "        data(List[Dict]): each list entry is one image\n",
        "    '''\n",
        "\n",
        "    for i, datum in enumerate(data):\n",
        "        \n",
        "        try:\n",
        "            insts = datum['instances']\n",
        "        except KeyError:\n",
        "            continue\n",
        "\n",
        "        # filter instances that have area zero\n",
        "        t = insts.gt_boxes.tensor.cpu()\n",
        "        num = len(insts)\n",
        "        mask = (t[:,0] - t[:,2]) != torch.zeros(num)\n",
        "        mask *= (t[:,1] - t[:,3]) != torch.zeros(num)\n",
        "        insts = insts[mask]\n",
        "\n",
        "        datum['instances'] = insts\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "SJ0s8gfxUqbb"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ubteacher.modeling.meta_arch.rcnn import TwoStagePseudoLabGeneralizedRCNN\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.structures import BoxMode\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('bmh')\n",
        "import numpy as np\n",
        "\n",
        "def change_classes(data):\n",
        "    for i, datum in enumerate(data):\n",
        "        # print(datum['instances'])\n",
        "        classes = getattr(datum['instances'], 'gt_classes')\n",
        "        setattr(datum['instances'], 'gt_classes', torch.ones_like(classes, dtype=int))\n",
        "        data[i] = datum\n",
        "    \n",
        "    return data\n",
        "\n",
        "class MaxarUBTeacher(DefaultTrainer):\n",
        "    '''\n",
        "    Unbiased teacher adapted to the transfer of training performance from \n",
        "    duke to maxar images\n",
        "\n",
        "    This currently completely omits the BURN-IN stage and presumes it a \n",
        "    as already complete\n",
        "    '''\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        cfg = DefaultTrainer.auto_scale_workers(cfg, comm.get_world_size())\n",
        "\n",
        "        model = self.build_model(cfg)\n",
        "        self.model_teacher = self.build_model(cfg)\n",
        "\n",
        "        data_loader = self.build_train_loader(cfg)\n",
        "        optimizer = self.build_optimizer(cfg, model)\n",
        "\n",
        "        if comm.get_world_size() > 1:\n",
        "            model = DistributedDataParallel(\n",
        "                model, device_ids=[comm.get_local_rank()], broadcast_buffers=False\n",
        "            )\n",
        "\n",
        "        TrainerBase.__init__(self)\n",
        "        self._trainer = SimpleTrainer(model, data_loader, optimizer)\n",
        "\n",
        "        ensem_ts_model = EnsembleTSModel(self.model_teacher, model)\n",
        "\n",
        "        self.scheduler = self.build_lr_scheduler(cfg, optimizer)\n",
        "        self.checkpointer = DetectionCheckpointer(\n",
        "            ensem_ts_model,\n",
        "            cfg.OUTPUT_DIR,\n",
        "            optimizer=optimizer,\n",
        "            scheduler=self.scheduler,\n",
        "        )\n",
        "        self.start_iter = 0\n",
        "        self.max_iter = cfg.SOLVER.MAX_ITER\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.register_hooks(self.build_hooks())\n",
        "        print('setup ub teacher complete!')\n",
        "\n",
        "    # =====================================================\n",
        "    # ================== Pseduo-labeling ==================\n",
        "    # =====================================================\n",
        "\n",
        "    def threshold_bbox(self, proposal_bbox_inst, thres=0.7, proposal_type=\"roih\"):\n",
        "        if proposal_type == \"rpn\":\n",
        "            valid_map = proposal_bbox_inst.objectness_logits > thres\n",
        "\n",
        "            # create instances containing boxes and gt_classes\n",
        "            image_shape = proposal_bbox_inst.image_size\n",
        "            new_proposal_inst = Instances(image_shape)\n",
        "\n",
        "            # create box\n",
        "            new_bbox_loc = proposal_bbox_inst.proposal_boxes.tensor[valid_map, :]\n",
        "            new_boxes = Boxes(new_bbox_loc)\n",
        "\n",
        "            # add boxes to instances\n",
        "            new_proposal_inst.gt_boxes = new_boxes\n",
        "            new_proposal_inst.objectness_logits = proposal_bbox_inst.objectness_logits[\n",
        "                valid_map\n",
        "            ]\n",
        "        elif proposal_type == \"roih\":\n",
        "            valid_map = proposal_bbox_inst.scores > thres\n",
        "\n",
        "            # create instances containing boxes and gt_classes\n",
        "            image_shape = proposal_bbox_inst.image_size\n",
        "            new_proposal_inst = Instances(image_shape)\n",
        "\n",
        "            # create box\n",
        "            new_bbox_loc = proposal_bbox_inst.pred_boxes.tensor[valid_map, :]\n",
        "            new_boxes = Boxes(new_bbox_loc)\n",
        "\n",
        "            # add boxes to instances\n",
        "            new_proposal_inst.gt_boxes = new_boxes\n",
        "            new_proposal_inst.gt_classes = proposal_bbox_inst.pred_classes[valid_map]\n",
        "            new_proposal_inst.scores = proposal_bbox_inst.scores[valid_map]\n",
        "\n",
        "        return new_proposal_inst\n",
        "\n",
        "    def process_pseudo_label(\n",
        "        self, proposals_rpn_unsup_k, cur_threshold, proposal_type, psedo_label_method=\"\"\n",
        "    ):\n",
        "        list_instances = []\n",
        "        num_proposal_output = 0.0\n",
        "        for proposal_bbox_inst in proposals_rpn_unsup_k:\n",
        "            # thresholding\n",
        "            if psedo_label_method == \"thresholding\":\n",
        "                proposal_bbox_inst = self.threshold_bbox(\n",
        "                    proposal_bbox_inst, thres=cur_threshold, proposal_type=proposal_type\n",
        "                )\n",
        "            else:\n",
        "                raise ValueError(\"Unkown pseudo label boxes methods\")\n",
        "            num_proposal_output += len(proposal_bbox_inst)\n",
        "            list_instances.append(proposal_bbox_inst)\n",
        "        num_proposal_output = num_proposal_output / len(proposals_rpn_unsup_k)\n",
        "        return list_instances, num_proposal_output\n",
        "\n",
        "    def remove_label(self, label_data):\n",
        "        for label_datum in label_data:\n",
        "            if \"instances\" in label_datum.keys():\n",
        "                del label_datum[\"instances\"]\n",
        "        return label_data\n",
        "\n",
        "    def add_label(self, unlabled_data, label):\n",
        "        for unlabel_datum, lab_inst in zip(unlabled_data, label):\n",
        "            unlabel_datum[\"instances\"] = lab_inst\n",
        "        return unlabled_data\n",
        "\n",
        "    # =====================================================\n",
        "    # =================== Training Flow ===================\n",
        "    # =====================================================\n",
        "    \n",
        "    def train(self):\n",
        "        self.train_loop(self.start_iter, self.max_iter)\n",
        "        if hasattr(self, \"_last_eval_results\") and comm.is_main_process():\n",
        "            verify_results(self.cfg, self._last_eval_results)\n",
        "            return self._last_eval_results\n",
        "\n",
        "\n",
        "    def train_loop(self, start_iter: int, max_iter: int):\n",
        "        logger = logging.getLogger(__name__)\n",
        "        logger.info('Starting from iteration {}'.format(start_iter))\n",
        "\n",
        "        self.iter = self.start_iter = start_iter\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "        with EventStorage(start_iter) as self.storage:\n",
        "            try:\n",
        "                self.before_train()\n",
        "\n",
        "                for self.iter in range(start_iter, max_iter):\n",
        "\n",
        "                    self.before_step()\n",
        "                    self.run_step_full_semisup()\n",
        "                    self.after_step()\n",
        "\n",
        "            except Exception:\n",
        "                logger.exception(\"Exception during training:\")\n",
        "                raise\n",
        "            finally:\n",
        "                self.after_train()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _update_teacher_model(self, keep_rate=0.996):\n",
        "        if comm.get_world_size() > 1:\n",
        "            student_model_dict = {\n",
        "                key[7:]: value for key, value in self.model.state_dict().items()\n",
        "            }\n",
        "        else:\n",
        "            student_model_dict = self.model.state_dict()\n",
        "\n",
        "        new_teacher_dict = OrderedDict()\n",
        "        for key, value in self.model_teacher.state_dict().items():\n",
        "            if key in student_model_dict.keys():\n",
        "                new_teacher_dict[key] = (\n",
        "                    student_model_dict[key] *\n",
        "                    (1 - keep_rate) + value * keep_rate\n",
        "                )\n",
        "            else:\n",
        "                raise Exception(\"{} is not found in student model\".format(key))\n",
        "\n",
        "        self.model_teacher.load_state_dict(new_teacher_dict)\n",
        "\n",
        "    def _write_metrics(self, metrics_dict: dict):\n",
        "        metrics_dict = {\n",
        "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
        "            for k, v in metrics_dict.items()\n",
        "        }\n",
        "\n",
        "        # gather metrics among all workers for logging\n",
        "        # This assumes we do DDP-style training, which is currently the only\n",
        "        # supported method in detectron2.\n",
        "        all_metrics_dict = comm.gather(metrics_dict)\n",
        "        # all_hg_dict = comm.gather(hg_dict)\n",
        "\n",
        "        if comm.is_main_process():\n",
        "            if \"data_time\" in all_metrics_dict[0]:\n",
        "                # data_time among workers can have high variance. The actual latency\n",
        "                # caused by data_time is the maximum among workers.\n",
        "                data_time = np.max([x.pop(\"data_time\")\n",
        "                                   for x in all_metrics_dict])\n",
        "                self.storage.put_scalar(\"data_time\", data_time)\n",
        "\n",
        "            # average the rest metrics\n",
        "            metrics_dict = {\n",
        "                k: np.mean([x[k] for x in all_metrics_dict])\n",
        "                for k in all_metrics_dict[0].keys()\n",
        "            }\n",
        "\n",
        "            # append the list\n",
        "            loss_dict = {}\n",
        "            for key in metrics_dict.keys():\n",
        "                if key[:4] == \"loss\":\n",
        "                    loss_dict[key] = metrics_dict[key]\n",
        "\n",
        "            total_losses_reduced = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            self.storage.put_scalar(\"total_loss\", total_losses_reduced)\n",
        "            if len(metrics_dict) > 1:\n",
        "                self.storage.put_scalars(**metrics_dict)\n",
        "\n",
        "\n",
        "    def run_step_full_semisup(self):\n",
        "        self._trainer.iter = self.iter\n",
        "        assert self.model.training, 'self.model was changed to eval mode!'\n",
        "\n",
        "        start = time.perf_counter()\n",
        "        data = next(self._trainer._data_loader_iter)\n",
        "        label_data_q, label_data_k, unlabel_data_q, unlabel_data_k = data\n",
        "        data_time = time.perf_counter() - start\n",
        "        # print('unlabel_data_k')\n",
        "        # show_data(unlabel_data_k)\n",
        "\n",
        "        # remove unlabeled data labels\n",
        "        unlabel_data_q = self.remove_label(unlabel_data_q)\n",
        "        unlabel_data_k = self.remove_label(unlabel_data_k)\n",
        "\n",
        "\n",
        "        if self.iter % self.cfg.SEMISUPNET.TEACHER_UPDATE_ITER == 0:\n",
        "            self._update_teacher_model(keep_rate=self.cfg.SEMISUPNET.EMA_KEEP_RATE) \n",
        "\n",
        "        record_dict = {}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Get everything at pseudo-labelling\n",
        "        global student\n",
        "        global teacher \n",
        "        global loader \n",
        "        global checkpointer\n",
        "\n",
        "        student = self.model \n",
        "        teacher = self.model_teacher\n",
        "        loader = self._trainer._data_loader_iter\n",
        "        checkpointer = self.checkpointer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            try:\n",
        "                # print('what we are putting inside the fct')\n",
        "                # print(unlabel_data_k)\n",
        "                # print(type(unlabel_data_k))\n",
        "                (\n",
        "                _,\n",
        "                proposals_rpn_unsup_k,\n",
        "                proposals_roih_unsup_k,\n",
        "                _,\n",
        "                ) = self.model_teacher(unlabel_data_k, branch=\"unsup_data_weak\")\n",
        "            except FloatingPointError:\n",
        "                import pprint\n",
        "                print('unlabel data k')\n",
        "                pprint.pprint(unlabel_data_k)\n",
        "                dummy = jfoisndvoc\n",
        "\n",
        "\n",
        "\n",
        "        cur_threshold = self.cfg.SEMISUPNET.BBOX_THRESHOLD\n",
        "\n",
        "        joint_proposal_dict = {}\n",
        "        joint_proposal_dict['proposals_rpn'] = proposals_rpn_unsup_k\n",
        "\n",
        "        (\n",
        "            pesudo_proposals_rpn_unsup_k,\n",
        "            nun_pseudo_bbox_rpn,\n",
        "        ) = self.process_pseudo_label(\n",
        "            proposals_rpn_unsup_k, cur_threshold, \"rpn\", \"thresholding\"\n",
        "        )\n",
        "\n",
        "        joint_proposal_dict[\"proposals_pseudo_rpn\"] = pesudo_proposals_rpn_unsup_k\n",
        "        # Pseudo_labeling for ROI head (bbox location/objectness)\n",
        "        pesudo_proposals_roih_unsup_k, _ = self.process_pseudo_label(\n",
        "            proposals_roih_unsup_k, cur_threshold, \"roih\", \"thresholding\"\n",
        "        )\n",
        "        joint_proposal_dict[\"proposals_pseudo_roih\"] = pesudo_proposals_roih_unsup_k   \n",
        "\n",
        "\n",
        "        unlabel_data_q = self.add_label(\n",
        "            unlabel_data_q, joint_proposal_dict[\"proposals_pseudo_roih\"]\n",
        "        )\n",
        "        unlabel_data_k = self.add_label(\n",
        "            unlabel_data_k, joint_proposal_dict[\"proposals_pseudo_roih\"]\n",
        "        )\n",
        "\n",
        "        all_label_data = label_data_q + label_data_k\n",
        "        global all_unlabel_data\n",
        "        all_unlabel_data = unlabel_data_q\n",
        "\n",
        "        all_label_data = change_classes(all_label_data)\n",
        "        all_unlabel_data = change_classes(all_unlabel_data)\n",
        "\n",
        "        # import pprint\n",
        "        # print('for this it works')\n",
        "        # pprint.pprint(all_label_data)\n",
        "        # print('not so much here')\n",
        "        # pprint.pprint(all_unlabel_data)\n",
        "\n",
        "        all_unlabel_data = filter_instances(all_unlabel_data)\n",
        "        \n",
        "        try:\n",
        "            record_all_label_data, _, _, _ = self.model(all_label_data, branch='supervised')\n",
        "        except FloatingPointError:\n",
        "            import pprint\n",
        "            print('all label data')\n",
        "            pprint.pprint(all_label_data)\n",
        "\n",
        "            print('nancheck')\n",
        "            for data in all_label_data:\n",
        "                print(torch.isnan(data['image']).sum())\n",
        "\n",
        "            dummy = jfoisndvoc\n",
        "\n",
        "        record_dict.update(record_all_label_data)\n",
        "\n",
        "        record_all_unlabel_data, _, _, _ = self.model(\n",
        "            all_unlabel_data, branch=\"supervised\"\n",
        "        )\n",
        "        new_record_all_unlabel_data = {}\n",
        "        for key in record_all_unlabel_data.keys():\n",
        "            new_record_all_unlabel_data[key + \"_pseudo\"] = record_all_unlabel_data[\n",
        "                key\n",
        "            ]\n",
        "        record_dict.update(new_record_all_unlabel_data)\n",
        "\n",
        "        # print('--------- current state of progression ----------')\n",
        "        # print('final record dict before adjusting losses')\n",
        "        # print(record_dict)\n",
        "\n",
        "        # weight losses\n",
        "        loss_dict = {}\n",
        "        for key in record_dict.keys():\n",
        "            if key[:4] == \"loss\":\n",
        "                if key == \"loss_rpn_loc_pseudo\" or key == \"loss_box_reg_pseudo\":\n",
        "                    # pseudo bbox regression <- 0\n",
        "                    loss_dict[key] = record_dict[key] * 0\n",
        "                elif key[-6:] == \"pseudo\":  # unsupervised loss\n",
        "                    loss_dict[key] = (\n",
        "                        record_dict[key] *\n",
        "                        self.cfg.SEMISUPNET.UNSUP_LOSS_WEIGHT\n",
        "                    )\n",
        "                else:  # supervised loss\n",
        "                    loss_dict[key] = record_dict[key] * 1\n",
        "\n",
        "        losses = sum(loss_dict.values())\n",
        "\n",
        "        metrics_dict = record_dict\n",
        "        metrics_dict[\"data_time\"] = data_time\n",
        "        self._write_metrics(metrics_dict)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "\n",
        "        self.optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # print('step done')\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        mapper = MaxarDatasetMapper(cfg, True)\n",
        "        # return build_detection_semisup_train_loader(cfg, mapper=None)\n",
        "        return build_maxar_loader_semisup_two_crops(cfg, mapper)\n",
        "            \n",
        "\n"
      ],
      "metadata": {
        "id": "CwLAApxT01pl"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = default_argument_parser().parse_args()\n",
        "args.config_file = 'configs/coco_supervision/faster_rcnn_R_50_FPN_sup2_run1.yaml'\n",
        "cfg = setup(args)\n",
        "cfg.defrost()\n",
        "cfg.SEMISUPNET.Trainer = 'ubteacher'\n",
        "cfg.SOLVER.IMG_PER_BATCH_LABEL = 1\n",
        "cfg.SOLVER.IMG_PER_BATCH_UNLABEL = 1\n",
        "cfg.INPUT.FORMAT = 'RGB'\n",
        "cfg.DATALOADER.ASPECT_RATIO_GROUPING = True\n",
        "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = (256, 512, 640, 672, 704, 736, 768, 800)\n",
        "cfg.SEMISUPNET.BURN_UP_STEP = 0\n",
        "cfg.SOLVER.MAX_ITER = 1000\n",
        "cfg.SOLVER.STEPS = [100, 200]\n",
        "cfg.MODEL.META_ARCHITECTURE = 'MaxarPseudoLabGeneralizedRCNN'\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
        "model_path = os.path.join('/content', 'drive', 'MyDrive', 'PyPSA_Africa_images', 'models', \n",
        "                            '2021-11-29_frcnn_180000_dukeset', 'model_final.pth')\n",
        "\n",
        "cfg.MODEL.WEIGHTS = model_path\n",
        "\n",
        "cfg.MODEL.PROPOSAL_GENERATOR.RPN = 'PseudoLabRPN'\n",
        "cfg.MODEL.ROI_HEADS.NAME = 'MaxarROIHeads'\n",
        "cfg.freeze()\n",
        "\n",
        "trainer = MaxarUBTeacher(cfg)\n",
        "trainer.train()\n",
        "\n"
      ],
      "metadata": {
        "id": "SDGmWaZu0yJU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92e41570-24b0-4da1-ca78-1be74205b41a"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[02/20 16:58:11 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[02/20 16:58:11 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ----------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.7.12 (default, Jan 15 2022, 18:48:18) [GCC 7.5.0]\n",
            "numpy                   1.21.5\n",
            "detectron2              0.6 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
            "Compiler                GCC 7.3\n",
            "CUDA compiler           CUDA 11.1\n",
            "detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.10.0+cu111 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           Yes\n",
            "GPU 0                   Tesla P100-PCIE-16GB (arch=6.0)\n",
            "Driver version          460.32.03\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.1.2\n",
            "torchvision             0.11.1+cu111 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\n",
            "fvcore                  0.1.5.post20220212\n",
            "iopath                  0.1.9\n",
            "cv2                     4.1.2\n",
            "----------------------  ----------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.0.5\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
            "\n",
            "\u001b[32m[02/20 16:58:11 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='configs/coco_supervision/faster_rcnn_R_50_FPN_sup2_run1.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)\n",
            "\u001b[32m[02/20 16:58:11 detectron2]: \u001b[0mContents of args.config_file=configs/coco_supervision/faster_rcnn_R_50_FPN_sup2_run1.yaml:\n",
            "\u001b[38;5;197m_BASE_\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186m../Base-RCNN-FPN.yaml\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mTwoStagePseudoLabGeneralizedRCNN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mPseudoLabRPN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mCrossEntropy\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mStandardROIHeadsPseudoLab\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mFocalLoss\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mWarmupMultiStepLR\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m(179990, 179995)\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m180000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMG_PER_BATCH_LABEL\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMG_PER_BATCH_UNLABEL\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSUP_PERCENT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_DATA_SEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROSS_DATASET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m(\"coco_2017_train\",)\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m(\"coco_2017_val\",)\n",
            "\u001b[38;5;197mSEMISUPNET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTrainer\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mubteacher\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBBOX_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEACHER_UPDATE_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBURN_UP_STEP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEMA_KEEP_RATE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9996\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mUNSUP_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\n",
            "\u001b[32m[02/20 16:58:11 detectron2]: \u001b[0mRunning with full config:\n",
            "\u001b[38;5;197mCUDNN_BENCHMARK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mASPECT_RATIO_GROUPING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFILTER_EMPTY_ANNOTATIONS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNUM_WORKERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_DATA_SEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_DATA_SEED_PATH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mdataseed/COCO_supervision.txt\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREPEAT_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSAMPLER_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrainingSampler\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSUP_PERCENT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROSS_DATASET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_val\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN_LABEL\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id001\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN_UNLABEL\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id001\u001b[39m\n",
            "\u001b[38;5;197mEMAMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSUP_CONSIST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;197mGLOBAL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHACK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrelative_range\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mBGR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_FORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mpolygon\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m640\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m672\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m704\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m736\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m768\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mchoice\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_FLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mhorizontal\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mANCHOR_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANGLES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m-90\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m90\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mASPECT_RATIOS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDefaultAnchorGenerator\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOFFSET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBACKBONE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFREEZE_AT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbuild_resnet_fpn_backbone\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDEVICE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcuda\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFUSE_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msum\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOAD_PROPOSALS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTwoStagePseudoLabGeneralizedRCNN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPANOPTIC_FPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMBINE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mINSTANCES_CONFIDENCE_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mOVERLAP_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mSTUFF_AREA_LIMIT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4096\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m103.53\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m116.28\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m123.675\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mPseudoLabRPN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_MODULATED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_NUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_ON_PER_STAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFrozenBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES2_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES5_DILATION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTEM_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mWIDTH_PER_GROUP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRETINANET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id002\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_LOSS_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTOPK_CANDIDATES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_CASCADE_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOUS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFC_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1024\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFastRCNNConvFCHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTRAIN_ON_PRED_BOXES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFocalLoss\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardROIHeadsPseudoLab\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPROPOSAL_APPEND_GT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_KEYPOINT_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_KEYPOINTS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mKRCNNConvDeconvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m17\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_MASK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mMaskRCNNConvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id002\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOUNDARY_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mHEAD_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardRPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCrossEntropy\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUNSUP_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSEM_SEG_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIGNORE_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m255\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSemSegFPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m54\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mdetectron2://ImageNetPretrained/MSRA/R-50.pkl\n",
            "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./output\n",
            "\u001b[38;5;197mSEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;197mSEMISUPNET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBBOX_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBURN_UP_STEP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEMA_KEEP_RATE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9996\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOSS_WEIGHT_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mstandard\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMLP_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPSEUDO_BBOX_SAMPLE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mthresholding\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSUP_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEACHER_UPDATE_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTrainer\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mubteacher\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mUNSUP_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4.0\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAMP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBIAS_LR_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCHECKPOINT_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m5000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCLIP_GRADIENTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mvalue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFACTOR_LIST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mGAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMG_PER_BATCH_LABEL\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMG_PER_BATCH_UNLABEL\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mWarmupMultiStepLR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m180000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOMENTUM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNESTEROV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREFERENCE_WORLD_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m179990\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m179995\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_ITERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_METHOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mlinear\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_BIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mnull\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_NORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAUG\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m400\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m500\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m600\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m700\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m900\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1100\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDETECTIONS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVALUATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCOCOeval\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEXPECTED_RESULTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_OKS_SIGMAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mVAL_LOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;197mVERSION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;197mVIS_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\n",
            "\u001b[32m[02/20 16:58:11 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
            "\u001b[32m[02/20 16:58:12 d2.utils.env]: \u001b[0mUsing a generated random seed 12050112\n",
            "\u001b[32m[02/20 16:58:12 d2.engine.defaults]: \u001b[0mModel:\n",
            "MaxarPseudoLabGeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): PseudoLabRPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): MaxarROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[02/20 16:58:13 d2.engine.defaults]: \u001b[0mModel:\n",
            "MaxarPseudoLabGeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): PseudoLabRPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): MaxarROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/20 16:58:13 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[02/20 16:58:13 d2.data.datasets.coco]: \u001b[0mLoaded 762 images in COCO format from /content/drive/My Drive/PyPSA_Africa_images/datasets/maxar_train/labels.json\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/20 16:58:13 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[02/20 16:58:13 d2.data.datasets.coco]: \u001b[0mLoaded 190 images in COCO format from /content/drive/My Drive/PyPSA_Africa_images/datasets/maxar_val/labels.json\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/20 16:58:13 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[02/20 16:58:13 d2.data.datasets.coco]: \u001b[0mLoaded 11813 images in COCO format from /content/drive/My Drive/PyPSA_Africa_images/datasets/fake_maxar_train/labels.json\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/20 16:58:14 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[02/20 16:58:14 d2.data.datasets.coco]: \u001b[0mLoaded 4502 images in COCO format from /content/drive/My Drive/PyPSA_Africa_images/datasets/fake_maxar_val/labels.json\n",
            "\u001b[32m[02/20 16:58:14 d2.data.common]: \u001b[0mSerializing 16315 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[02/20 16:58:14 d2.data.common]: \u001b[0mSerialized dataset takes 6.29 MiB\n",
            "\u001b[32m[02/20 16:58:14 d2.data.common]: \u001b[0mSerializing 952 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[02/20 16:58:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.29 MiB\n",
            "setup ub teacher complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[02/20 16:58:22 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 19  total_loss: 21.48  loss_cls: 5.371  loss_box_reg: 0.7865  loss_rpn_cls: 1.303  loss_rpn_loc: 0.3951  loss_cls_pseudo: 2.596  loss_box_reg_pseudo: 0.5517  loss_rpn_cls_pseudo: 3.497  loss_rpn_loc_pseudo: 3.097  time: 0.3503  data_time: 0.0591  lr: 1.171e-05  max_mem: 4414M\n",
            "\u001b[32m[02/20 16:58:29 d2.utils.events]: \u001b[0m eta: 0:05:21  iter: 39  total_loss: 6.15  loss_cls: 0.2702  loss_box_reg: 0.1414  loss_rpn_cls: 0.3898  loss_rpn_loc: 0.08547  loss_cls_pseudo: 1.391  loss_box_reg_pseudo: 0.7446  loss_rpn_cls_pseudo: 0.5159  loss_rpn_loc_pseudo: 1.995  time: 0.3409  data_time: 0.0067  lr: 1.351e-05  max_mem: 4470M\n",
            "\u001b[32m[02/20 16:58:36 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 59  total_loss: 5.392  loss_cls: 0.1674  loss_box_reg: 0.149  loss_rpn_cls: 0.303  loss_rpn_loc: 0.06721  loss_cls_pseudo: 1.02  loss_box_reg_pseudo: 0.9709  loss_rpn_cls_pseudo: 0.4657  loss_rpn_loc_pseudo: 2.061  time: 0.3542  data_time: 0.0077  lr: 1.531e-05  max_mem: 4486M\n",
            "\u001b[32m[02/20 16:58:44 d2.utils.events]: \u001b[0m eta: 0:05:42  iter: 79  total_loss: 3.727  loss_cls: 0.2626  loss_box_reg: 0.09193  loss_rpn_cls: 0.2152  loss_rpn_loc: 0.02993  loss_cls_pseudo: 0.7843  loss_box_reg_pseudo: 0.3765  loss_rpn_cls_pseudo: 0.417  loss_rpn_loc_pseudo: 1.364  time: 0.3624  data_time: 0.0104  lr: 1.711e-05  max_mem: 4486M\n",
            "\u001b[32m[02/20 16:58:51 d2.utils.events]: \u001b[0m eta: 0:05:23  iter: 99  total_loss: 1.275  loss_cls: 0.08852  loss_box_reg: 0.05741  loss_rpn_cls: 0.1667  loss_rpn_loc: 0.02463  loss_cls_pseudo: 0.06768  loss_box_reg_pseudo: 0.03747  loss_rpn_cls_pseudo: 0.211  loss_rpn_loc_pseudo: 0.1277  time: 0.3559  data_time: 0.0066  lr: 1.891e-05  max_mem: 4486M\n",
            "\u001b[32m[02/20 16:58:57 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 119  total_loss: 0.4284  loss_cls: 0.05862  loss_box_reg: 0.04311  loss_rpn_cls: 0.1766  loss_rpn_loc: 0.05822  loss_cls_pseudo: 0.001433  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.03902  loss_rpn_loc_pseudo: 0  time: 0.3505  data_time: 0.0067  lr: 2.071e-05  max_mem: 4486M\n",
            "\u001b[32m[02/20 16:59:04 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 139  total_loss: 0.3049  loss_cls: 0.05948  loss_box_reg: 0.009523  loss_rpn_cls: 0.1332  loss_rpn_loc: 0.03014  loss_cls_pseudo: 0.0008377  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.01397  loss_rpn_loc_pseudo: 0  time: 0.3452  data_time: 0.0065  lr: 2.251e-05  max_mem: 4486M\n",
            "\u001b[32m[02/20 16:59:10 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 159  total_loss: 0.2715  loss_cls: 0.05258  loss_box_reg: 0.009584  loss_rpn_cls: 0.1319  loss_rpn_loc: 0.03667  loss_cls_pseudo: 0.0004574  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.009215  loss_rpn_loc_pseudo: 0  time: 0.3432  data_time: 0.0067  lr: 2.431e-05  max_mem: 4486M\n",
            "\u001b[32m[02/20 16:59:16 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 179  total_loss: 0.2069  loss_cls: 0.05496  loss_box_reg: 0.00497  loss_rpn_cls: 0.09984  loss_rpn_loc: 0.02818  loss_cls_pseudo: 0.001012  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.01126  loss_rpn_loc_pseudo: 0  time: 0.3399  data_time: 0.0064  lr: 2.611e-05  max_mem: 4486M\n",
            "\u001b[32m[02/20 16:59:23 d2.utils.events]: \u001b[0m eta: 0:04:29  iter: 199  total_loss: 0.2304  loss_cls: 0.03663  loss_box_reg: 0.004746  loss_rpn_cls: 0.1305  loss_rpn_loc: 0.03301  loss_cls_pseudo: 0.000644  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.003626  loss_rpn_loc_pseudo: 0  time: 0.3388  data_time: 0.0063  lr: 2.791e-05  max_mem: 4486M\n",
            "\u001b[32m[02/20 16:59:29 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 219  total_loss: 0.1754  loss_cls: 0.04273  loss_box_reg: 0.005247  loss_rpn_cls: 0.09157  loss_rpn_loc: 0.02072  loss_cls_pseudo: 0.0007336  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.006536  loss_rpn_loc_pseudo: 0  time: 0.3346  data_time: 0.0067  lr: 2.971e-05  max_mem: 4486M\n",
            "\u001b[32m[02/20 16:59:35 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 239  total_loss: 0.2232  loss_cls: 0.04232  loss_box_reg: 0.005153  loss_rpn_cls: 0.1168  loss_rpn_loc: 0.02412  loss_cls_pseudo: 0.0006157  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.004076  loss_rpn_loc_pseudo: 0  time: 0.3334  data_time: 0.0063  lr: 3.151e-05  max_mem: 4486M\n",
            "\u001b[32m[02/20 16:59:41 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 259  total_loss: 0.1799  loss_cls: 0.03331  loss_box_reg: 0.004138  loss_rpn_cls: 0.1058  loss_rpn_loc: 0.01935  loss_cls_pseudo: 0.0006283  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.009014  loss_rpn_loc_pseudo: 0  time: 0.3303  data_time: 0.0069  lr: 3.331e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 16:59:48 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 279  total_loss: 0.1883  loss_cls: 0.0345  loss_box_reg: 0.003369  loss_rpn_cls: 0.1031  loss_rpn_loc: 0.01803  loss_cls_pseudo: 0.0005856  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.01174  loss_rpn_loc_pseudo: 0  time: 0.3301  data_time: 0.0063  lr: 3.511e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 16:59:54 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 299  total_loss: 0.2691  loss_cls: 0.03975  loss_box_reg: 0.003835  loss_rpn_cls: 0.1712  loss_rpn_loc: 0.02483  loss_cls_pseudo: 0.001288  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.007842  loss_rpn_loc_pseudo: 0  time: 0.3300  data_time: 0.0068  lr: 3.691e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:00:00 d2.utils.events]: \u001b[0m eta: 0:03:44  iter: 319  total_loss: 0.1695  loss_cls: 0.03514  loss_box_reg: 0.005309  loss_rpn_cls: 0.0947  loss_rpn_loc: 0.01666  loss_cls_pseudo: 0.0004104  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.003904  loss_rpn_loc_pseudo: 0  time: 0.3284  data_time: 0.0065  lr: 3.871e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:00:07 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 339  total_loss: 0.2478  loss_cls: 0.05403  loss_box_reg: 0.006301  loss_rpn_cls: 0.1201  loss_rpn_loc: 0.02484  loss_cls_pseudo: 0.0006267  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.006406  loss_rpn_loc_pseudo: 0  time: 0.3275  data_time: 0.0069  lr: 4.051e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:00:13 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 359  total_loss: 0.2125  loss_cls: 0.05088  loss_box_reg: 0.00332  loss_rpn_cls: 0.112  loss_rpn_loc: 0.02326  loss_cls_pseudo: 0.001046  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.009246  loss_rpn_loc_pseudo: 0  time: 0.3268  data_time: 0.0064  lr: 4.231e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:00:19 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 379  total_loss: 0.2299  loss_cls: 0.04748  loss_box_reg: 0.007322  loss_rpn_cls: 0.143  loss_rpn_loc: 0.02938  loss_cls_pseudo: 0.0006699  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.005881  loss_rpn_loc_pseudo: 0  time: 0.3264  data_time: 0.0067  lr: 4.411e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:00:26 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 399  total_loss: 0.2179  loss_cls: 0.05371  loss_box_reg: 0.004383  loss_rpn_cls: 0.1076  loss_rpn_loc: 0.02223  loss_cls_pseudo: 9.459e-05  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.00765  loss_rpn_loc_pseudo: 0  time: 0.3265  data_time: 0.0067  lr: 4.591e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:00:32 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 419  total_loss: 0.1936  loss_cls: 0.03926  loss_box_reg: 0.00395  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.01799  loss_cls_pseudo: 0.000517  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.01089  loss_rpn_loc_pseudo: 0  time: 0.3257  data_time: 0.0067  lr: 4.771e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:00:39 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 439  total_loss: 0.2154  loss_cls: 0.04644  loss_box_reg: 0.007521  loss_rpn_cls: 0.1196  loss_rpn_loc: 0.02521  loss_cls_pseudo: 0.0008078  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.005682  loss_rpn_loc_pseudo: 0  time: 0.3261  data_time: 0.0062  lr: 4.951e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:00:45 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 459  total_loss: 0.3272  loss_cls: 0.06487  loss_box_reg: 0.01025  loss_rpn_cls: 0.1857  loss_rpn_loc: 0.03803  loss_cls_pseudo: 0.0007015  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.006477  loss_rpn_loc_pseudo: 0  time: 0.3257  data_time: 0.0063  lr: 5.131e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:00:52 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 479  total_loss: 0.167  loss_cls: 0.04449  loss_box_reg: 0.00606  loss_rpn_cls: 0.08501  loss_rpn_loc: 0.01711  loss_cls_pseudo: 0.0006144  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.005588  loss_rpn_loc_pseudo: 0  time: 0.3261  data_time: 0.0066  lr: 5.311e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:00:59 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 499  total_loss: 0.2171  loss_cls: 0.04392  loss_box_reg: 0.004834  loss_rpn_cls: 0.1248  loss_rpn_loc: 0.02203  loss_cls_pseudo: 0.00052  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.00364  loss_rpn_loc_pseudo: 0  time: 0.3262  data_time: 0.0065  lr: 5.491e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:01:05 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 519  total_loss: 0.1853  loss_cls: 0.04992  loss_box_reg: 0.005365  loss_rpn_cls: 0.09782  loss_rpn_loc: 0.01751  loss_cls_pseudo: 0.001946  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.006122  loss_rpn_loc_pseudo: 0  time: 0.3270  data_time: 0.0071  lr: 5.671e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:01:12 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 539  total_loss: 0.2148  loss_cls: 0.0416  loss_box_reg: 0.004257  loss_rpn_cls: 0.1244  loss_rpn_loc: 0.0219  loss_cls_pseudo: 0.0008497  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.006828  loss_rpn_loc_pseudo: 0  time: 0.3266  data_time: 0.0061  lr: 5.851e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:01:18 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 559  total_loss: 0.2044  loss_cls: 0.05566  loss_box_reg: 0.005935  loss_rpn_cls: 0.1006  loss_rpn_loc: 0.02481  loss_cls_pseudo: 8.424e-05  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.007387  loss_rpn_loc_pseudo: 0  time: 0.3262  data_time: 0.0067  lr: 6.031e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:01:25 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 579  total_loss: 0.2777  loss_cls: 0.05154  loss_box_reg: 0.005022  loss_rpn_cls: 0.146  loss_rpn_loc: 0.03839  loss_cls_pseudo: 0.001857  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.008909  loss_rpn_loc_pseudo: 0  time: 0.3264  data_time: 0.0065  lr: 6.211e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:01:31 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 599  total_loss: 0.1804  loss_cls: 0.03631  loss_box_reg: 0.006049  loss_rpn_cls: 0.09479  loss_rpn_loc: 0.02088  loss_cls_pseudo: 0.001089  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.003995  loss_rpn_loc_pseudo: 0  time: 0.3261  data_time: 0.0066  lr: 6.391e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:01:38 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 619  total_loss: 0.1798  loss_cls: 0.04894  loss_box_reg: 0.005391  loss_rpn_cls: 0.0916  loss_rpn_loc: 0.02045  loss_cls_pseudo: 0.0001652  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.003893  loss_rpn_loc_pseudo: 0  time: 0.3260  data_time: 0.0065  lr: 6.571e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:01:44 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 639  total_loss: 0.2111  loss_cls: 0.04485  loss_box_reg: 0.004573  loss_rpn_cls: 0.1028  loss_rpn_loc: 0.01775  loss_cls_pseudo: 0.0001564  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.003488  loss_rpn_loc_pseudo: 0  time: 0.3258  data_time: 0.0066  lr: 6.751e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:01:50 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 659  total_loss: 0.1937  loss_cls: 0.04793  loss_box_reg: 0.004217  loss_rpn_cls: 0.1082  loss_rpn_loc: 0.0221  loss_cls_pseudo: 0.0003908  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.009875  loss_rpn_loc_pseudo: 0  time: 0.3254  data_time: 0.0062  lr: 6.931e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:01:56 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 679  total_loss: 0.1538  loss_cls: 0.04628  loss_box_reg: 0.005452  loss_rpn_cls: 0.101  loss_rpn_loc: 0.01413  loss_cls_pseudo: 0.0007664  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.004297  loss_rpn_loc_pseudo: 0  time: 0.3249  data_time: 0.0070  lr: 7.111e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:02:03 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 699  total_loss: 0.2485  loss_cls: 0.056  loss_box_reg: 0.003917  loss_rpn_cls: 0.1298  loss_rpn_loc: 0.0214  loss_cls_pseudo: 4.899e-05  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.005146  loss_rpn_loc_pseudo: 0  time: 0.3250  data_time: 0.0063  lr: 7.291e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:02:09 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 719  total_loss: 0.3561  loss_cls: 0.05762  loss_box_reg: 0.0037  loss_rpn_cls: 0.1985  loss_rpn_loc: 0.05543  loss_cls_pseudo: 0.0002113  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.01392  loss_rpn_loc_pseudo: 0  time: 0.3248  data_time: 0.0067  lr: 7.471e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:02:16 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 739  total_loss: 0.2172  loss_cls: 0.06022  loss_box_reg: 0.002564  loss_rpn_cls: 0.09567  loss_rpn_loc: 0.02419  loss_cls_pseudo: 6.052e-05  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.006797  loss_rpn_loc_pseudo: 0  time: 0.3245  data_time: 0.0067  lr: 7.651e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:02:22 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 759  total_loss: 0.2294  loss_cls: 0.05106  loss_box_reg: 0.005473  loss_rpn_cls: 0.1532  loss_rpn_loc: 0.02437  loss_cls_pseudo: 0.0005784  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.002933  loss_rpn_loc_pseudo: 0  time: 0.3244  data_time: 0.0067  lr: 7.831e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:02:29 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 779  total_loss: 0.2222  loss_cls: 0.05369  loss_box_reg: 0.003256  loss_rpn_cls: 0.08588  loss_rpn_loc: 0.01296  loss_cls_pseudo: 3.419e-06  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.005965  loss_rpn_loc_pseudo: 0  time: 0.3246  data_time: 0.0065  lr: 8.011e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:02:35 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 799  total_loss: 0.2285  loss_cls: 0.07475  loss_box_reg: 0.00787  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.02178  loss_cls_pseudo: 0.0001816  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.01176  loss_rpn_loc_pseudo: 0  time: 0.3246  data_time: 0.0069  lr: 8.191e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:02:42 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 819  total_loss: 0.1649  loss_cls: 0.04901  loss_box_reg: 0.003825  loss_rpn_cls: 0.09328  loss_rpn_loc: 0.01506  loss_cls_pseudo: 0.0002797  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.005297  loss_rpn_loc_pseudo: 0  time: 0.3246  data_time: 0.0068  lr: 8.371e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:02:48 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 839  total_loss: 0.2042  loss_cls: 0.05948  loss_box_reg: 0.006409  loss_rpn_cls: 0.1141  loss_rpn_loc: 0.01672  loss_cls_pseudo: 0.0002968  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.00501  loss_rpn_loc_pseudo: 0  time: 0.3248  data_time: 0.0064  lr: 8.551e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:02:55 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 859  total_loss: 0.2707  loss_cls: 0.04188  loss_box_reg: 0.003334  loss_rpn_cls: 0.1584  loss_rpn_loc: 0.02459  loss_cls_pseudo: 0.0007639  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.003541  loss_rpn_loc_pseudo: 0  time: 0.3247  data_time: 0.0064  lr: 8.731e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:03:01 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 879  total_loss: 0.2081  loss_cls: 0.05112  loss_box_reg: 0.003591  loss_rpn_cls: 0.1068  loss_rpn_loc: 0.01205  loss_cls_pseudo: 0.000848  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.007516  loss_rpn_loc_pseudo: 0  time: 0.3248  data_time: 0.0063  lr: 8.911e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:03:08 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 899  total_loss: 0.2439  loss_cls: 0.06627  loss_box_reg: 0.009964  loss_rpn_cls: 0.1115  loss_rpn_loc: 0.01948  loss_cls_pseudo: 0.0004141  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.004143  loss_rpn_loc_pseudo: 0  time: 0.3249  data_time: 0.0067  lr: 9.091e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:03:14 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 919  total_loss: 0.2089  loss_cls: 0.04607  loss_box_reg: 0.003328  loss_rpn_cls: 0.1104  loss_rpn_loc: 0.01771  loss_cls_pseudo: 0.0007461  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.00673  loss_rpn_loc_pseudo: 0  time: 0.3247  data_time: 0.0065  lr: 9.271e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:03:21 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 939  total_loss: 0.191  loss_cls: 0.04175  loss_box_reg: 0.002759  loss_rpn_cls: 0.1074  loss_rpn_loc: 0.02569  loss_cls_pseudo: 0.001525  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.008508  loss_rpn_loc_pseudo: 0  time: 0.3244  data_time: 0.0066  lr: 9.451e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:03:27 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 959  total_loss: 0.1934  loss_cls: 0.04824  loss_box_reg: 0.004411  loss_rpn_cls: 0.09751  loss_rpn_loc: 0.02318  loss_cls_pseudo: 0.0003414  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.005244  loss_rpn_loc_pseudo: 0  time: 0.3245  data_time: 0.0062  lr: 9.631e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:03:33 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 979  total_loss: 0.2795  loss_cls: 0.06099  loss_box_reg: 0.005946  loss_rpn_cls: 0.132  loss_rpn_loc: 0.02449  loss_cls_pseudo: 0.000105  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.002404  loss_rpn_loc_pseudo: 0  time: 0.3242  data_time: 0.0064  lr: 9.811e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:03:40 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
            "\u001b[32m[02/20 17:03:41 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 0.2214  loss_cls: 0.06327  loss_box_reg: 0.007318  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.01871  loss_cls_pseudo: 0.0005904  loss_box_reg_pseudo: 0  loss_rpn_cls_pseudo: 0.00534  loss_rpn_loc_pseudo: 0  time: 0.3243  data_time: 0.0068  lr: 9.991e-05  max_mem: 4537M\n",
            "\u001b[32m[02/20 17:03:41 d2.engine.hooks]: \u001b[0mOverall training speed: 997 iterations in 0:05:23 (0.3247 s / it)\n",
            "\u001b[32m[02/20 17:03:41 d2.engine.hooks]: \u001b[0mTotal training time: 0:05:25 (0:00:01 on hooks)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-b1c19af84ac8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxarUBTeacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-109-2d7bcad5a2a4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_last_eval_results\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mverify_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_eval_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-109-2d7bcad5a2a4>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mafter_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbefore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/engine/hooks.py\u001b[0m in \u001b[0;36mafter_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;31m# This condition is to prevent the eval from running after a failed training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;31m# func is likely a closure that holds reference to the trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;31m# therefore we clean it to avoid circular reference in the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/engine/hooks.py\u001b[0m in \u001b[0;36m_do_eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mtest_and_save_results\u001b[0;34m()\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mtest_and_save_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_eval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_eval_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(cls, cfg, model, evaluators)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_test_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0;31m# When evaluators are passed in as arguments,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;31m# implicitly assume that evaluators can be created before data_loader.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mbuild_test_loader\u001b[0;34m(cls, cfg, dataset_name)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0mOverwrite\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0myou\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0md\u001b[0m \u001b[0mlike\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \"\"\"\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_detection_test_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/config/config.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_called_with_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                     \u001b[0mexplicit_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_args_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0morig_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mexplicit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/config/config.py\u001b[0m in \u001b[0;36m_get_args_from_config\u001b[0;34m(from_config_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msupported_arg_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0mextra_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_config_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;31m# forward the other arguments to __init__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/data/build.py\u001b[0m in \u001b[0;36m_test_loader_from_config\u001b[0;34m(cfg, dataset_name, mapper)\u001b[0m\n\u001b[1;32m    455\u001b[0m         ]\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOAD_PROPOSALS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     )\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmapper\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/data/build.py\u001b[0m in \u001b[0;36mget_detection_dataset_dicts\u001b[0;34m(names, filter_empty, min_keypoints, proposal_files, check_consistency)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0mdataset_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dataset '{}' is empty!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/data/build.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0mdataset_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dataset '{}' is empty!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/data/catalog.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 )\n\u001b[1;32m     57\u001b[0m             ) from e\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/data/datasets/coco.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;31m# 1. register a function which returns dicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m     \u001b[0mDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_coco_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;31m# 2. Optionally, add metadata about this dataset,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/data/datasets/coco.py\u001b[0m in \u001b[0;36mload_coco_json\u001b[0;34m(json_file, image_root, dataset_name, extra_annotation_keys)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mjson_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPathManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mredirect_stdout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mcoco_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading {} takes {:.2f} seconds.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pycocotools/coco.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loading annotations into memory...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                 \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'annotation file format {} not supported'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/coco/annotations/instances_val2017.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpointer.__dict__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHt10Z7QDCp2",
        "outputId": "96c9ddf3-0bc4-4359-d2ce-4cbf234deb63"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CfgNode({'LR_SCHEDULER_NAME': 'WarmupMultiStepLR', 'MAX_ITER': 1000, 'BASE_LR': 0.01, 'MOMENTUM': 0.9, 'NESTEROV': False, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_NORM': 0.0, 'GAMMA': 0.1, 'STEPS': (179990, 179995), 'WARMUP_FACTOR': 0.001, 'WARMUP_ITERS': 1000, 'WARMUP_METHOD': 'linear', 'CHECKPOINT_PERIOD': 5000, 'IMS_PER_BATCH': 16, 'REFERENCE_WORLD_SIZE': 0, 'BIAS_LR_FACTOR': 1.0, 'WEIGHT_DECAY_BIAS': None, 'CLIP_GRADIENTS': CfgNode({'ENABLED': False, 'CLIP_TYPE': 'value', 'CLIP_VALUE': 1.0, 'NORM_TYPE': 2.0}), 'AMP': CfgNode({'ENABLED': False}), 'IMG_PER_BATCH_LABEL': 1, 'IMG_PER_BATCH_UNLABEL': 1, 'FACTOR_LIST': (1,)})"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Our model methods"
      ],
      "metadata": {
        "id": "6fnRT022eY6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import helper\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2.data.build import build_batch_data_loader\n",
        "from detectron2.checkpoint import DetectionCheckpointer\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "def get_true_images(dir, num, show=False):\n",
        "    '''\n",
        "    loads a list of images that all have a tower in them. dir has to be a directory\n",
        "    only containing such images\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dir : str\n",
        "        directory of true examples\n",
        "    num : int\n",
        "        length of list returned\n",
        "    show : bool\n",
        "        if True, some of the examples are shown\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    imgs : list of 3 x height x width np.ndarray\n",
        "        list of obtained images\n",
        "    '''\n",
        "\n",
        "    imgs = os.listdir(dir) \n",
        "    imgs = [os.path.join(dir, img) for img in imgs]\n",
        "    # randomize order\n",
        "    np.random.shuffle(imgs)\n",
        "\n",
        "    imgs = [cv2.imread(img) for img in imgs[:num]]\n",
        "\n",
        "    if show:\n",
        "        print('here are 10 images we have obtained')\n",
        "        for img in imgs[:10]:\n",
        "            _, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
        "            ax.imshow(img)\n",
        "            plt.show()\n",
        "    \n",
        "    return imgs    \n",
        "\n",
        "\n",
        "def build_predictor_model(threshold=0.2, model_path=None):\n",
        "    '''\n",
        "    Returns predictor and model using detectron2 from files stored in the\n",
        "    PyPSA Africa drive\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    threshold : float\n",
        "        detection threshold\n",
        "    model_path : str\n",
        "        path to .pth file\n",
        "\n",
        "    Returns\n",
        "    ---------\n",
        "    predictor : detectron2.DefaultPredictor\n",
        "    model : torch.nn.Module\n",
        "\n",
        "    ''' \n",
        "\n",
        "    print('Building predictor from path:')\n",
        "    print(model_path)\n",
        "\n",
        "    ds_path = f'/content/drive/My Drive/PyPSA_Africa_images/datasets/duke_train/data/' \n",
        "    json_path = f'/content/drive/My Drive/PyPSA_Africa_images/datasets/duke_train/labels.json'\n",
        "    ds_name = 'duke'\n",
        "    \n",
        "    if ds_name in DatasetCatalog.list():\n",
        "        DatasetCatalog.remove(ds_name)\n",
        "        MetadataCatalog.remove(ds_name)\n",
        "    \n",
        "    register_coco_instances(ds_name, {}, json_path, ds_path)\n",
        "    \n",
        "    frcnn = 'faster_rcnn_R_101_FPN_3x.yaml'\n",
        "    \n",
        "    cfg = get_cfg() # Model Config\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/\"+frcnn))\n",
        "\n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
        "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold\n",
        "    if model_path is None:\n",
        "        model_path = os.path.join('/content', 'drive', 'MyDrive', 'PyPSA_Africa_images', 'models', \n",
        "                                    '2021-11-29_frcnn_180000_dukeset', 'model_final.pth')\n",
        "    \n",
        "    cfg.MODEL.WEIGHTS = model_path\n",
        "\n",
        "    print('working with path: ', model_path)\n",
        "    cfg.INPUT.FORMAT = 'BGR'\n",
        "\n",
        "    predictor = DefaultPredictor(cfg)                                \n",
        "    model = build_model(cfg)\n",
        "\n",
        "    print('standard frcnn cfg')\n",
        "    print(cfg)\n",
        "\n",
        "    global frcnn_cfg\n",
        "    frcnn_cfg = cfg\n",
        "\n",
        "    checkpointer = DetectionCheckpointer(model)\n",
        "    checkpointer.load(model_path)\n",
        "\n",
        "    # loader = build_batch_data_loader(cfg)\n",
        "\n",
        "    return predictor, model#, loader\n",
        "\n",
        "\n",
        "def eval_predictor(imgs, model_path=None, threshold=0.1):\n",
        "    '''\n",
        "    Method to check performance of model on some imgs (only chekc via plotting, does \n",
        "    not return precision scores)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    imgs : list of np.array \n",
        "        images on which inference will run\n",
        "    model_path : str\n",
        "        path to model .pth file\n",
        "    threshold : float\n",
        "        cutoff for what is considered as an instance\n",
        "    \n",
        "    Returns\n",
        "    ----------\n",
        "    -\n",
        "\n",
        "    '''\n",
        "\n",
        "    print('Evaluating model stored under:')\n",
        "    print(model_path)\n",
        "\n",
        "    predictor, model = build_predictor_model(threshold=threshold, model_path=model_path)\n",
        "    # model.eval()\n",
        "\n",
        "    for img in imgs:\n",
        "\n",
        "        out = predictor(img)\n",
        "        # out = predictor(img[:,:,::-1])\n",
        "        v = Visualizer(img, MetadataCatalog.get('duke'), scale=1.5)\n",
        "        out = v.draw_instance_predictions(out[\"instances\"].to(\"cpu\"))\n",
        "        cv2_imshow(out.get_image())\n",
        "\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            img = predictor.aug.get_transform(img).apply_image(img)\n",
        "            img = torch.as_tensor(img.astype('float32').transpose(2, 0, 1))\n",
        "            x = [{'image': img, 'width': 256, 'height': 256}]\n",
        "            pred = predictor.model(x)\n",
        "            print(pred)\n",
        "\n",
        "\n",
        "'''\n",
        "if __name__ == '__main__':\n",
        "    \n",
        "    duke_img_dir = '/content/drive/MyDrive/PyPSA_Africa_images/datasets/duke_val/data/'\n",
        "    duke_imgs = get_true_images(duke_img_dir, 20)\n",
        "    \n",
        "    model_path = '/content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth'\n",
        "    model_path_cycle = '/content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth'\n",
        "    \n",
        "    print('The cycle GAN trained model')\n",
        "    eval_predictor(duke_imgs, model_path=model_path_cycle)\n",
        "    \n",
        "    print('The regular trained model')\n",
        "    eval_predictor(duke_imgs, model_path=model_path)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "BMrJSXdQRLcM",
        "outputId": "1d2ee899-b09d-4e8d-ff66-e0ce8001f193"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nif __name__ == '__main__':\\n    \\n    duke_img_dir = '/content/drive/MyDrive/PyPSA_Africa_images/datasets/duke_val/data/'\\n    duke_imgs = get_true_images(duke_img_dir, 20)\\n    \\n    model_path = '/content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth'\\n    model_path_cycle = '/content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth'\\n    \\n    print('The cycle GAN trained model')\\n    eval_predictor(duke_imgs, model_path=model_path_cycle)\\n    \\n    print('The regular trained model')\\n    eval_predictor(duke_imgs, model_path=model_path)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor, model = build_predictor_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEYRMolPe0o4",
        "outputId": "49ea008d-836e-497c-c0dc-e17b87b1f91c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building predictor from path:\n",
            "None\n",
            "working with path:  /content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth\n",
            "\u001b[32m[02/20 15:10:30 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from /content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth ...\n",
            "standard frcnn cfg\n",
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('coco_2017_val',)\n",
            "  TRAIN: ('coco_2017_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 101\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 2\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.2\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: /content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.02\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 16\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 270000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n",
            "\u001b[32m[02/20 15:10:31 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from /content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lq, lk, uq, uk = next(loader)"
      ],
      "metadata": {
        "id": "1yyJXv-vgsmS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uk = trainer.remove_label(uk)"
      ],
      "metadata": {
        "id": "9FcrI2DXilrj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# _, prop_rpn, prop_roih, _ = teacher(uk, branch='unsup_data_weak')"
      ],
      "metadata": {
        "id": "dOGLUEElePR5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import detectron2\n",
        "\n",
        "with torch.no_grad():\n",
        "    out = uk\n",
        "\n",
        "    current = model \n",
        "    print(type(current))\n",
        "    model.eval()\n",
        "\n",
        "    images = current.preprocess_image(out)\n",
        "\n",
        "    if \"instances\" in uk[0]:\n",
        "        gt_instances = [x[\"instances\"].to(teacher.device) for x in uk]\n",
        "    else:\n",
        "        gt_instances = None\n",
        "\n",
        "    features = current.backbone(images.tensor)\n",
        "\n",
        "    branch = 'unsup_data_weak'\n",
        "\n",
        "    print(help(current.proposal_generator.forward))\n",
        "\n",
        "    if branch == 'unsup_data_weak':\n",
        "\n",
        "        # not using isistance as on type inherits the other\n",
        "        if type(current) == detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN:\n",
        "            print('detected d2.GeneralizedRCNN')\n",
        "            prop_rpn, _ = current.proposal_generator(images, features, None)\n",
        "            prop_roih, ROI_PRED = current.roi_heads(\n",
        "                images,\n",
        "                features,\n",
        "                prop_rpn,\n",
        "            )\n",
        "\n",
        "        elif type(current) == MaxarPseudoLabGeneralizedRCNN:  \n",
        "            print('detected MaxarGeneralizedRCNN')\n",
        "            prop_rpn, _ = current.proposal_generator(images, features, None, compute_loss=False)\n",
        "            prop_roih, ROI_PRED = current.roi_heads(\n",
        "                images,\n",
        "                features,\n",
        "                prop_rpn,\n",
        "                targets=None,\n",
        "                compute_loss=False,\n",
        "                branch=branch\n",
        "            )\n",
        "        else:\n",
        "            assert False, 'Unrecognized network type!'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # pprint.pprint(features)\n",
        "    print('results')\n",
        "    pprint.pprint(prop_roih[0])\n",
        "    print(type(prop_roih))\n",
        "    \n",
        " \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQEmKmyle7bJ",
        "outputId": "3fcefe9a-d685-438a-8196-26597fdb2634"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN'>\n",
            "Help on method forward in module detectron2.modeling.proposal_generator.rpn:\n",
            "\n",
            "forward(images: detectron2.structures.image_list.ImageList, features: Dict[str, torch.Tensor], gt_instances: Union[List[detectron2.structures.instances.Instances], NoneType] = None) method of detectron2.modeling.proposal_generator.rpn.RPN instance\n",
            "    Args:\n",
            "        images (ImageList): input images of length `N`\n",
            "        features (dict[str, Tensor]): input data as a mapping from feature\n",
            "            map name to tensor. Axis 0 represents the number of images `N` in\n",
            "            the input data; axes 1-3 are channels, height, and width, which may\n",
            "            vary between feature maps (e.g., if a feature pyramid is used).\n",
            "        gt_instances (list[Instances], optional): a length `N` list of `Instances`s.\n",
            "            Each `Instances` stores ground-truth instances for the corresponding image.\n",
            "    \n",
            "    Returns:\n",
            "        proposals: list[Instances]: contains fields \"proposal_boxes\", \"objectness_logits\"\n",
            "        loss: dict[Tensor] or None\n",
            "\n",
            "None\n",
            "detected d2.GeneralizedRCNN\n",
            "results\n",
            "Instances(num_instances=0, image_height=768, image_width=768, fields=[pred_boxes: Boxes(tensor([], device='cuda:0', size=(0, 4))), scores: tensor([], device='cuda:0'), pred_classes: tensor([], device='cuda:0', dtype=torch.int64)])\n",
            "<class 'list'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(student)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDiRThzWfYCP",
        "outputId": "39232c06-1f97-411e-9232-694a3a6f7cb4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ubteacher.modeling.meta_arch.rcnn.TwoStagePseudoLabGeneralizedRCNN"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqMlRJzXfZcO",
        "outputId": "4521b6e7-ad8c-4d05-f345-6b90667ce739"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (0.2.25)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax) (3.10.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from jax) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod = 'roi_heads'\n",
        "print(type(getattr(teacher, mod)))\n",
        "print(type(getattr(model, mod)))\n",
        "print(cfg.MODEL.WEIGHTS)\n",
        "print(frcnn_cfg.MODEL.WEIGHTS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY-WVClD5asD",
        "outputId": "e362eac9-f8f1-4804-f9e1-f7df0cb2d2d5"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'ubteacher.modeling.roi_heads.roi_heads.StandardROIHeadsPseudoLab'>\n",
            "<class 'detectron2.modeling.roi_heads.roi_heads.StandardROIHeads'>\n",
            "detectron2://ImageNetPretrained/MSRA/R-50.pkl\n",
            "/content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frcnn = 'faster_rcnn_R_101_FPN_3x.yaml'\n",
        "\n",
        "test_cfg = get_cfg() # Model Config\n",
        "test_cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/\"+frcnn))\n",
        "\n",
        "test_cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
        "model_path = os.path.join('/content', 'drive', 'MyDrive', 'PyPSA_Africa_images', 'models', \n",
        "                            '2021-11-29_frcnn_180000_dukeset', 'model_final.pth')\n",
        "\n",
        "test_cfg.MODEL.WEIGHTS = model_path\n",
        "\n",
        "test_cfg.MODEL.META_ARCHITECTURE = 'MaxarPseudoLabGeneralizedRCNN'\n",
        "test_cfg.MODEL.PROPOSAL_GENERATOR.RPN = 'PseudoLabRPN'\n",
        "test_cfg.MODEL.ROI_HEADS.NAME = 'MaxarROIHeads'\n",
        "\n",
        "test_model = build_model(test_cfg)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IMaBxW3B9U8h"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "from detectron2.structures import Boxes, ImageList, Instances, pairwise_iou\n",
        "from detectron2.modeling.proposal_generator.proposal_utils import (\n",
        "    add_ground_truth_to_proposals,\n",
        ")\n",
        "from detectron2.utils.events import get_event_storage\n",
        "from detectron2.modeling.roi_heads.box_head import build_box_head\n",
        "from detectron2.layers import ShapeSpec\n",
        "from detectron2.modeling.roi_heads import (\n",
        "    ROI_HEADS_REGISTRY,\n",
        "    StandardROIHeads,\n",
        ")\n",
        "from detectron2.modeling.roi_heads.fast_rcnn import FastRCNNOutputLayers\n",
        "\n",
        "import numpy as np\n",
        "from detectron2.modeling.poolers import ROIPooler\n",
        "\n",
        "if 'MaxarROIHeads' in ROI_HEADS_REGISTRY:\n",
        "    ROI_HEADS_REGISTRY.__dict__['_obj_map'].pop('MaxarROIHeads')\n",
        "\n",
        "@ROI_HEADS_REGISTRY.register()\n",
        "class MaxarROIHeads(StandardROIHeads):\n",
        "    @classmethod\n",
        "    def _init_box_head(cls, cfg, input_shape):\n",
        "        # fmt: off\n",
        "        in_features       = cfg.MODEL.ROI_HEADS.IN_FEATURES\n",
        "        pooler_resolution = cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION\n",
        "        pooler_scales     = tuple(1.0 / input_shape[k].stride for k in in_features)\n",
        "        sampling_ratio    = cfg.MODEL.ROI_BOX_HEAD.POOLER_SAMPLING_RATIO\n",
        "        pooler_type       = cfg.MODEL.ROI_BOX_HEAD.POOLER_TYPE\n",
        "        # fmt: on\n",
        "\n",
        "        in_channels = [input_shape[f].channels for f in in_features]\n",
        "        # Check all channel counts are equal\n",
        "        assert len(set(in_channels)) == 1, in_channels\n",
        "        in_channels = in_channels[0]\n",
        "\n",
        "        box_pooler = ROIPooler(\n",
        "            output_size=pooler_resolution,\n",
        "            scales=pooler_scales,\n",
        "            sampling_ratio=sampling_ratio,\n",
        "            pooler_type=pooler_type,\n",
        "        )\n",
        "        box_head = build_box_head(\n",
        "            cfg,\n",
        "            ShapeSpec(\n",
        "                channels=in_channels, height=pooler_resolution, width=pooler_resolution\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        box_predictor = FastRCNNOutputLayers(cfg, box_head.output_shape)    \n",
        "        return {\n",
        "            \"box_in_features\": in_features,\n",
        "            \"box_pooler\": box_pooler,\n",
        "            \"box_head\": box_head,\n",
        "            \"box_predictor\": box_predictor,\n",
        "        }\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        images: ImageList,\n",
        "        features: Dict[str, torch.Tensor],\n",
        "        proposals: List[Instances],\n",
        "        targets: Optional[List[Instances]] = None,\n",
        "        compute_loss=True,\n",
        "        branch=\"\",\n",
        "        compute_val_loss=False,\n",
        "    ) -> Tuple[List[Instances], Dict[str, torch.Tensor]]:\n",
        "\n",
        "        del images\n",
        "        if self.training and compute_loss:  # apply if training loss\n",
        "            assert targets\n",
        "            # 1000 --> 512\n",
        "            proposals = self.label_and_sample_proposals(\n",
        "                proposals, targets, branch=branch\n",
        "            )\n",
        "        elif compute_val_loss:  # apply if val loss\n",
        "            assert targets\n",
        "            # 1000 --> 512\n",
        "            temp_proposal_append_gt = self.proposal_append_gt\n",
        "            self.proposal_append_gt = False\n",
        "            proposals = self.label_and_sample_proposals(\n",
        "                proposals, targets, branch=branch\n",
        "            )  # do not apply target on proposals\n",
        "            self.proposal_append_gt = temp_proposal_append_gt\n",
        "        del targets\n",
        "\n",
        "        if (self.training and compute_loss) or compute_val_loss:\n",
        "            losses, _ = self._forward_box(\n",
        "                features, proposals, compute_loss, compute_val_loss, branch\n",
        "            )\n",
        "            return proposals, losses\n",
        "        else:\n",
        "            pred_instances, predictions = self._forward_box(\n",
        "                features, proposals, compute_loss, compute_val_loss, branch\n",
        "            )\n",
        "\n",
        "            return pred_instances, predictions\n",
        "\n",
        "\n",
        "    def _forward_box(\n",
        "        self,\n",
        "        features: Dict[str, torch.Tensor],\n",
        "        proposals: List[Instances],\n",
        "        compute_loss: bool = True,\n",
        "        compute_val_loss: bool = False,\n",
        "        branch: str = \"\",\n",
        "    ) -> Union[Dict[str, torch.Tensor], List[Instances]]:\n",
        "        features = [features[f] for f in self.box_in_features]\n",
        "        box_features = self.box_pooler(features, [x.proposal_boxes for x in proposals])\n",
        "        box_features = self.box_head(box_features)\n",
        "        predictions = self.box_predictor(box_features)\n",
        "        del box_features\n",
        "\n",
        "        if (\n",
        "            self.training and compute_loss\n",
        "        ) or compute_val_loss:  # apply if training loss or val loss\n",
        "            losses = self.box_predictor.losses(predictions, proposals)\n",
        "\n",
        "            if self.train_on_pred_boxes:\n",
        "                with torch.no_grad():\n",
        "                    pred_boxes = self.box_predictor.predict_boxes_for_gt_classes(\n",
        "                        predictions, proposals\n",
        "                    )\n",
        "                    for proposals_per_image, pred_boxes_per_image in zip(\n",
        "                        proposals, pred_boxes\n",
        "                    ):\n",
        "                        proposals_per_image.proposal_boxes = Boxes(pred_boxes_per_image)\n",
        "            return losses, predictions\n",
        "        else:\n",
        "\n",
        "            pred_instances, _ = self.box_predictor.inference(predictions, proposals)\n",
        "            return pred_instances, predictions\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def label_and_sample_proposals(\n",
        "        self, proposals: List[Instances], targets: List[Instances], branch: str = \"\"\n",
        "    ) -> List[Instances]:\n",
        "        gt_boxes = [x.gt_boxes for x in targets]\n",
        "        if self.proposal_append_gt:\n",
        "            proposals = add_ground_truth_to_proposals(gt_boxes, proposals)\n",
        "\n",
        "        proposals_with_gt = []\n",
        "\n",
        "        num_fg_samples = []\n",
        "        num_bg_samples = []\n",
        "        for proposals_per_image, targets_per_image in zip(proposals, targets):\n",
        "            has_gt = len(targets_per_image) > 0\n",
        "            match_quality_matrix = pairwise_iou(\n",
        "                targets_per_image.gt_boxes, proposals_per_image.proposal_boxes\n",
        "            )\n",
        "            matched_idxs, matched_labels = self.proposal_matcher(match_quality_matrix)\n",
        "            sampled_idxs, gt_classes = self._sample_proposals(\n",
        "                matched_idxs, matched_labels, targets_per_image.gt_classes\n",
        "            )\n",
        "\n",
        "            proposals_per_image = proposals_per_image[sampled_idxs]\n",
        "            proposals_per_image.gt_classes = gt_classes\n",
        "\n",
        "            if has_gt:\n",
        "                sampled_targets = matched_idxs[sampled_idxs]\n",
        "                for (trg_name, trg_value) in targets_per_image.get_fields().items():\n",
        "                    if trg_name.startswith(\"gt_\") and not proposals_per_image.has(\n",
        "                        trg_name\n",
        "                    ):\n",
        "                        proposals_per_image.set(trg_name, trg_value[sampled_targets])\n",
        "            else:\n",
        "                gt_boxes = Boxes(\n",
        "                    targets_per_image.gt_boxes.tensor.new_zeros((len(sampled_idxs), 4))\n",
        "                )\n",
        "                proposals_per_image.gt_boxes = gt_boxes\n",
        "\n",
        "            num_bg_samples.append((gt_classes == self.num_classes).sum().item())\n",
        "            num_fg_samples.append(gt_classes.numel() - num_bg_samples[-1])\n",
        "            proposals_with_gt.append(proposals_per_image)\n",
        "\n",
        "        storage = get_event_storage()\n",
        "        storage.put_scalar(\n",
        "            \"roi_head/num_target_fg_samples_\" + branch, np.mean(num_fg_samples)\n",
        "        )\n",
        "        storage.put_scalar(\n",
        "            \"roi_head/num_target_bg_samples_\" + branch, np.mean(num_bg_samples)\n",
        "        )\n",
        "\n",
        "        return proposals_with_gt"
      ],
      "metadata": {
        "id": "KpCL0muRrwB4"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KnBRSw4d-a6i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}