{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facebook_ut.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdhCdS_3O3ah",
        "outputId": "6cf9ce71-d351-4ff1-a80b-bebca07e6a76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml==5.1\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mWHa0_yI2do0",
        "outputId": "d6da42a0-6224-4b68-e244-e566ea579f57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 29.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 34.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 71 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 81 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 102 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 112 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 122 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 143 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 153 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 163 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 174 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 184 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 194 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 204 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 225 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 235 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 245 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 256 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 274 kB 9.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=574f1d5dd1892d3ee6f638b35e1ab1de059c99529915524818e1266cc5174952\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1\n",
            "torch:  1.10 ; cuda:  cu111\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html\n",
            "Collecting detectron2\n",
            "  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/detectron2-0.6%2Bcu111-cp37-cp37m-linux_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.62.3)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.8.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)\n",
            "Collecting black==21.4b2\n",
            "  Downloading black-21.4b2-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)\n",
            "Collecting fvcore<0.1.6,>=0.1.5\n",
            "  Downloading fvcore-0.1.5.post20220212.tar.gz (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.4)\n",
            "Collecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 53.2 MB/s \n",
            "\u001b[?25hCollecting omegaconf>=2.1\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting yacs>=0.1.8\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting iopath<0.1.10,>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (7.1.2)\n",
            "Collecting pathspec<1,>=0.8.1\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 60.8 MB/s \n",
            "\u001b[?25hCollecting regex>=2020.1.8\n",
            "  Downloading regex-2022.1.18-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
            "\u001b[K     |████████████████████████████████| 748 kB 63.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (3.10.0.2)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting toml>=0.10.1\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.4.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.21.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (5.1)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 80.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (5.4.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2) (1.15.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2) (3.7.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.43.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.3.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.17.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (4.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.2.0)\n",
            "Building wheels for collected packages: fvcore, antlr4-python3-runtime\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20220212-py3-none-any.whl size=61216 sha256=9194cc33d3aa04af61619f2bf35f4b8ba03aeeb10325706cc301866e6fe5ca0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/43/75/238d2a5d897274799f92b8938f3cd807a3ccd3c8f37c0a4725\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=8b2baa013f3885610d77057135b8bf23958791a5b20450a5058d105731e2aaa5\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built fvcore antlr4-python3-runtime\n",
            "Installing collected packages: portalocker, antlr4-python3-runtime, yacs, typed-ast, toml, regex, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, fvcore, black, detectron2\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "Successfully installed antlr4-python3-runtime-4.8 black-21.4b2 detectron2-0.6+cu111 fvcore-0.1.5.post20220212 hydra-core-1.1.1 iopath-0.1.9 mypy-extensions-0.4.3 omegaconf-2.1.1 pathspec-0.9.0 portalocker-2.4.0 regex-2022.1.18 toml-0.10.2 typed-ast-1.5.2 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git\n"
      ],
      "metadata": {
        "id": "zlzpyRthSMV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datapath = '/content/drive/MyDrive/PyPSA_Africa_images/datasets'\n",
        "\n",
        "import sys\n",
        "sys.argv = ['']"
      ],
      "metadata": {
        "id": "WvNVQVtqTklA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add pypsa africa tool\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/PyPSA_Africa_images/unbiased-teacher/')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/PyPSA_Africa_images/detect_energy/src/')"
      ],
      "metadata": {
        "id": "dv9TOSlUhnab"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import detectron2.utils.comm as comm\n",
        "from detectron2.checkpoint import DetectionCheckpointer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import default_argument_parser, default_setup, launch\n",
        "\n",
        "from ubteacher import add_ubteacher_config\n",
        "from ubteacher.engine.trainer import UBTeacherTrainer, BaselineTrainer\n",
        "\n",
        "# hacky way to register\n",
        "from ubteacher.modeling.meta_arch.rcnn import TwoStagePseudoLabGeneralizedRCNN\n",
        "from ubteacher.modeling.proposal_generator.rpn import PseudoLabRPN\n",
        "from ubteacher.modeling.roi_heads.roi_heads import StandardROIHeadsPseudoLab\n",
        "from ubteacher.modeling.meta_arch.rcnn import TwoStagePseudoLabGeneralizedRCNN\n",
        "import ubteacher.data.datasets.builtin\n",
        "\n",
        "from ubteacher.modeling.meta_arch.ts_ensemble import EnsembleTSModel\n",
        "\n",
        "# import some of our own methods\n",
        "from utils.detectron_utils import eval_predictor\n",
        "from utils.image_utils import get_true_images"
      ],
      "metadata": {
        "id": "fmGq_Ys-Z8-Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(args):\n",
        "    cfg = setup(args)\n",
        "\n",
        "    if cfg.SEMISUPNET.Trainer == \"ubteacher\":\n",
        "        Trainer = UBTeacherTrainer\n",
        "    elif cfg.SEMISUPNET.Trainer == \"baseline\":\n",
        "        Trainer = BaselineTrainer\n",
        "    else:\n",
        "        raise ValueError(\"Trainer Name is not found.\")\n",
        "\n",
        "    trainer = Trainer(cfg)    \n",
        "    trainer.train()\n",
        "    \n",
        "    return None"
      ],
      "metadata": {
        "id": "6AEeIRH8Nucq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2 import model_zoo\n",
        "\n",
        "def setup(args):\n",
        "\n",
        "    \"\"\"\n",
        "    Create configs and perform basic setups.\n",
        "    \"\"\"\n",
        "    cfg = get_cfg()\n",
        "    # print(cfg)\n",
        "    add_ubteacher_config(cfg)\n",
        "    # print(cfg)\n",
        "    cfg.merge_from_file(args.config_file)\n",
        "    cfg.merge_from_list(args.opts)\n",
        "    # cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml'))\n",
        "    cfg.freeze()\n",
        "    default_setup(cfg, args)\n",
        "    return cfg\n"
      ],
      "metadata": {
        "id": "Otixly6SNMPi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import logging\n",
        "import torch\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "from fvcore.nn.precise_bn import get_bn_modules\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "\n",
        "import detectron2.utils.comm as comm\n",
        "from detectron2.checkpoint import DetectionCheckpointer\n",
        "from detectron2.engine import DefaultTrainer, SimpleTrainer, TrainerBase\n",
        "from detectron2.engine.train_loop import AMPTrainer\n",
        "from detectron2.utils.events import EventStorage\n",
        "from detectron2.evaluation import COCOEvaluator, verify_results, PascalVOCDetectionEvaluator, DatasetEvaluators\n",
        "from detectron2.data.dataset_mapper import DatasetMapper\n",
        "from detectron2.engine import hooks\n",
        "from detectron2.structures.boxes import Boxes\n",
        "from detectron2.structures.instances import Instances\n",
        "from detectron2.utils.env import TORCH_VERSION\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2 import model_zoo\n",
        "\n",
        "from ubteacher.data.build import (\n",
        "    build_detection_semisup_train_loader,\n",
        "    build_detection_test_loader,\n",
        "    build_detection_semisup_train_loader_two_crops,\n",
        ")\n",
        "from ubteacher.data.dataset_mapper import DatasetMapperTwoCropSeparate\n",
        "from ubteacher.engine.hooks import LossEvalHook\n",
        "from ubteacher.modeling.meta_arch.ts_ensemble import EnsembleTSModel\n",
        "from ubteacher.checkpoint.detection_checkpoint import DetectionTSCheckpointer\n",
        "from ubteacher.solver.build import build_lr_scheduler"
      ],
      "metadata": {
        "id": "aK7Ub6lkh5sI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import logging\n",
        "import operator\n",
        "\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data.build import get_detection_dataset_dicts, build_batch_data_loader\n",
        "from detectron2.data.common import DatasetFromList, MapDataset\n",
        "from detectron2.data.samplers import TrainingSampler\n",
        "from detectron2.data.dataset_mapper import DatasetMapper\n",
        "from detectron2.utils.comm import get_world_size\n",
        "from detectron2.data.build import (\n",
        "    trivial_batch_collator,\n",
        "    worker_init_reset_seed,\n",
        "    get_detection_dataset_dicts,\n",
        "    build_batch_data_loader,\n",
        ")\n",
        "\n",
        "\n",
        "from ubteacher.data.build import divide_label_unlabel\n",
        "from ubteacher.data.common import (\n",
        "    AspectRatioGroupedSemiSupDatasetTwoCrop,\n",
        ")\n",
        "from ubteacher.modeling.meta_arch.ts_ensemble import EnsembleTSModel\n",
        "\n",
        "from itertools import product\n",
        "\n",
        "\n",
        "# batch data loader\n",
        "def build_semisup_batch_data_loader_two_crop(\n",
        "    dataset,\n",
        "    sampler,\n",
        "    total_batch_size_label,\n",
        "    total_batch_size_unlabel,\n",
        "    *,\n",
        "    aspect_ratio_grouping=False,\n",
        "    num_workers=0\n",
        "):\n",
        "    world_size = get_world_size()\n",
        "    assert (\n",
        "        total_batch_size_label > 0 and total_batch_size_label % world_size == 0\n",
        "    ), \"Total label batch size ({}) must be divisible by the number of gpus ({}).\".format(\n",
        "        total_batch_size_label, world_size\n",
        "    )\n",
        "\n",
        "    assert (\n",
        "        total_batch_size_unlabel > 0 and total_batch_size_unlabel % world_size == 0\n",
        "    ), \"Total unlabel batch size ({}) must be divisible by the number of gpus ({}).\".format(\n",
        "        total_batch_size_label, world_size\n",
        "    )\n",
        "\n",
        "    batch_size_label = total_batch_size_label // world_size\n",
        "    batch_size_unlabel = total_batch_size_unlabel // world_size\n",
        "\n",
        "    label_dataset, unlabel_dataset = dataset\n",
        "    label_sampler, unlabel_sampler = sampler\n",
        "\n",
        "    if aspect_ratio_grouping:\n",
        "        label_data_loader = torch.utils.data.DataLoader(\n",
        "            label_dataset,\n",
        "            sampler=label_sampler,\n",
        "            num_workers=num_workers,\n",
        "            batch_sampler=None,\n",
        "            collate_fn=operator.itemgetter(\n",
        "                0\n",
        "            ),  # don't batch, but yield individual elements\n",
        "            worker_init_fn=worker_init_reset_seed,\n",
        "        )  # yield individual mapped dict\n",
        "        unlabel_data_loader = torch.utils.data.DataLoader(\n",
        "            unlabel_dataset,\n",
        "            sampler=unlabel_sampler,\n",
        "            num_workers=num_workers,\n",
        "            batch_sampler=None,\n",
        "            collate_fn=operator.itemgetter(\n",
        "                0\n",
        "            ),  # don't batch, but yield individual elements\n",
        "            worker_init_fn=worker_init_reset_seed,\n",
        "        )  # yield individual mapped dict\n",
        "        return AspectRatioGroupedSemiSupDatasetTwoCrop(\n",
        "            (label_data_loader, unlabel_data_loader),\n",
        "            (batch_size_label, batch_size_unlabel),\n",
        "        )\n",
        "    else:\n",
        "        raise NotImplementedError(\"ASPECT_RATIO_GROUPING = False is not supported yet\")\n",
        "\n",
        "\n",
        "def build_maxar_loader_semisup_two_crops(cfg, mapper=None):\n",
        "    '''\n",
        "    Sets up loader for custom maxar data\n",
        "    '''\n",
        "\n",
        "    # register used datasets\n",
        "    ds_names = ['fake_maxar', 'maxar']\n",
        "    modes = ['train', 'val']\n",
        "\n",
        "    for name, mode in product(ds_names, modes):\n",
        "\n",
        "        ds_name = f'{name}_{mode}'\n",
        "        json_path = f'/content/drive/My Drive/PyPSA_Africa_images/datasets/{ds_name}/labels.json'\n",
        "        ds_path = f'/content/drive/My Drive/PyPSA_Africa_images/datasets/{ds_name}/data/' \n",
        "    \n",
        "        if ds_name in DatasetCatalog.list():\n",
        "            DatasetCatalog.remove(ds_name)\n",
        "            MetadataCatalog.remove(ds_name)\n",
        "    \n",
        "        register_coco_instances(ds_name, {}, json_path, ds_path)\n",
        "    \n",
        "    unlabel_dicts = get_detection_dataset_dicts(\n",
        "                            ['maxar_train', 'maxar_val'],\n",
        "                            filter_empty=False,\n",
        "                            min_keypoints=0,\n",
        "                            proposal_files=None\n",
        "                        )\n",
        "\n",
        "    label_dicts = get_detection_dataset_dicts(\n",
        "                            ['fake_maxar_train', 'fake_maxar_val'],\n",
        "                            filter_empty=False,\n",
        "                            min_keypoints=0,\n",
        "                            proposal_files=None\n",
        "                        )\n",
        " \n",
        "     \n",
        "    label_dataset = DatasetFromList(label_dicts, copy=False)\n",
        "    unlabel_dataset = DatasetFromList(unlabel_dicts, copy=False)\n",
        "\n",
        "    if mapper is None:\n",
        "        mapper = DatasetMapper(cfg, True)\n",
        "    label_dataset = MapDataset(label_dataset, mapper)\n",
        "    unlabel_dataset = MapDataset(unlabel_dataset, mapper)\n",
        "\n",
        "    sampler_name = cfg.DATALOADER.SAMPLER_TRAIN\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.info(\"Using training sampler {}\".format(sampler_name))\n",
        "    if sampler_name == \"TrainingSampler\":\n",
        "        label_sampler = TrainingSampler(len(label_dataset))\n",
        "        unlabel_sampler = TrainingSampler(len(unlabel_dataset))\n",
        "    elif sampler_name == \"RepeatFactorTrainingSampler\":\n",
        "        raise NotImplementedError(\"{} not yet supported.\".format(sampler_name))\n",
        "    else:\n",
        "        raise ValueError(\"Unknown training sampler: {}\".format(sampler_name))\n",
        "    return build_semisup_batch_data_loader_two_crop(\n",
        "        (label_dataset, unlabel_dataset),\n",
        "        (label_sampler, unlabel_sampler),\n",
        "        cfg.SOLVER.IMG_PER_BATCH_LABEL,\n",
        "        cfg.SOLVER.IMG_PER_BATCH_UNLABEL,\n",
        "        aspect_ratio_grouping=cfg.DATALOADER.ASPECT_RATIO_GROUPING,\n",
        "        num_workers=cfg.DATALOADER.NUM_WORKERS,\n",
        "    )\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DegpQw46zRuG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import torchvision.transforms as transforms\n",
        "from ubteacher.data.transforms.augmentation_impl import GaussianBlur\n",
        "\n",
        "def build_strong_maxar_augmentation(cfg, is_train):\n",
        "\n",
        "    logger = logging.getLogger(__name__)\n",
        "    augmentation = []\n",
        "\n",
        "    if is_train:\n",
        "        # This is simialr to SimCLR https://arxiv.org/abs/2002.05709\n",
        "        augmentation.append(\n",
        "            transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8)\n",
        "        )\n",
        "        augmentation.append(transforms.RandomGrayscale(p=0.2))\n",
        "        augmentation.append(transforms.RandomApply([GaussianBlur([0.1, 2.0])], p=0.5))\n",
        "\n",
        "        other_transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.ToTensor(),\n",
        "                # transforms.RandomErasing(\n",
        "                #     p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=\"random\"\n",
        "                # ),\n",
        "                # transforms.RandomErasing(\n",
        "                #     p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=\"random\"\n",
        "                # ),\n",
        "                # transforms.RandomErasing(\n",
        "                #     p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=\"random\"\n",
        "                # ),\n",
        "                transforms.ToPILImage(),\n",
        "            ]\n",
        "        )\n",
        "        augmentation.append(other_transform)\n",
        "\n",
        "        logger.info(\"Augmentations used in training: \" + str(augmentation))\n",
        "    return transforms.Compose(augmentation)\n"
      ],
      "metadata": {
        "id": "7S0u1XCKvM2O"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.data.dataset_mapper import DatasetMapper\n",
        "import detectron2.data.detection_utils as utils\n",
        "\n",
        "from ubteacher.data.dataset_mapper import DatasetMapperTwoCropSeparate\n",
        "\n",
        "\n",
        "class MaxarDatasetMapper(DatasetMapperTwoCropSeparate):\n",
        "    def __init__(self, cfg, is_train=True):\n",
        "        self.augmentation = utils.build_augmentation(cfg, is_train)\n",
        "        self.compute_tight_boxes = False\n",
        "        self.strong_augmentation = build_strong_maxar_augmentation(cfg, is_train)\n",
        "\n",
        "        # fmt: off\n",
        "        self.img_format = cfg.INPUT.FORMAT\n",
        "        self.mask_on = cfg.MODEL.MASK_ON\n",
        "        self.mask_format = cfg.INPUT.MASK_FORMAT\n",
        "        self.keypoint_on = cfg.MODEL.KEYPOINT_ON\n",
        "        self.load_proposals = cfg.MODEL.LOAD_PROPOSALS\n",
        "        # fmt: on\n",
        "        if self.keypoint_on and is_train:\n",
        "            self.keypoint_hflip_indices = utils.create_keypoint_hflip_indices(\n",
        "                cfg.DATASETS.TRAIN\n",
        "            )\n",
        "        else:\n",
        "            self.keypoint_hflip_indices = None\n",
        "\n",
        "        if self.load_proposals:\n",
        "            self.proposal_min_box_size = cfg.MODEL.PROPOSAL_GENERATOR.MIN_SIZE\n",
        "            self.proposal_topk = (\n",
        "                cfg.DATASETS.PRECOMPUTED_PROPOSAL_TOPK_TRAIN\n",
        "                if is_train\n",
        "                else cfg.DATASETS.PRECOMPUTED_PROPOSAL_TOPK_TEST\n",
        "            )\n",
        "        self.is_train = is_train\n",
        "\n"
      ],
      "metadata": {
        "id": "S_y9SwGpQn3O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.modeling.meta_arch.build import META_ARCH_REGISTRY\n",
        "from detectron2.modeling.meta_arch.rcnn import GeneralizedRCNN\n",
        "import pprint\n",
        "\n",
        "if 'MaxarPseudoLabGeneralizedRCNN' in META_ARCH_REGISTRY:\n",
        "    META_ARCH_REGISTRY.__dict__['_obj_map'].pop('MaxarPseudoLabGeneralizedRCNN')\n",
        "\n",
        "@META_ARCH_REGISTRY.register()\n",
        "class MaxarPseudoLabGeneralizedRCNN(GeneralizedRCNN):\n",
        "\n",
        "    def forward(\n",
        "        self, batched_inputs, branch=\"supervised\", given_proposals=None, val_mode=False\n",
        "    ):\n",
        "        if (not self.training) and (not val_mode) and (not branch=='unsup_data_weak'):\n",
        "            inference = self.inference(batched_inputs)\n",
        "            # inference = change_prediction_classes(inference, to=0)\n",
        "            return inference\n",
        "\n",
        "        images = self.preprocess_image(batched_inputs)\n",
        "\n",
        "        if \"instances\" in batched_inputs[0]:\n",
        "            gt_instances = [x[\"instances\"].to(self.device) for x in batched_inputs]\n",
        "        else:\n",
        "            gt_instances = None\n",
        "\n",
        "        features = self.backbone(images.tensor)\n",
        "\n",
        "        if branch == \"supervised\":\n",
        "            # Region proposal network\n",
        "            proposals_rpn, proposal_losses = self.proposal_generator(\n",
        "                images, features, gt_instances\n",
        "            )\n",
        "\n",
        "            # # roi_head lower branch\n",
        "            _, detector_losses = self.roi_heads(\n",
        "                images, features, proposals_rpn, gt_instances, branch=branch\n",
        "            )\n",
        "\n",
        "            losses = {}\n",
        "            losses.update(detector_losses)\n",
        "            losses.update(proposal_losses)\n",
        "            return losses, [], [], None\n",
        "\n",
        "        elif branch == \"unsup_data_weak\":\n",
        "\n",
        "            # Region proposal network\n",
        "            proposals_rpn, _ = self.proposal_generator(\n",
        "                images, features, None, compute_loss=False\n",
        "            )\n",
        "\n",
        "            # roi_head lower branch (keep this for further production)  \n",
        "            # notice that we do not use any target in ROI head to do inference !\n",
        "            proposals_roih, ROI_predictions = self.roi_heads(\n",
        "                images,\n",
        "                features,\n",
        "                proposals_rpn,\n",
        "                targets=None,\n",
        "                compute_loss=False,\n",
        "                branch=branch,\n",
        "            )\n",
        "\n",
        "            return {}, proposals_rpn, proposals_roih, ROI_predictions\n",
        "\n",
        "        elif branch == \"val_loss\":\n",
        " \n",
        "            # Region proposal network\n",
        "            proposals_rpn, proposal_losses = self.proposal_generator(\n",
        "                images, features, gt_instances, compute_val_loss=True\n",
        "            )\n",
        "\n",
        "            # roi_head lower branch\n",
        "            _, detector_losses = self.roi_heads(\n",
        "                images,\n",
        "                features,\n",
        "                proposals_rpn,\n",
        "                gt_instances,\n",
        "                branch=branch,\n",
        "                compute_val_loss=True,\n",
        "            )\n",
        "\n",
        "            losses = {}\n",
        "            losses.update(detector_losses)\n",
        "            losses.update(proposal_losses)\n",
        "            return losses, [], [], None"
      ],
      "metadata": {
        "id": "sydVSMVD1LUu"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "from detectron2.structures import Boxes, ImageList, Instances, pairwise_iou\n",
        "from detectron2.modeling.proposal_generator.proposal_utils import (\n",
        "    add_ground_truth_to_proposals,\n",
        ")\n",
        "from detectron2.utils.events import get_event_storage\n",
        "from detectron2.modeling.roi_heads.box_head import build_box_head\n",
        "from detectron2.layers import ShapeSpec\n",
        "from detectron2.modeling.roi_heads import (\n",
        "    ROI_HEADS_REGISTRY,\n",
        "    StandardROIHeads,\n",
        ")\n",
        "from detectron2.modeling.roi_heads.fast_rcnn import FastRCNNOutputLayers\n",
        "\n",
        "import numpy as np\n",
        "from detectron2.modeling.poolers import ROIPooler\n",
        "\n",
        "if 'MaxarROIHeads' in ROI_HEADS_REGISTRY:\n",
        "    ROI_HEADS_REGISTRY.__dict__['_obj_map'].pop('MaxarROIHeads')\n",
        "\n",
        "@ROI_HEADS_REGISTRY.register()\n",
        "class MaxarROIHeads(StandardROIHeads):\n",
        "    @classmethod\n",
        "    def _init_box_head(cls, cfg, input_shape):\n",
        "        # fmt: off\n",
        "        in_features       = cfg.MODEL.ROI_HEADS.IN_FEATURES\n",
        "        pooler_resolution = cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION\n",
        "        pooler_scales     = tuple(1.0 / input_shape[k].stride for k in in_features)\n",
        "        sampling_ratio    = cfg.MODEL.ROI_BOX_HEAD.POOLER_SAMPLING_RATIO\n",
        "        pooler_type       = cfg.MODEL.ROI_BOX_HEAD.POOLER_TYPE\n",
        "        # fmt: on\n",
        "\n",
        "        in_channels = [input_shape[f].channels for f in in_features]\n",
        "        # Check all channel counts are equal\n",
        "        assert len(set(in_channels)) == 1, in_channels\n",
        "        in_channels = in_channels[0]\n",
        "\n",
        "        box_pooler = ROIPooler(\n",
        "            output_size=pooler_resolution,\n",
        "            scales=pooler_scales,\n",
        "            sampling_ratio=sampling_ratio,\n",
        "            pooler_type=pooler_type,\n",
        "        )\n",
        "        box_head = build_box_head(\n",
        "            cfg,\n",
        "            ShapeSpec(\n",
        "                channels=in_channels, height=pooler_resolution, width=pooler_resolution\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        box_predictor = FastRCNNOutputLayers(cfg, box_head.output_shape)    \n",
        "        return {\n",
        "            \"box_in_features\": in_features,\n",
        "            \"box_pooler\": box_pooler,\n",
        "            \"box_head\": box_head,\n",
        "            \"box_predictor\": box_predictor,\n",
        "        }\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        images: ImageList,\n",
        "        features: Dict[str, torch.Tensor],\n",
        "        proposals: List[Instances],\n",
        "        targets: Optional[List[Instances]] = None,\n",
        "        compute_loss=True,\n",
        "        branch=\"\",\n",
        "        compute_val_loss=False,\n",
        "    ) -> Tuple[List[Instances], Dict[str, torch.Tensor]]:\n",
        "\n",
        "        del images\n",
        "        if self.training and compute_loss:  # apply if training loss\n",
        "            assert targets\n",
        "            # 1000 --> 512\n",
        "            proposals = self.label_and_sample_proposals(\n",
        "                proposals, targets, branch=branch\n",
        "            )\n",
        "        elif compute_val_loss:  # apply if val loss\n",
        "            assert targets\n",
        "            # 1000 --> 512\n",
        "            temp_proposal_append_gt = self.proposal_append_gt\n",
        "            self.proposal_append_gt = False\n",
        "            proposals = self.label_and_sample_proposals(\n",
        "                proposals, targets, branch=branch\n",
        "            )  # do not apply target on proposals\n",
        "            self.proposal_append_gt = temp_proposal_append_gt\n",
        "        del targets\n",
        "\n",
        "        if (self.training and compute_loss) or compute_val_loss:\n",
        "            losses, _ = self._forward_box(\n",
        "                features, proposals, compute_loss, compute_val_loss, branch\n",
        "            )\n",
        "            return proposals, losses\n",
        "        else:\n",
        "            pred_instances, predictions = self._forward_box(\n",
        "                features, proposals, compute_loss, compute_val_loss, branch\n",
        "            )\n",
        "\n",
        "            return pred_instances, predictions\n",
        "\n",
        "\n",
        "    def _forward_box(\n",
        "        self,\n",
        "        features: Dict[str, torch.Tensor],\n",
        "        proposals: List[Instances],\n",
        "        compute_loss: bool = True,\n",
        "        compute_val_loss: bool = False,\n",
        "        branch: str = \"\",\n",
        "    ) -> Union[Dict[str, torch.Tensor], List[Instances]]:\n",
        "        features = [features[f] for f in self.box_in_features]\n",
        "        box_features = self.box_pooler(features, [x.proposal_boxes for x in proposals])\n",
        "        box_features = self.box_head(box_features)\n",
        "        predictions = self.box_predictor(box_features)\n",
        "        del box_features\n",
        "\n",
        "        if (\n",
        "            self.training and compute_loss\n",
        "        ) or compute_val_loss:  # apply if training loss or val loss\n",
        "            losses = self.box_predictor.losses(predictions, proposals)\n",
        "\n",
        "            if self.train_on_pred_boxes:\n",
        "                with torch.no_grad():\n",
        "                    pred_boxes = self.box_predictor.predict_boxes_for_gt_classes(\n",
        "                        predictions, proposals\n",
        "                    )\n",
        "                    for proposals_per_image, pred_boxes_per_image in zip(\n",
        "                        proposals, pred_boxes\n",
        "                    ):\n",
        "                        proposals_per_image.proposal_boxes = Boxes(pred_boxes_per_image)\n",
        "            return losses, predictions\n",
        "        else:\n",
        "\n",
        "            pred_instances, _ = self.box_predictor.inference(predictions, proposals)\n",
        "            return pred_instances, predictions\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def label_and_sample_proposals(\n",
        "        self, proposals: List[Instances], targets: List[Instances], branch: str = \"\"\n",
        "    ) -> List[Instances]:\n",
        "        gt_boxes = [x.gt_boxes for x in targets]\n",
        "        if self.proposal_append_gt:\n",
        "            proposals = add_ground_truth_to_proposals(gt_boxes, proposals)\n",
        "\n",
        "        proposals_with_gt = []\n",
        "\n",
        "        num_fg_samples = []\n",
        "        num_bg_samples = []\n",
        "        for proposals_per_image, targets_per_image in zip(proposals, targets):\n",
        "            has_gt = len(targets_per_image) > 0\n",
        "            match_quality_matrix = pairwise_iou(\n",
        "                targets_per_image.gt_boxes, proposals_per_image.proposal_boxes\n",
        "            )\n",
        "            matched_idxs, matched_labels = self.proposal_matcher(match_quality_matrix)\n",
        "            sampled_idxs, gt_classes = self._sample_proposals(\n",
        "                matched_idxs, matched_labels, targets_per_image.gt_classes\n",
        "            )\n",
        "\n",
        "            proposals_per_image = proposals_per_image[sampled_idxs]\n",
        "            proposals_per_image.gt_classes = gt_classes\n",
        "\n",
        "            if has_gt:\n",
        "                sampled_targets = matched_idxs[sampled_idxs]\n",
        "                for (trg_name, trg_value) in targets_per_image.get_fields().items():\n",
        "                    if trg_name.startswith(\"gt_\") and not proposals_per_image.has(\n",
        "                        trg_name\n",
        "                    ):\n",
        "                        proposals_per_image.set(trg_name, trg_value[sampled_targets])\n",
        "            else:\n",
        "                gt_boxes = Boxes(\n",
        "                    targets_per_image.gt_boxes.tensor.new_zeros((len(sampled_idxs), 4))\n",
        "                )\n",
        "                proposals_per_image.gt_boxes = gt_boxes\n",
        "\n",
        "            num_bg_samples.append((gt_classes == self.num_classes).sum().item())\n",
        "            num_fg_samples.append(gt_classes.numel() - num_bg_samples[-1])\n",
        "            proposals_with_gt.append(proposals_per_image)\n",
        "\n",
        "        storage = get_event_storage()\n",
        "        storage.put_scalar(\n",
        "            \"roi_head/num_target_fg_samples_\" + branch, np.mean(num_fg_samples)\n",
        "        )\n",
        "        storage.put_scalar(\n",
        "            \"roi_head/num_target_bg_samples_\" + branch, np.mean(num_bg_samples)\n",
        "        )\n",
        "\n",
        "        return proposals_with_gt"
      ],
      "metadata": {
        "id": "KpCL0muRrwB4"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data import detection_utils as utils\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import softmax\n",
        "from scipy.special import expit\n",
        "plt.style.use('bmh')\n",
        "\n",
        "\n",
        "def show_data(datalist, metadata=MetadataCatalog.get('fake_maxar_val'), final_output=True):\n",
        "\n",
        "    if final_output:\n",
        "        try:\n",
        "            datalist = change_classes(datalist)\n",
        "        except KeyError:\n",
        "            pass\n",
        "    \n",
        "    for data in datalist:\n",
        "        img = data[\"image\"].permute(1, 2, 0).cpu().detach().numpy()\n",
        "        img = utils.convert_image_to_rgb(img, cfg.INPUT.FORMAT)        \n",
        "\n",
        "        visualizer = Visualizer(img, metadata=metadata, scale=0.6)\n",
        "\n",
        "        if 'instances' in data:\n",
        "            target_fields = data[\"instances\"].get_fields()\n",
        "\n",
        "            if 'proposal_boxes' in target_fields:\n",
        "\n",
        "                objectness = [expit(val.cpu()) for val in target_fields['objectness_logits']]\n",
        "\n",
        "                for prob, (i, box) in zip(objectness, enumerate(target_fields['proposal_boxes'].to('cpu'))):\n",
        "\n",
        "                    if prob < max(objectness):\n",
        "                        continue\n",
        "\n",
        "                    visualizer.draw_box(box)\n",
        "                    visualizer.draw_text(prob.item(), tuple(box[:2].numpy()))\n",
        "\n",
        "                cv2_imshow(visualizer.get_output().get_image()[:,:,::-1])\n",
        "                return\n",
        "\n",
        "            elif 'gt_classes' in target_fields:\n",
        "                labels = [metadata.thing_classes[i] for i in target_fields[\"gt_classes\"]]\n",
        "                visualizer = visualizer.overlay_instances(\n",
        "                    labels=labels,\n",
        "                    boxes=target_fields.get(\"gt_boxes\", None),\n",
        "                    masks=target_fields.get(\"gt_masks\", None),\n",
        "                    keypoints=target_fields.get(\"gt_keypoints\", None),\n",
        "                )\n",
        "            else:\n",
        "                visualizer = visualizer.draw_instance_predictions(data['instances'])\n",
        "\n",
        "            cv2_imshow(visualizer.get_image()[:,:,::-1])\n",
        "        \n",
        "        else:\n",
        "            cv2_imshow(visualizer.get_output().get_image()[:,:,::-1])\n",
        "\n",
        "\n",
        "def filter_instances(data):\n",
        "    '''\n",
        "    Removes all instances in data that are faulty.\n",
        "    E.g. have no extent\n",
        "\n",
        "    Args:\n",
        "        data(List[Dict]): each list entry is one image\n",
        "    '''\n",
        "\n",
        "    for i, datum in enumerate(data):\n",
        "        \n",
        "        try:\n",
        "            insts = datum['instances']\n",
        "        except KeyError:\n",
        "            continue\n",
        "\n",
        "        # filter instances that have area zero\n",
        "        t = insts.gt_boxes.tensor.cpu()\n",
        "        num = len(insts)\n",
        "        mask = (t[:,0] - t[:,2]) != torch.zeros(num)\n",
        "        mask *= (t[:,1] - t[:,3]) != torch.zeros(num)\n",
        "        insts = insts[mask]\n",
        "\n",
        "        datum['instances'] = insts\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "SJ0s8gfxUqbb"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def change_prediction_classes(inference, to=1):\n",
        "\n",
        "    for img in inference:\n",
        "        img['instances'].pred_classes = (torch.ones(len(img['instances']), dtype=int) * to)\n",
        "        img['instances']\n",
        "    return inference\n",
        "    \n"
      ],
      "metadata": {
        "id": "TvILLvCiKxGx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ubteacher.modeling.meta_arch.rcnn import TwoStagePseudoLabGeneralizedRCNN\n",
        "from ubteacher.modeling.meta_arch.rcnn import TwoStagePseudoLabGeneralizedRCNN\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.evaluation import inference_on_dataset \n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data import build_detection_test_loader\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('bmh')\n",
        "import numpy as np\n",
        "\n",
        "def change_classes(data):\n",
        "    for i, datum in enumerate(data):\n",
        "        # print(datum['instances'])\n",
        "        classes = getattr(datum['instances'], 'gt_classes')\n",
        "        setattr(datum['instances'], 'gt_classes', torch.ones_like(classes, dtype=int))\n",
        "        data[i] = datum\n",
        "    \n",
        "    return data\n",
        "\n",
        "class MaxarUBTeacher(DefaultTrainer):\n",
        "    '''\n",
        "    Unbiased teacher adapted to the transfer of training performance from \n",
        "    duke to maxar images\n",
        "\n",
        "    This currently completely omits the BURN-IN stage and presumes it a \n",
        "    as already complete\n",
        "    '''\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        cfg = DefaultTrainer.auto_scale_workers(cfg, comm.get_world_size())\n",
        "\n",
        "        model = self.build_model(cfg)\n",
        "        self.model_teacher = self.build_model(cfg)\n",
        "\n",
        "        data_loader = self.build_train_loader(cfg)\n",
        "        optimizer = self.build_optimizer(cfg, model)\n",
        "\n",
        "        self.evaluator = COCOEvaluator(cfg.DATASETS.TEST)\n",
        "        self.evaluator._tasks = ['bbox']\n",
        "\n",
        "        if comm.get_world_size() > 1:\n",
        "            model = DistributedDataParallel(\n",
        "                model, device_ids=[comm.get_local_rank()], broadcast_buffers=False\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "        TrainerBase.__init__(self)\n",
        "        self._trainer = SimpleTrainer(model, data_loader, optimizer)\n",
        "\n",
        "        ensem_ts_model = EnsembleTSModel(self.model_teacher, model)\n",
        "\n",
        "        self.scheduler = self.build_lr_scheduler(cfg, optimizer)\n",
        "        self.checkpointer = DetectionCheckpointer(\n",
        "            ensem_ts_model,\n",
        "            cfg.OUTPUT_DIR,\n",
        "            optimizer=optimizer,\n",
        "            scheduler=self.scheduler,\n",
        "        )\n",
        "        self.start_iter = 0\n",
        "        self.max_iter = cfg.SOLVER.MAX_ITER\n",
        "        self.cfg = cfg\n",
        "\n",
        "        ds_name = cfg.DATASETS.TEST\n",
        "        json_path = f'/content/drive/My Drive/PyPSA_Africa_images/datasets/{ds_name}/labels.json'\n",
        "        ds_path = f'/content/drive/My Drive/PyPSA_Africa_images/datasets/{ds_name}/data/' \n",
        "        if ds_name in DatasetCatalog.list():\n",
        "            DatasetCatalog.remove(ds_name)\n",
        "            MetadataCatalog.remove(ds_name)\n",
        "        register_coco_instances(ds_name, {}, json_path, ds_path)\n",
        "        \n",
        "        print(f'Building test loader from {cfg.DATASETS.TEST}')\n",
        "        print(type(DatasetCatalog.get(cfg.DATASETS.TEST)))\n",
        "        self.test_loader = build_detection_test_loader(\n",
        "                                DatasetCatalog.get(cfg.DATASETS.TEST),\n",
        "                                mapper=DatasetMapper(cfg, is_train=False)\n",
        "        )\n",
        "\n",
        "        self.register_hooks(self.build_hooks())\n",
        "        print('setup ub teacher complete!')\n",
        "\n",
        "    # =====================================================\n",
        "    # ================== Pseduo-labeling ==================\n",
        "    # =====================================================\n",
        "\n",
        "    def threshold_bbox(self, proposal_bbox_inst, thres=0.7, proposal_type=\"roih\"):\n",
        "        if proposal_type == \"rpn\":\n",
        "            valid_map = proposal_bbox_inst.objectness_logits > thres\n",
        "\n",
        "            # create instances containing boxes and gt_classes\n",
        "            image_shape = proposal_bbox_inst.image_size\n",
        "            new_proposal_inst = Instances(image_shape)\n",
        "\n",
        "            # create box\n",
        "            new_bbox_loc = proposal_bbox_inst.proposal_boxes.tensor[valid_map, :]\n",
        "            new_boxes = Boxes(new_bbox_loc)\n",
        "\n",
        "            # add boxes to instances\n",
        "            new_proposal_inst.gt_boxes = new_boxes\n",
        "            new_proposal_inst.objectness_logits = proposal_bbox_inst.objectness_logits[\n",
        "                valid_map\n",
        "            ]\n",
        "        elif proposal_type == \"roih\":\n",
        "            valid_map = proposal_bbox_inst.scores > thres\n",
        "\n",
        "            # create instances containing boxes and gt_classes\n",
        "            image_shape = proposal_bbox_inst.image_size\n",
        "            new_proposal_inst = Instances(image_shape)\n",
        "\n",
        "            # create box\n",
        "            new_bbox_loc = proposal_bbox_inst.pred_boxes.tensor[valid_map, :]\n",
        "            new_boxes = Boxes(new_bbox_loc)\n",
        "\n",
        "            # add boxes to instances\n",
        "            new_proposal_inst.gt_boxes = new_boxes\n",
        "            new_proposal_inst.gt_classes = proposal_bbox_inst.pred_classes[valid_map]\n",
        "            new_proposal_inst.scores = proposal_bbox_inst.scores[valid_map]\n",
        "\n",
        "        return new_proposal_inst\n",
        "\n",
        "    def process_pseudo_label(\n",
        "        self, proposals_rpn_unsup_k, cur_threshold, proposal_type, psedo_label_method=\"\"\n",
        "    ):\n",
        "        list_instances = []\n",
        "        num_proposal_output = 0.0\n",
        "        for proposal_bbox_inst in proposals_rpn_unsup_k:\n",
        "            # thresholding\n",
        "            if psedo_label_method == \"thresholding\":\n",
        "                proposal_bbox_inst = self.threshold_bbox(\n",
        "                    proposal_bbox_inst, thres=cur_threshold, proposal_type=proposal_type\n",
        "                )\n",
        "            else:\n",
        "                raise ValueError(\"Unkown pseudo label boxes methods\")\n",
        "            num_proposal_output += len(proposal_bbox_inst)\n",
        "            list_instances.append(proposal_bbox_inst)\n",
        "        num_proposal_output = num_proposal_output / len(proposals_rpn_unsup_k)\n",
        "        return list_instances, num_proposal_output\n",
        "\n",
        "    def remove_label(self, label_data):\n",
        "        for label_datum in label_data:\n",
        "            if \"instances\" in label_datum.keys():\n",
        "                del label_datum[\"instances\"]\n",
        "        return label_data\n",
        "\n",
        "    def add_label(self, unlabled_data, label):\n",
        "        for unlabel_datum, lab_inst in zip(unlabled_data, label):\n",
        "            unlabel_datum[\"instances\"] = lab_inst\n",
        "        return unlabled_data\n",
        "\n",
        "    # =====================================================\n",
        "    # =================== Training Flow ===================\n",
        "    # =====================================================\n",
        "    \n",
        "    def train(self):\n",
        "        self.train_loop(self.start_iter, self.max_iter)\n",
        "        if hasattr(self, \"_last_eval_results\") and comm.is_main_process():\n",
        "            verify_results(self.cfg, self._last_eval_results)\n",
        "            return self._last_eval_results\n",
        "\n",
        "\n",
        "    def train_loop(self, start_iter: int, max_iter: int):\n",
        "        logger = logging.getLogger(__name__)\n",
        "        logger.info('Starting from iteration {}'.format(start_iter))\n",
        "\n",
        "        self.iter = self.start_iter = start_iter\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "        with EventStorage(start_iter) as self.storage:\n",
        "            try:\n",
        "                self.before_train()\n",
        "\n",
        "                for self.iter in range(start_iter, max_iter):\n",
        "\n",
        "                    self.before_step()\n",
        "                    self.run_step_full_semisup()\n",
        "                    self.after_step()\n",
        "\n",
        "            except Exception:\n",
        "                logger.exception(\"Exception during training:\")\n",
        "                raise\n",
        "            finally:\n",
        "                self.after_train()\n",
        "\n",
        "\n",
        "    def after_step(self):\n",
        "        # tests of manually labelled maxar data every cfg.TEST.INTERVAL iterations\n",
        "\n",
        "        if self.cfg.TEST.INTERVAL % (self.iter+1) == 0:\n",
        "\n",
        "            _, model = build_predictor_model()\n",
        "            model_eval = inference_on_dataset(model, \n",
        "                                                self.test_loader, \n",
        "                                                self.evaluator)\n",
        "            teacher_eval = inference_on_dataset(self.model_teacher, \n",
        "                                                self.test_loader, \n",
        "                                                self.evaluator)\n",
        "            student_eval = inference_on_dataset(self.model, \n",
        "                                                self.test_loader, \n",
        "                                                self.evaluator)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def after_train(self):\n",
        "        print('Training has concluded')\n",
        "        \n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _update_teacher_model(self, keep_rate=0.996):\n",
        "        if comm.get_world_size() > 1:\n",
        "            student_model_dict = {\n",
        "                key[7:]: value for key, value in self.model.state_dict().items()\n",
        "            }\n",
        "        else:\n",
        "            student_model_dict = self.model.state_dict()\n",
        "\n",
        "        new_teacher_dict = OrderedDict()\n",
        "        for key, value in self.model_teacher.state_dict().items():\n",
        "            if key in student_model_dict.keys():\n",
        "                new_teacher_dict[key] = (\n",
        "                    student_model_dict[key] *\n",
        "                    (1 - keep_rate) + value * keep_rate\n",
        "                )\n",
        "            else:\n",
        "                raise Exception(\"{} is not found in student model\".format(key))\n",
        "\n",
        "        self.model_teacher.load_state_dict(new_teacher_dict)\n",
        "\n",
        "    def _write_metrics(self, metrics_dict: dict):\n",
        "        metrics_dict = {\n",
        "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
        "            for k, v in metrics_dict.items()\n",
        "        }\n",
        "\n",
        "        # gather metrics among all workers for logging\n",
        "        # This assumes we do DDP-style training, which is currently the only\n",
        "        # supported method in detectron2.\n",
        "        all_metrics_dict = comm.gather(metrics_dict)\n",
        "        # all_hg_dict = comm.gather(hg_dict)\n",
        "\n",
        "        if comm.is_main_process():\n",
        "            if \"data_time\" in all_metrics_dict[0]:\n",
        "                # data_time among workers can have high variance. The actual latency\n",
        "                # caused by data_time is the maximum among workers.\n",
        "                data_time = np.max([x.pop(\"data_time\")\n",
        "                                   for x in all_metrics_dict])\n",
        "                self.storage.put_scalar(\"data_time\", data_time)\n",
        "\n",
        "            # average the rest metrics\n",
        "            metrics_dict = {\n",
        "                k: np.mean([x[k] for x in all_metrics_dict])\n",
        "                for k in all_metrics_dict[0].keys()\n",
        "            }\n",
        "\n",
        "            # append the list\n",
        "            loss_dict = {}\n",
        "            for key in metrics_dict.keys():\n",
        "                if key[:4] == \"loss\":\n",
        "                    loss_dict[key] = metrics_dict[key]\n",
        "\n",
        "            total_losses_reduced = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            self.storage.put_scalar(\"total_loss\", total_losses_reduced)\n",
        "            if len(metrics_dict) > 1:\n",
        "                self.storage.put_scalars(**metrics_dict)\n",
        "\n",
        "\n",
        "    def run_step_full_semisup(self):\n",
        "        self._trainer.iter = self.iter\n",
        "        assert self.model.training, 'self.model was changed to eval mode!'\n",
        "\n",
        "        start = time.perf_counter()\n",
        "        data = next(self._trainer._data_loader_iter)\n",
        "        label_data_q, label_data_k, unlabel_data_q, unlabel_data_k = data\n",
        "        data_time = time.perf_counter() - start\n",
        "\n",
        "        # remove unlabeled data labels\n",
        "        unlabel_data_q = self.remove_label(unlabel_data_q)\n",
        "        unlabel_data_k = self.remove_label(unlabel_data_k)\n",
        "\n",
        "\n",
        "        if self.iter % self.cfg.SEMISUPNET.TEACHER_UPDATE_ITER == 0:\n",
        "            self._update_teacher_model(keep_rate=self.cfg.SEMISUPNET.EMA_KEEP_RATE) \n",
        "\n",
        "        record_dict = {}\n",
        "\n",
        "        # Get everything at pseudo-labelling\n",
        "        # global student\n",
        "        # global teacher \n",
        "        # global loader \n",
        "        # global checkpointer\n",
        "\n",
        "        # student = self.model \n",
        "        # teacher = self.model_teacher\n",
        "        # loader = self._trainer._data_loader_iter\n",
        "        # checkpointer = self.checkpointer\n",
        "\n",
        "        with torch.no_grad():\n",
        "            (\n",
        "            _,\n",
        "            proposals_rpn_unsup_k,\n",
        "            proposals_roih_unsup_k,\n",
        "            _,\n",
        "            ) = self.model_teacher(unlabel_data_k, branch=\"unsup_data_weak\")\n",
        "\n",
        "        cur_threshold = self.cfg.SEMISUPNET.BBOX_THRESHOLD\n",
        "\n",
        "        joint_proposal_dict = {}\n",
        "        joint_proposal_dict['proposals_rpn'] = proposals_rpn_unsup_k\n",
        "\n",
        "        (\n",
        "            pesudo_proposals_rpn_unsup_k,\n",
        "            nun_pseudo_bbox_rpn,\n",
        "        ) = self.process_pseudo_label(\n",
        "            proposals_rpn_unsup_k, cur_threshold, \"rpn\", \"thresholding\"\n",
        "        )\n",
        "\n",
        "        joint_proposal_dict[\"proposals_pseudo_rpn\"] = pesudo_proposals_rpn_unsup_k\n",
        "        # Pseudo_labeling for ROI head (bbox location/objectness)\n",
        "        pesudo_proposals_roih_unsup_k, _ = self.process_pseudo_label(\n",
        "            proposals_roih_unsup_k, cur_threshold, \"roih\", \"thresholding\"\n",
        "        )\n",
        "        joint_proposal_dict[\"proposals_pseudo_roih\"] = pesudo_proposals_roih_unsup_k   \n",
        "\n",
        "\n",
        "        unlabel_data_q = self.add_label(\n",
        "            unlabel_data_q, joint_proposal_dict[\"proposals_pseudo_roih\"]\n",
        "        )\n",
        "        unlabel_data_k = self.add_label(\n",
        "            unlabel_data_k, joint_proposal_dict[\"proposals_pseudo_roih\"]\n",
        "        )\n",
        "\n",
        "        all_label_data = label_data_q + label_data_k\n",
        "        global all_unlabel_data\n",
        "        all_unlabel_data = unlabel_data_q\n",
        "\n",
        "        all_label_data = change_classes(all_label_data)\n",
        "        all_unlabel_data = change_classes(all_unlabel_data)\n",
        "\n",
        "        all_unlabel_data = filter_instances(all_unlabel_data)\n",
        "        \n",
        "        record_all_label_data, _, _, _ = self.model(all_label_data, branch='supervised')\n",
        "\n",
        "        record_dict.update(record_all_label_data)\n",
        "\n",
        "        record_all_unlabel_data, _, _, _ = self.model(\n",
        "            all_unlabel_data, branch=\"supervised\"\n",
        "        )\n",
        "        new_record_all_unlabel_data = {}\n",
        "        for key in record_all_unlabel_data.keys():\n",
        "            new_record_all_unlabel_data[key + \"_pseudo\"] = record_all_unlabel_data[\n",
        "                key\n",
        "            ]\n",
        "        record_dict.update(new_record_all_unlabel_data)\n",
        "\n",
        "        # weight losses\n",
        "        loss_dict = {}\n",
        "        for key in record_dict.keys():\n",
        "            if key[:4] == \"loss\":\n",
        "                if key == \"loss_rpn_loc_pseudo\" or key == \"loss_box_reg_pseudo\":\n",
        "                    # pseudo bbox regression <- 0\n",
        "                    loss_dict[key] = record_dict[key] * 0\n",
        "                elif key[-6:] == \"pseudo\":  # unsupervised loss\n",
        "                    loss_dict[key] = (\n",
        "                        record_dict[key] *\n",
        "                        self.cfg.SEMISUPNET.UNSUP_LOSS_WEIGHT\n",
        "                    )\n",
        "                else:  # supervised loss\n",
        "                    loss_dict[key] = record_dict[key] * 1\n",
        "\n",
        "        losses = sum(loss_dict.values())\n",
        "\n",
        "        metrics_dict = record_dict\n",
        "        metrics_dict[\"data_time\"] = data_time\n",
        "        self._write_metrics(metrics_dict)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "\n",
        "        self.optimizer.step()\n",
        "\n",
        "   \n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        mapper = MaxarDatasetMapper(cfg, True)\n",
        "        # return build_detection_semisup_train_loader(cfg, mapper=None)\n",
        "        return build_maxar_loader_semisup_two_crops(cfg, mapper)\n",
        "            \n",
        "\n"
      ],
      "metadata": {
        "id": "CwLAApxT01pl"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(DatasetCatalog)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAs0mUC4cUyL",
        "outputId": "e2b54df3-3392-4a09-f0c6-95e4888acbb9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetCatalog(registered datasets: coco_2014_train, coco_2014_val, coco_2014_minival, coco_2014_minival_100, coco_2014_valminusminival, coco_2017_train, coco_2017_val, coco_2017_test, coco_2017_test-dev, coco_2017_val_100, keypoints_coco_2014_train, keypoints_coco_2014_val, keypoints_coco_2014_minival, keypoints_coco_2014_valminusminival, keypoints_coco_2014_minival_100, keypoints_coco_2017_train, keypoints_coco_2017_val, keypoints_coco_2017_val_100, coco_2017_train_panoptic_separated, coco_2017_train_panoptic_stuffonly, coco_2017_train_panoptic, coco_2017_val_panoptic_separated, coco_2017_val_panoptic_stuffonly, coco_2017_val_panoptic, coco_2017_val_100_panoptic_separated, coco_2017_val_100_panoptic_stuffonly, coco_2017_val_100_panoptic, lvis_v1_train, lvis_v1_val, lvis_v1_test_dev, lvis_v1_test_challenge, lvis_v0.5_train, lvis_v0.5_val, lvis_v0.5_val_rand_100, lvis_v0.5_test, lvis_v0.5_train_cocofied, lvis_v0.5_val_cocofied, cityscapes_fine_instance_seg_train, cityscapes_fine_sem_seg_train, cityscapes_fine_instance_seg_val, cityscapes_fine_sem_seg_val, cityscapes_fine_instance_seg_test, cityscapes_fine_sem_seg_test, cityscapes_fine_panoptic_train, cityscapes_fine_panoptic_val, voc_2007_trainval, voc_2007_train, voc_2007_val, voc_2007_test, voc_2012_trainval, voc_2012_train, voc_2012_val, ade20k_sem_seg_train, ade20k_sem_seg_val, coco_2017_unlabel, coco_2017_for_voc20, fake_maxar_train, fake_maxar_val, maxar_train, maxar_val, manual_maxar_val)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = default_argument_parser().parse_args()\n",
        "args.config_file = 'configs/coco_supervision/faster_rcnn_R_50_FPN_sup2_run1.yaml'\n",
        "cfg = setup(args)\n",
        "cfg.defrost()\n",
        "cfg.SEMISUPNET.Trainer = 'ubteacher'\n",
        "cfg.DATASETS.TEST = 'manual_maxar_val'\n",
        "# cfg.DATASETS.TEST = 'fake_maxar_val'\n",
        "cfg.SOLVER.IMG_PER_BATCH_LABEL = 1\n",
        "cfg.SOLVER.IMG_PER_BATCH_UNLABEL = 1\n",
        "cfg.INPUT.FORMAT = 'RGB'\n",
        "cfg.DATALOADER.ASPECT_RATIO_GROUPING = True\n",
        "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = (256, 512, 640, 672, 704, 736, 768, 800)\n",
        "cfg.SEMISUPNET.BURN_UP_STEP = 0\n",
        "cfg.SOLVER.MAX_ITER = 1\n",
        "cfg.SOLVER.STEPS = [100, 200]\n",
        "cfg.MODEL.META_ARCHITECTURE = 'MaxarPseudoLabGeneralizedRCNN'\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
        "model_path = os.path.join('/content', 'drive', 'MyDrive', 'PyPSA_Africa_images', 'models', \n",
        "                            '2021-11-29_frcnn_180000_dukeset', 'model_final.pth')\n",
        "\n",
        "cfg.MODEL.WEIGHTS = model_path\n",
        "\n",
        "cfg.TEST.INTERVAL = 10\n",
        "cfg.DATASETS.NUM_CLASSES = 1\n",
        "\n",
        "cfg.MODEL.PROPOSAL_GENERATOR.RPN = 'PseudoLabRPN'\n",
        "cfg.MODEL.ROI_HEADS.NAME = 'MaxarROIHeads'\n",
        "cfg.freeze()\n",
        "\n",
        "trainer = MaxarUBTeacher(cfg)\n",
        "trainer.train()\n",
        "\n"
      ],
      "metadata": {
        "id": "SDGmWaZu0yJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c43b9a6-0be1-4ba6-ee99-16916b17cf6c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[02/21 23:18:45 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[02/21 23:18:46 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ----------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.7.12 (default, Jan 15 2022, 18:48:18) [GCC 7.5.0]\n",
            "numpy                   1.21.5\n",
            "detectron2              0.6 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
            "Compiler                GCC 7.3\n",
            "CUDA compiler           CUDA 11.1\n",
            "detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.10.0+cu111 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           Yes\n",
            "GPU 0                   Tesla P100-PCIE-16GB (arch=6.0)\n",
            "Driver version          460.32.03\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.1.2\n",
            "torchvision             0.11.1+cu111 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6\n",
            "fvcore                  0.1.5.post20220212\n",
            "iopath                  0.1.9\n",
            "cv2                     4.1.2\n",
            "----------------------  ----------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.0.5\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
            "\n",
            "\u001b[32m[02/21 23:18:46 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='configs/coco_supervision/faster_rcnn_R_50_FPN_sup2_run1.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)\n",
            "\u001b[32m[02/21 23:18:46 detectron2]: \u001b[0mContents of args.config_file=configs/coco_supervision/faster_rcnn_R_50_FPN_sup2_run1.yaml:\n",
            "\u001b[38;5;197m_BASE_\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186m../Base-RCNN-FPN.yaml\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mTwoStagePseudoLabGeneralizedRCNN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mPseudoLabRPN\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mCrossEntropy\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mStandardROIHeadsPseudoLab\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mFocalLoss\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mWarmupMultiStepLR\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m(179990, 179995)\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m180000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMG_PER_BATCH_LABEL\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMG_PER_BATCH_UNLABEL\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSUP_PERCENT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_DATA_SEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROSS_DATASET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m(\"coco_2017_train\",)\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m(\"coco_2017_val\",)\n",
            "\u001b[38;5;197mSEMISUPNET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTrainer\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m\"\u001b[39m\u001b[38;5;186mubteacher\u001b[39m\u001b[38;5;186m\"\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBBOX_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEACHER_UPDATE_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBURN_UP_STEP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEMA_KEEP_RATE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9996\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mUNSUP_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\n",
            "\u001b[32m[02/21 23:18:46 detectron2]: \u001b[0mRunning with full config:\n",
            "\u001b[38;5;197mCUDNN_BENCHMARK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;197mDATALOADER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mASPECT_RATIO_GROUPING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFILTER_EMPTY_ANNOTATIONS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNUM_WORKERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_DATA_SEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_DATA_SEED_PATH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mdataseed/COCO_supervision.txt\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREPEAT_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSAMPLER_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTrainingSampler\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSUP_PERCENT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;197mDATASETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROSS_DATASET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_FILES_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_val\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN_LABEL\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id001\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39mcoco_2017_train\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTRAIN_UNLABEL\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id001\u001b[39m\n",
            "\u001b[38;5;197mEMAMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSUP_CONSIST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;197mGLOBAL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mHACK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;197mINPUT\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCROP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mrelative_range\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mBGR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_FORMAT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mpolygon\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1333\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m640\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m672\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m704\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m736\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m768\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMIN_SIZE_TRAIN_SAMPLING\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mchoice\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRANDOM_FLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mhorizontal\n",
            "\u001b[38;5;197mMODEL\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mANCHOR_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mANGLES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m-90\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m90\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mASPECT_RATIOS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mDefaultAnchorGenerator\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOFFSET\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBACKBONE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFREEZE_AT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mbuild_resnet_fpn_backbone\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDEVICE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mcuda\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFUSE_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msum\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOAD_PROPOSALS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMASK_ON\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMETA_ARCHITECTURE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mTwoStagePseudoLabGeneralizedRCNN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPANOPTIC_FPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMBINE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mINSTANCES_CONFIDENCE_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mOVERLAP_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m      \u001b[39m\u001b[38;5;197mSTUFF_AREA_LIMIT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4096\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mINSTANCE_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_MEAN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m103.53\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m116.28\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m123.675\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPIXEL_STD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPROPOSAL_GENERATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mPseudoLabRPN\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRESNETS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_MODULATED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_NUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEFORM_ON_PER_STAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mDEPTH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m50\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFrozenBN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_GROUPS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mOUT_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mres5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES2_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mRES5_DILATION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTEM_OUT_CHANNELS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSTRIDE_IN_1X1\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mWIDTH_PER_GROUP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m64\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRETINANET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m&id002\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_ALPHA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFOCAL_LOSS_GAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONVS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRIOR_PROB\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_LOSS_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTOPK_CANDIDATES_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_CASCADE_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m20.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m30.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m      \u001b[39m-\u001b[38;5;15m \u001b[39m15.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOUS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.6\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_BOX_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m10.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m5.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_BBOX_REG\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFC_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1024\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFastRCNNConvFCHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_FC\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mTRAIN_ON_PRED_BOXES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_HEADS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mFocalLoss\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardROIHeadsPseudoLab\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m80\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPROPOSAL_APPEND_GT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSCORE_THRESH_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.05\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_KEYPOINT_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m512\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_KEYPOINTS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mKRCNNConvDeconvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_KEYPOINTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m17\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mROI_MASK_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLS_AGNOSTIC_MASK\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mMaskRCNNConvUpsampleHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;186m'\u001b[39m\u001b[38;5;186m'\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CONV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_RESOLUTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m14\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_SAMPLING_RATIO\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOOLER_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mROIAlignV2\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mRPN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBATCH_SIZE_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m256\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39msmooth_l1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBBOX_REG_WEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15m*id002\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mBOUNDARY_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONV_DIMS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mHEAD_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mStandardRPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp6\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_LABELS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIOU_THRESHOLDS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCrossEntropy\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNMS_THRESH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOSITIVE_FRACTION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.25\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPOST_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TEST\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mPRE_NMS_TOPK_TRAIN\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mSMOOTH_L1_BETA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mUNSUP_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSEM_SEG_HEAD\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCOMMON_STRIDE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCONVS_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIGNORE_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m255\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mIN_FEATURES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp2\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp3\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp4\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39mp5\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mLOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mSemSegFPNHead\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mGN\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_CLASSES\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m54\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mdetectron2://ImageNetPretrained/MSRA/R-50.pkl\n",
            "\u001b[38;5;197mOUTPUT_DIR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m./output\n",
            "\u001b[38;5;197mSEED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m-1\n",
            "\u001b[38;5;197mSEMISUPNET\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBBOX_THRESHOLD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.7\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBURN_UP_STEP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEMA_KEEP_RATE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9996\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLOSS_WEIGHT_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mstandard\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMLP_DIM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m128\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPSEUDO_BBOX_SAMPLE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mthresholding\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSUP_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.5\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTEACHER_UPDATE_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mTrainer\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mubteacher\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mUNSUP_LOSS_WEIGHT\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4.0\n",
            "\u001b[38;5;197mSOLVER\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAMP\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBASE_LR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.01\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mBIAS_LR_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCHECKPOINT_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m5000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mCLIP_GRADIENTS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mvalue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mCLIP_VALUE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1.0\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNORM_TYPE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2.0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mFACTOR_LIST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mGAMMA\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.1\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMG_PER_BATCH_LABEL\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMG_PER_BATCH_UNLABEL\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m32\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mIMS_PER_BATCH\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m16\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mLR_SCHEDULER_NAME\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mWarmupMultiStepLR\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMAX_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m180000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mMOMENTUM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.9\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mNESTEROV\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mREFERENCE_WORLD_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mSTEPS\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m179990\n",
            "\u001b[38;5;15m  \u001b[39m-\u001b[38;5;15m \u001b[39m179995\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_FACTOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_ITERS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWARMUP_METHOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mlinear\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0001\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_BIAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mnull\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mWEIGHT_DECAY_NORM\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0.0\n",
            "\u001b[38;5;197mTEST\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mAUG\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mFLIP\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMAX_SIZE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m4000\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mMIN_SIZES\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m400\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m500\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m600\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m700\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m800\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m900\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1100\n",
            "\u001b[38;5;15m    \u001b[39m-\u001b[38;5;15m \u001b[39m1200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mDETECTIONS_PER_IMAGE\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m100\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVALUATOR\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mCOCOeval\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEVAL_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m1000\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mEXPECTED_RESULTS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mKEYPOINT_OKS_SIGMAS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m[]\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mPRECISE_BN\u001b[39m\u001b[38;5;15m:\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mENABLED\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mfalse\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;197mNUM_ITER\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m200\n",
            "\u001b[38;5;15m  \u001b[39m\u001b[38;5;197mVAL_LOSS\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39mtrue\n",
            "\u001b[38;5;197mVERSION\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m2\n",
            "\u001b[38;5;197mVIS_PERIOD\u001b[39m\u001b[38;5;15m:\u001b[39m\u001b[38;5;15m \u001b[39m0\n",
            "\n",
            "\u001b[32m[02/21 23:18:46 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
            "\u001b[32m[02/21 23:18:46 d2.utils.env]: \u001b[0mUsing a generated random seed 46325392\n",
            "\u001b[32m[02/21 23:18:46 d2.engine.defaults]: \u001b[0mModel:\n",
            "MaxarPseudoLabGeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): PseudoLabRPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): MaxarROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[02/21 23:18:47 d2.engine.defaults]: \u001b[0mModel:\n",
            "MaxarPseudoLabGeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): PseudoLabRPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): MaxarROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/21 23:18:47 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[02/21 23:18:47 d2.data.datasets.coco]: \u001b[0mLoaded 762 images in COCO format from /content/drive/My Drive/PyPSA_Africa_images/datasets/maxar_train/labels.json\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/21 23:18:47 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[02/21 23:18:47 d2.data.datasets.coco]: \u001b[0mLoaded 190 images in COCO format from /content/drive/My Drive/PyPSA_Africa_images/datasets/maxar_val/labels.json\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/21 23:18:48 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[02/21 23:18:48 d2.data.datasets.coco]: \u001b[0mLoaded 11813 images in COCO format from /content/drive/My Drive/PyPSA_Africa_images/datasets/fake_maxar_train/labels.json\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/21 23:18:48 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[02/21 23:18:48 d2.data.datasets.coco]: \u001b[0mLoaded 4502 images in COCO format from /content/drive/My Drive/PyPSA_Africa_images/datasets/fake_maxar_val/labels.json\n",
            "\u001b[32m[02/21 23:18:49 d2.data.common]: \u001b[0mSerializing 16315 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[02/21 23:18:49 d2.data.common]: \u001b[0mSerialized dataset takes 6.29 MiB\n",
            "\u001b[32m[02/21 23:18:49 d2.data.common]: \u001b[0mSerializing 952 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[02/21 23:18:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.29 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/21 23:18:49 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "Building test loader from manual_maxar_val\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/21 23:18:49 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[02/21 23:18:49 d2.data.datasets.coco]: \u001b[0mLoaded 855 images in COCO format from /content/drive/My Drive/PyPSA_Africa_images/datasets/manual_maxar_val/labels.json\n",
            "<class 'list'>\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/21 23:18:49 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[02/21 23:18:49 d2.data.datasets.coco]: \u001b[0mLoaded 855 images in COCO format from /content/drive/My Drive/PyPSA_Africa_images/datasets/manual_maxar_val/labels.json\n",
            "\u001b[32m[02/21 23:18:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[02/21 23:18:49 d2.data.common]: \u001b[0mSerializing 855 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[02/21 23:18:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.22 MiB\n",
            "setup ub teacher complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running test on manual data\n",
            "we have test loader\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7ff108ab92d0>\n",
            "Building predictor from path:\n",
            "None\n",
            "working with path:  /content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth\n",
            "\u001b[32m[02/21 23:18:51 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from /content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth ...\n",
            "standard frcnn cfg\n",
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('coco_2017_val',)\n",
            "  TRAIN: ('coco_2017_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 101\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 2\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.2\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: /content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.02\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 16\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 270000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n",
            "\u001b[32m[02/21 23:18:56 fvcore.common.checkpoint]: \u001b[0m[Checkpointer] Loading from /content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth ...\n",
            "\u001b[32m[02/21 23:18:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 855 batches\n",
            "\u001b[32m[02/21 23:18:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/855. Dataloading: 0.0118 s/iter. Inference: 0.0644 s/iter. Eval: 0.0001 s/iter. Total: 0.0763 s/iter. ETA=0:01:04\n",
            "\u001b[32m[02/21 23:19:02 d2.evaluation.evaluator]: \u001b[0mInference done 76/855. Dataloading: 0.0131 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0776 s/iter. ETA=0:01:00\n",
            "\u001b[32m[02/21 23:19:07 d2.evaluation.evaluator]: \u001b[0mInference done 141/855. Dataloading: 0.0132 s/iter. Inference: 0.0643 s/iter. Eval: 0.0001 s/iter. Total: 0.0778 s/iter. ETA=0:00:55\n",
            "\u001b[32m[02/21 23:19:12 d2.evaluation.evaluator]: \u001b[0mInference done 206/855. Dataloading: 0.0133 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0778 s/iter. ETA=0:00:50\n",
            "\u001b[32m[02/21 23:19:18 d2.evaluation.evaluator]: \u001b[0mInference done 271/855. Dataloading: 0.0133 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0777 s/iter. ETA=0:00:45\n",
            "\u001b[32m[02/21 23:19:23 d2.evaluation.evaluator]: \u001b[0mInference done 336/855. Dataloading: 0.0133 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0777 s/iter. ETA=0:00:40\n",
            "\u001b[32m[02/21 23:19:28 d2.evaluation.evaluator]: \u001b[0mInference done 401/855. Dataloading: 0.0133 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0778 s/iter. ETA=0:00:35\n",
            "\u001b[32m[02/21 23:19:33 d2.evaluation.evaluator]: \u001b[0mInference done 466/855. Dataloading: 0.0133 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0778 s/iter. ETA=0:00:30\n",
            "\u001b[32m[02/21 23:19:38 d2.evaluation.evaluator]: \u001b[0mInference done 531/855. Dataloading: 0.0133 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0778 s/iter. ETA=0:00:25\n",
            "\u001b[32m[02/21 23:19:43 d2.evaluation.evaluator]: \u001b[0mInference done 596/855. Dataloading: 0.0133 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0778 s/iter. ETA=0:00:20\n",
            "\u001b[32m[02/21 23:19:48 d2.evaluation.evaluator]: \u001b[0mInference done 661/855. Dataloading: 0.0133 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0778 s/iter. ETA=0:00:15\n",
            "\u001b[32m[02/21 23:19:53 d2.evaluation.evaluator]: \u001b[0mInference done 724/855. Dataloading: 0.0135 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0780 s/iter. ETA=0:00:10\n",
            "\u001b[32m[02/21 23:19:58 d2.evaluation.evaluator]: \u001b[0mInference done 789/855. Dataloading: 0.0135 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0780 s/iter. ETA=0:00:05\n",
            "\u001b[32m[02/21 23:20:03 d2.evaluation.evaluator]: \u001b[0mInference done 854/855. Dataloading: 0.0135 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0780 s/iter. ETA=0:00:00\n",
            "\u001b[32m[02/21 23:20:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:06.305577 (0.078007 s / iter per device, on 1 devices)\n",
            "\u001b[32m[02/21 23:20:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:54 (0.064299 s / iter per device, on 1 devices)\n",
            "\u001b[32m[02/21 23:20:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[02/21 23:20:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[02/21 23:20:03 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "\u001b[32m[02/21 23:20:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.24 seconds.\n",
            "\u001b[32m[02/21 23:20:03 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[02/21 23:20:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "\u001b[32m[02/21 23:20:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.002 | 0.004  | 0.003  | 0.000 | 0.009 | 0.000 |\n",
            "\u001b[32m[02/21 23:20:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category     | AP    | category     | AP   |\n",
            "|:-------------|:------|:-------------|:-----|\n",
            "| distribution | 0.002 | transmission | nan  |\n",
            "baseline result\n",
            "OrderedDict([('bbox', {'AP': 0.002473194042457199, 'AP50': 0.004387440221126987, 'AP75': 0.0033907500339075, 'APs': 0.0, 'APm': 0.009042968561705243, 'APl': 0.0, 'AP-distribution': 0.002473194042457199, 'AP-transmission': nan})])\n",
            "\u001b[32m[02/21 23:20:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 855 batches\n",
            "\u001b[32m[02/21 23:20:08 d2.evaluation.evaluator]: \u001b[0mInference done 87/855. Dataloading: 0.0129 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0533 s/iter. ETA=0:00:40\n",
            "\u001b[32m[02/21 23:20:13 d2.evaluation.evaluator]: \u001b[0mInference done 181/855. Dataloading: 0.0130 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0534 s/iter. ETA=0:00:35\n",
            "\u001b[32m[02/21 23:20:18 d2.evaluation.evaluator]: \u001b[0mInference done 275/855. Dataloading: 0.0131 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0535 s/iter. ETA=0:00:31\n",
            "\u001b[32m[02/21 23:20:23 d2.evaluation.evaluator]: \u001b[0mInference done 369/855. Dataloading: 0.0132 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0536 s/iter. ETA=0:00:26\n",
            "\u001b[32m[02/21 23:20:28 d2.evaluation.evaluator]: \u001b[0mInference done 463/855. Dataloading: 0.0131 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0535 s/iter. ETA=0:00:20\n",
            "\u001b[32m[02/21 23:20:33 d2.evaluation.evaluator]: \u001b[0mInference done 557/855. Dataloading: 0.0131 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0536 s/iter. ETA=0:00:15\n",
            "\u001b[32m[02/21 23:20:38 d2.evaluation.evaluator]: \u001b[0mInference done 651/855. Dataloading: 0.0131 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0536 s/iter. ETA=0:00:10\n",
            "\u001b[32m[02/21 23:20:43 d2.evaluation.evaluator]: \u001b[0mInference done 745/855. Dataloading: 0.0131 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0536 s/iter. ETA=0:00:05\n",
            "\u001b[32m[02/21 23:20:48 d2.evaluation.evaluator]: \u001b[0mInference done 839/855. Dataloading: 0.0131 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0536 s/iter. ETA=0:00:00\n",
            "\u001b[32m[02/21 23:20:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.555766 (0.053595 s / iter per device, on 1 devices)\n",
            "\u001b[32m[02/21 23:20:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:34 (0.040171 s / iter per device, on 1 devices)\n",
            "\u001b[32m[02/21 23:20:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[02/21 23:20:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[02/21 23:20:49 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "Replaced o[iscrowd] by 0. Fix your dataset!\n",
            "\u001b[32m[02/21 23:20:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.13 seconds.\n",
            "\u001b[32m[02/21 23:20:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[02/21 23:20:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "\u001b[32m[02/21 23:20:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
            "\u001b[32m[02/21 23:20:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category     | AP    | category     | AP   |\n",
            "|:-------------|:------|:-------------|:-----|\n",
            "| distribution | 0.000 | transmission | nan  |\n",
            "\u001b[32m[02/21 23:20:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 855 batches\n",
            "\u001b[32m[02/21 23:20:53 d2.evaluation.evaluator]: \u001b[0mInference done 73/855. Dataloading: 0.0130 s/iter. Inference: 0.0400 s/iter. Eval: 0.0001 s/iter. Total: 0.0532 s/iter. ETA=0:00:41\n",
            "\u001b[32m[02/21 23:20:58 d2.evaluation.evaluator]: \u001b[0mInference done 167/855. Dataloading: 0.0133 s/iter. Inference: 0.0401 s/iter. Eval: 0.0001 s/iter. Total: 0.0535 s/iter. ETA=0:00:36\n",
            "\u001b[32m[02/21 23:21:04 d2.evaluation.evaluator]: \u001b[0mInference done 261/855. Dataloading: 0.0132 s/iter. Inference: 0.0401 s/iter. Eval: 0.0001 s/iter. Total: 0.0535 s/iter. ETA=0:00:31\n",
            "\u001b[32m[02/21 23:21:09 d2.evaluation.evaluator]: \u001b[0mInference done 355/855. Dataloading: 0.0132 s/iter. Inference: 0.0401 s/iter. Eval: 0.0001 s/iter. Total: 0.0535 s/iter. ETA=0:00:26\n",
            "\u001b[32m[02/21 23:21:14 d2.evaluation.evaluator]: \u001b[0mInference done 449/855. Dataloading: 0.0132 s/iter. Inference: 0.0401 s/iter. Eval: 0.0001 s/iter. Total: 0.0534 s/iter. ETA=0:00:21\n",
            "\u001b[32m[02/21 23:21:19 d2.evaluation.evaluator]: \u001b[0mInference done 543/855. Dataloading: 0.0132 s/iter. Inference: 0.0401 s/iter. Eval: 0.0001 s/iter. Total: 0.0534 s/iter. ETA=0:00:16\n",
            "\u001b[32m[02/21 23:21:24 d2.evaluation.evaluator]: \u001b[0mInference done 637/855. Dataloading: 0.0132 s/iter. Inference: 0.0401 s/iter. Eval: 0.0001 s/iter. Total: 0.0535 s/iter. ETA=0:00:11\n",
            "\u001b[32m[02/21 23:21:29 d2.evaluation.evaluator]: \u001b[0mInference done 732/855. Dataloading: 0.0132 s/iter. Inference: 0.0401 s/iter. Eval: 0.0001 s/iter. Total: 0.0534 s/iter. ETA=0:00:06\n",
            "\u001b[32m[02/21 23:21:34 d2.evaluation.evaluator]: \u001b[0mInference done 827/855. Dataloading: 0.0132 s/iter. Inference: 0.0401 s/iter. Eval: 0.0001 s/iter. Total: 0.0534 s/iter. ETA=0:00:01\n",
            "\u001b[32m[02/21 23:21:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.385074 (0.053394 s / iter per device, on 1 devices)\n",
            "\u001b[32m[02/21 23:21:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:34 (0.040095 s / iter per device, on 1 devices)\n",
            "\u001b[32m[02/21 23:21:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[02/21 23:21:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/21 23:21:35 d2.evaluation.coco_evaluation]: \u001b[0mNo predictions from the model!\n",
            "result teacher:\n",
            "OrderedDict([('bbox', {'AP': 0.0, 'AP50': 0.0, 'AP75': 0.0, 'APs': 0.0, 'APm': 0.0, 'APl': 0.0, 'AP-distribution': 0.0, 'AP-transmission': nan})])\n",
            "results student\n",
            "OrderedDict([('bbox', {'AP': nan, 'AP50': nan, 'AP75': nan, 'APs': nan, 'APm': nan, 'APl': nan})])\n",
            "Training has concluded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6TmkqcLeKvZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Our model methods"
      ],
      "metadata": {
        "id": "6fnRT022eY6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UDXNOwyBKvEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import helper\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2.data.build import build_batch_data_loader\n",
        "from detectron2.checkpoint import DetectionCheckpointer\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "def get_true_images(dir, num, show=False):\n",
        "    '''\n",
        "    loads a list of images that all have a tower in them. dir has to be a directory\n",
        "    only containing such images\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dir : str\n",
        "        directory of true examples\n",
        "    num : int\n",
        "        length of list returned\n",
        "    show : bool\n",
        "        if True, some of the examples are shown\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    imgs : list of 3 x height x width np.ndarray\n",
        "        list of obtained images\n",
        "    '''\n",
        "\n",
        "    imgs = os.listdir(dir) \n",
        "    imgs = [os.path.join(dir, img) for img in imgs]\n",
        "    # randomize order\n",
        "    np.random.shuffle(imgs)\n",
        "\n",
        "    imgs = [cv2.imread(img) for img in imgs[:num]]\n",
        "\n",
        "    if show:\n",
        "        print('here are 10 images we have obtained')\n",
        "        for img in imgs[:10]:\n",
        "            _, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
        "            ax.imshow(img)\n",
        "            plt.show()\n",
        "    \n",
        "    return imgs    \n",
        "\n",
        "\n",
        "def build_predictor_model(threshold=0.2, model_path=None):\n",
        "    '''\n",
        "    Returns predictor and model using detectron2 from files stored in the\n",
        "    PyPSA Africa drive\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    threshold : float\n",
        "        detection threshold\n",
        "    model_path : str\n",
        "        path to .pth file\n",
        "\n",
        "    Returns\n",
        "    ---------\n",
        "    predictor : detectron2.DefaultPredictor\n",
        "    model : torch.nn.Module\n",
        "\n",
        "    ''' \n",
        "\n",
        "    print('Building predictor from path:')\n",
        "    print(model_path)\n",
        "\n",
        "    modes = ['train', 'val']\n",
        "   \n",
        "    for mode in modes:\n",
        "        ds_name = 'duke_'+mode\n",
        "        ds_path = f'/content/drive/My Drive/PyPSA_Africa_images/datasets/{ds_name}/data/' \n",
        "        json_path = f'/content/drive/My Drive/PyPSA_Africa_images/datasets/{ds_name}/labels.json'\n",
        "\n",
        "        if ds_name in DatasetCatalog.list():\n",
        "            DatasetCatalog.remove(ds_name)\n",
        "            MetadataCatalog.remove(ds_name)\n",
        "    \n",
        "        register_coco_instances(ds_name, {}, json_path, ds_path)\n",
        "    \n",
        "    for mode in modes:\n",
        "        ds_name = 'fake_maxar_'+mode\n",
        "        ds_path = f'/content/drive/My Drive/PyPSA_Africa_images/datasets/{ds_name}/data/' \n",
        "        json_path = f'/content/drive/My Drive/PyPSA_Africa_images/datasets/{ds_name}/labels.json'\n",
        "\n",
        "        if ds_name in DatasetCatalog.list():\n",
        "            DatasetCatalog.remove(ds_name)\n",
        "            MetadataCatalog.remove(ds_name)\n",
        "    \n",
        "        register_coco_instances(ds_name, {}, json_path, ds_path)\n",
        "\n",
        "    ds_name = 'manual_maxar_val'\n",
        "    ds_path = f'/content/drive/My Drive/PyPSA_Africa_images/datasets/{ds_name}/data/' \n",
        "    json_path = f'/content/drive/My Drive/PyPSA_Africa_images/datasets/{ds_name}/labels.json'\n",
        "\n",
        "    if ds_name in DatasetCatalog.list():\n",
        "        DatasetCatalog.remove(ds_name)\n",
        "        MetadataCatalog.remove(ds_name)\n",
        "\n",
        "    register_coco_instances(ds_name, {}, json_path, ds_path)\n",
        "\n",
        "    frcnn = 'faster_rcnn_R_101_FPN_3x.yaml'\n",
        "    \n",
        "    cfg = get_cfg() # Model Config\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/\"+frcnn))\n",
        "\n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
        "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold\n",
        "    if model_path is None:\n",
        "        model_path = os.path.join('/content', 'drive', 'MyDrive', 'PyPSA_Africa_images', 'models', \n",
        "                                    '2021-11-29_frcnn_180000_dukeset', 'model_final.pth')\n",
        "    \n",
        "    cfg.MODEL.WEIGHTS = model_path\n",
        "\n",
        "    print('working with path: ', model_path)\n",
        "    cfg.INPUT.FORMAT = 'BGR'\n",
        "\n",
        "    predictor = DefaultPredictor(cfg)                                \n",
        "    model = build_model(cfg)\n",
        "\n",
        "    print('standard frcnn cfg')\n",
        "    print(cfg)\n",
        "\n",
        "    checkpointer = DetectionCheckpointer(model)\n",
        "    checkpointer.load(model_path)\n",
        "\n",
        "    # loader = build_batch_data_loader(cfg)\n",
        "\n",
        "    return predictor, model, cfg\n",
        "\n",
        "\n",
        "def eval_predictor(imgs, model_path=None, threshold=0.1):\n",
        "    '''\n",
        "    Method to check performance of model on some imgs (only chekc via plotting, does \n",
        "    not return precision scores)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    imgs : list of np.array \n",
        "        images on which inference will run\n",
        "    model_path : str\n",
        "        path to model .pth file\n",
        "    threshold : float\n",
        "        cutoff for what is considered as an instance\n",
        "    \n",
        "    Returns\n",
        "    ----------\n",
        "    -\n",
        "\n",
        "    '''\n",
        "\n",
        "    print('Evaluating model stored under:')\n",
        "    print(model_path)\n",
        "\n",
        "    predictor, model = build_predictor_model(threshold=threshold, model_path=model_path)\n",
        "    # model.eval()\n",
        "\n",
        "    for img in imgs:\n",
        "\n",
        "        out = predictor(img)\n",
        "        # out = predictor(img[:,:,::-1])\n",
        "        v = Visualizer(img, MetadataCatalog.get('duke'), scale=1.5)\n",
        "        out = v.draw_instance_predictions(out[\"instances\"].to(\"cpu\"))\n",
        "        cv2_imshow(out.get_image())\n",
        "\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            img = predictor.aug.get_transform(img).apply_image(img)\n",
        "            img = torch.as_tensor(img.astype('float32').transpose(2, 0, 1))\n",
        "            x = [{'image': img, 'width': 256, 'height': 256}]\n",
        "            pred = predictor.model(x)\n",
        "            print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "BMrJSXdQRLcM",
        "outputId": "25a3020c-f317-4146-a1e3-7901a214a480"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nif __name__ == '__main__':\\n    \\n    duke_img_dir = '/content/drive/MyDrive/PyPSA_Africa_images/datasets/duke_val/data/'\\n    duke_imgs = get_true_images(duke_img_dir, 20)\\n    \\n    model_path = '/content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth'\\n    model_path_cycle = '/content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth'\\n    \\n    print('The cycle GAN trained model')\\n    eval_predictor(duke_imgs, model_path=model_path_cycle)\\n    \\n    print('The regular trained model')\\n    eval_predictor(duke_imgs, model_path=model_path)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEYRMolPe0o4",
        "outputId": "0ad58e97-baf2-4682-88e1-48e45219bbca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building predictor from path:\n",
            "None\n",
            "working with path:  /content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth\n",
            "standard frcnn cfg\n",
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('coco_2017_val',)\n",
            "  TRAIN: ('coco_2017_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 101\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 2\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.2\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: /content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.02\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 16\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 270000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.evaluation import inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.data import DatasetMapper\n",
        "\n",
        "model_path = '/content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth'\n",
        "model_path_cycle = '/content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth'\n",
        "\n",
        "predictor, model, cfg = build_predictor_model(model_path=model_path_cycle)\n",
        "\n",
        "cfg.defrost()\n",
        "cfg.DATASETS.TEST = ('fake_maxar_val')\n",
        "cfg.freeze()\n",
        "\n",
        "loader = build_detection_test_loader(DatasetCatalog.get(cfg.DATASETS.TEST), \n",
        "                                     mapper=DatasetMapper(cfg, is_train=False)\n",
        "                                    )\n",
        "evaluator = COCOEvaluator(cfg.DATASETS.TEST)\n",
        "results = inference_on_dataset(model, loader, evaluator)\n"
      ],
      "metadata": {
        "id": "lG9N5-0EYngq",
        "outputId": "d8b79ce6-2dc2-49e9-c06c-a16f96cddd58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building predictor from path:\n",
            "/content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth\n",
            "working with path:  /content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth\n",
            "standard frcnn cfg\n",
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('coco_2017_val',)\n",
            "  TRAIN: ('coco_2017_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 101\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 2\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.2\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: /content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.02\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 16\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 270000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.040\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.022\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.027\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.040\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.058\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.evaluation import inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.data import DatasetMapper\n",
        "\n",
        "model_path = '/content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth'\n",
        "model_path_cycle = '/content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth'\n",
        "\n",
        "predictor, model, cfg = build_predictor_model(model_path=model_path)\n",
        "\n",
        "cfg.defrost()\n",
        "cfg.DATASETS.TEST = ('fake_maxar_val')\n",
        "cfg.freeze()\n",
        "\n",
        "loader = build_detection_test_loader(DatasetCatalog.get(cfg.DATASETS.TEST), \n",
        "                                     mapper=DatasetMapper(cfg, is_train=False)\n",
        "                                    )\n",
        "evaluator = COCOEvaluator(cfg.DATASETS.TEST)\n",
        "results = inference_on_dataset(model, loader, evaluator)"
      ],
      "metadata": {
        "id": "4suAHN-qujEp",
        "outputId": "c278dfe6-9693-45d9-a025-7e27b010cf04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building predictor from path:\n",
            "/content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth\n",
            "working with path:  /content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth\n",
            "standard frcnn cfg\n",
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('coco_2017_val',)\n",
            "  TRAIN: ('coco_2017_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 101\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 2\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.2\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: /content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.02\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 16\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 270000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.evaluation import inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.data import DatasetMapper\n",
        "\n",
        "model_path = '/content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth'\n",
        "model_path_cycle = '/content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth'\n",
        "\n",
        "predictor, model, cfg = build_predictor_model(model_path=model_path_cycle)\n",
        "\n",
        "cfg.defrost()\n",
        "cfg.DATASETS.TEST = ('duke_val')\n",
        "cfg.freeze()\n",
        "\n",
        "loader = build_detection_test_loader(DatasetCatalog.get(cfg.DATASETS.TEST), \n",
        "                                     mapper=DatasetMapper(cfg, is_train=False)\n",
        "                                    )\n",
        "evaluator = COCOEvaluator(cfg.DATASETS.TEST)\n",
        "results = inference_on_dataset(model, loader, evaluator)"
      ],
      "metadata": {
        "id": "BjTSvWlRw-Yd",
        "outputId": "6b4935e0-1577-472e-c179-d568369b817f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building predictor from path:\n",
            "/content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth\n",
            "working with path:  /content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth\n",
            "standard frcnn cfg\n",
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('coco_2017_val',)\n",
            "  TRAIN: ('coco_2017_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 101\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 2\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.2\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: /content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.02\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 16\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 270000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.033\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.090\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.019\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.040\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.057\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.070\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.evaluation import inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.data import DatasetMapper\n",
        "\n",
        "model_path = '/content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth'\n",
        "model_path_cycle = '/content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth'\n",
        "\n",
        "predictor, model, cfg = build_predictor_model(model_path=model_path)\n",
        "\n",
        "cfg.defrost()\n",
        "cfg.DATASETS.TEST = ('duke_val')\n",
        "cfg.freeze()\n",
        "\n",
        "loader = build_detection_test_loader(DatasetCatalog.get(cfg.DATASETS.TEST), \n",
        "                                     mapper=DatasetMapper(cfg, is_train=False)\n",
        "                                    )\n",
        "evaluator = COCOEvaluator(cfg.DATASETS.TEST)\n",
        "results = inference_on_dataset(model, loader, evaluator)"
      ],
      "metadata": {
        "id": "a6TJNoj1xGpx",
        "outputId": "5fe3b667-8077-4f12-b524-8401ddb1495d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building predictor from path:\n",
            "/content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth\n",
            "working with path:  /content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth\n",
            "standard frcnn cfg\n",
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('coco_2017_val',)\n",
            "  TRAIN: ('coco_2017_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 101\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 2\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.2\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: /content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.02\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 16\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 270000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.061\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.034\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.093\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.083\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.099\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.evaluation import inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.data import DatasetMapper\n",
        "\n",
        "model_path = '/content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth'\n",
        "model_path_cycle = '/content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth'\n",
        "\n",
        "predictor, model, cfg = build_predictor_model(model_path=None)\n",
        "\n",
        "cfg.defrost()\n",
        "cfg.DATASETS.TEST = ('duke_val')\n",
        "cfg.freeze()\n",
        "\n",
        "loader = build_detection_test_loader(DatasetCatalog.get(cfg.DATASETS.TEST), \n",
        "                                     mapper=DatasetMapper(cfg, is_train=False)\n",
        "                                    )\n",
        "evaluator = COCOEvaluator(cfg.DATASETS.TEST)\n",
        "results = inference_on_dataset(model, loader, evaluator)"
      ],
      "metadata": {
        "id": "3N2rAQpTxKXx",
        "outputId": "eee7fb2f-9f1c-4086-be15-9bd9994aeff1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building predictor from path:\n",
            "None\n",
            "working with path:  /content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth\n",
            "standard frcnn cfg\n",
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('coco_2017_val',)\n",
            "  TRAIN: ('coco_2017_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 101\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 2\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.2\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: /content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.02\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 16\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 270000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preparing results...\n",
            "DONE (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.069\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.032\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.075\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.197\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.093\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.121\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.121\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.130\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.evaluation import inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.data import DatasetMapper\n",
        "\n",
        "model_path = '/content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth'\n",
        "model_path_cycle = '/content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth'\n",
        "\n",
        "predictor, model, cfg = build_predictor_model(model_path=None)\n",
        "\n",
        "cfg.defrost()\n",
        "cfg.DATASETS.TEST = ('fake_maxar_val')\n",
        "cfg.freeze()\n",
        "\n",
        "loader = build_detection_test_loader(DatasetCatalog.get(cfg.DATASETS.TEST), \n",
        "                                     mapper=DatasetMapper(cfg, is_train=False)\n",
        "                                    )\n",
        "evaluator = COCOEvaluator(cfg.DATASETS.TEST)\n",
        "results = inference_on_dataset(model, loader, evaluator)"
      ],
      "metadata": {
        "id": "nncmnHlXyTLp",
        "outputId": "fd68ad50-3f9b-4b83-ab02-39f2b80d372f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building predictor from path:\n",
            "None\n",
            "working with path:  /content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth\n",
            "standard frcnn cfg\n",
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('coco_2017_val',)\n",
            "  TRAIN: ('coco_2017_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 101\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 2\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.2\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: /content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.02\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 16\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 270000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.007\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.007\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.evaluation import inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.data import DatasetMapper\n",
        "\n",
        "model_path = '/content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth'\n",
        "model_path_cycle = '/content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth'\n",
        "\n",
        "predictor, model, cfg = build_predictor_model(model_path=None)\n",
        "\n",
        "cfg.defrost()\n",
        "cfg.DATASETS.TEST = ('manual_maxar_val')\n",
        "cfg.freeze()\n",
        "\n",
        "loader = build_detection_test_loader(DatasetCatalog.get(cfg.DATASETS.TEST), \n",
        "                                     mapper=DatasetMapper(cfg, is_train=False)\n",
        "                                    )\n",
        "evaluator = COCOEvaluator(cfg.DATASETS.TEST)\n",
        "results = inference_on_dataset(model, loader, evaluator)"
      ],
      "metadata": {
        "id": "N48X6tJB2ukd",
        "outputId": "07752ee3-8e69-49ee-9370-7f22c0b65bbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building predictor from path:\n",
            "None\n",
            "working with path:  /content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth\n",
            "standard frcnn cfg\n",
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('coco_2017_val',)\n",
            "  TRAIN: ('coco_2017_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 101\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 2\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.2\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: /content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.02\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 16\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 270000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.004\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.evaluation import inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.data import DatasetMapper\n",
        "\n",
        "model_path = '/content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth'\n",
        "model_path_cycle = '/content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth'\n",
        "\n",
        "predictor, model, cfg = build_predictor_model(model_path=model_path)\n",
        "\n",
        "cfg.defrost()\n",
        "cfg.DATASETS.TEST = ('manual_maxar_val')\n",
        "cfg.freeze()\n",
        "\n",
        "loader = build_detection_test_loader(DatasetCatalog.get(cfg.DATASETS.TEST), \n",
        "                                     mapper=DatasetMapper(cfg, is_train=False)\n",
        "                                    )\n",
        "evaluator = COCOEvaluator(cfg.DATASETS.TEST)\n",
        "results = inference_on_dataset(model, loader, evaluator)"
      ],
      "metadata": {
        "id": "G0cpIsE63PTV",
        "outputId": "2cfa5138-9baf-4ab1-9edb-ea0efdda3da5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building predictor from path:\n",
            "/content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth\n",
            "working with path:  /content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth\n",
            "standard frcnn cfg\n",
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('coco_2017_val',)\n",
            "  TRAIN: ('coco_2017_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 101\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 2\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.2\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: /content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.02\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 16\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 270000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.evaluation import inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.data import DatasetMapper\n",
        "\n",
        "model_path = '/content/drive/MyDrive/PyPSA_Africa_images/notebooks/pypsa-africa/PISA_models_duke/model_final.pth'\n",
        "model_path_cycle = '/content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth'\n",
        "\n",
        "predictor, model, cfg = build_predictor_model(model_path=model_path_cycle)\n",
        "\n",
        "cfg.defrost()\n",
        "cfg.DATASETS.TEST = ('manual_maxar_val')\n",
        "cfg.freeze()\n",
        "\n",
        "loader = build_detection_test_loader(DatasetCatalog.get(cfg.DATASETS.TEST), \n",
        "                                     mapper=DatasetMapper(cfg, is_train=False)\n",
        "                                    )\n",
        "evaluator = COCOEvaluator(cfg.DATASETS.TEST)\n",
        "results = inference_on_dataset(model, loader, evaluator)\n"
      ],
      "metadata": {
        "id": "4Zub8ETb3TPc",
        "outputId": "db9eb241-7cfe-466f-b6e8-e158204fa9f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building predictor from path:\n",
            "/content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth\n",
            "working with path:  /content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth\n",
            "standard frcnn cfg\n",
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('coco_2017_val',)\n",
            "  TRAIN: ('coco_2017_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: False\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 101\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 2\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.2\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: /content/drive/MyDrive/PyPSA_Africa_images/PISA_models/11_01_2022_fake_maxar_train/model_final.pth\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.02\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 16\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 270000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.103\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.009\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.011\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = frcnn_cfg\n",
        "cfg.defrost()\n",
        "cfg.DATASETS.TEST = ('fake_maxar_val')\n",
        "cfg.freeze()\n",
        "\n",
        "loader = build_detection_test_loader(DatasetCatalog.get(cfg.DATASETS.TEST), \n",
        "                                     mapper=DatasetMapper(cfg, is_train=False)\n",
        "                                    )\n",
        "\n",
        "evaluator = COCOEvaluator(cfg.DATASETS.TEST)\n",
        "results = inference_on_dataset(model, loader, evaluator)"
      ],
      "metadata": {
        "id": "Hvstzscslt7K",
        "outputId": "0db6b089-a7c0-44c0-90bc-0db6649800b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d57fab36aff9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCOEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/evaluation/evaluator.py\u001b[0m in \u001b[0;36minference_on_dataset\u001b[0;34m(model, data_loader, evaluator)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mstart_data_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0mtotal_data_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_data_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_warmup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/data/common.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fallback_candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/utils/serialize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/data/dataset_mapper.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, dataset_dict)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mdataset_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dict\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# it will be modified by code below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# USER: Write your own image loading if it's not from a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_image_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/data/detection_utils.py\u001b[0m in \u001b[0;36mread_image\u001b[0;34m(file_name, format)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \"\"\"\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPathManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# work around this bug: https://github.com/python-pillow/Pillow/issues/3973\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2850\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2852\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lq, lk, uq, uk = next(loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "1yyJXv-vgsmS",
        "outputId": "a6602731-7d28-4171-84eb-88f86c7edaad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-0055b4c1f0a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uk = trainer.remove_label(uk)"
      ],
      "metadata": {
        "id": "9FcrI2DXilrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# _, prop_rpn, prop_roih, _ = teacher(uk, branch='unsup_data_weak')"
      ],
      "metadata": {
        "id": "dOGLUEElePR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import detectron2\n",
        "\n",
        "with torch.no_grad():\n",
        "    out = uk\n",
        "\n",
        "    current = model \n",
        "    print(type(current))\n",
        "    model.eval()\n",
        "\n",
        "    images = current.preprocess_image(out)\n",
        "\n",
        "    if \"instances\" in uk[0]:\n",
        "        gt_instances = [x[\"instances\"].to(teacher.device) for x in uk]\n",
        "    else:\n",
        "        gt_instances = None\n",
        "\n",
        "    features = current.backbone(images.tensor)\n",
        "\n",
        "    branch = 'unsup_data_weak'\n",
        "\n",
        "    print(help(current.proposal_generator.forward))\n",
        "\n",
        "    if branch == 'unsup_data_weak':\n",
        "\n",
        "        # not using isistance as on type inherits the other\n",
        "        if type(current) == detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN:\n",
        "            print('detected d2.GeneralizedRCNN')\n",
        "            prop_rpn, _ = current.proposal_generator(images, features, None)\n",
        "            prop_roih, ROI_PRED = current.roi_heads(\n",
        "                images,\n",
        "                features,\n",
        "                prop_rpn,\n",
        "            )\n",
        "\n",
        "        elif type(current) == MaxarPseudoLabGeneralizedRCNN:  \n",
        "            print('detected MaxarGeneralizedRCNN')\n",
        "            prop_rpn, _ = current.proposal_generator(images, features, None, compute_loss=False)\n",
        "            prop_roih, ROI_PRED = current.roi_heads(\n",
        "                images,\n",
        "                features,\n",
        "                prop_rpn,\n",
        "                targets=None,\n",
        "                compute_loss=False,\n",
        "                branch=branch\n",
        "            )\n",
        "        else:\n",
        "            assert False, 'Unrecognized network type!'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # pprint.pprint(features)\n",
        "    print('results')\n",
        "    pprint.pprint(prop_roih[0])\n",
        "    print(type(prop_roih))\n",
        "    \n",
        " \n"
      ],
      "metadata": {
        "id": "qQEmKmyle7bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(student)"
      ],
      "metadata": {
        "id": "KDiRThzWfYCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqMlRJzXfZcO",
        "outputId": "4521b6e7-ad8c-4d05-f345-6b90667ce739"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (0.2.25)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax) (3.10.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from jax) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod = 'roi_heads'\n",
        "print(type(getattr(teacher, mod)))\n",
        "print(type(getattr(model, mod)))\n",
        "print(cfg.MODEL.WEIGHTS)\n",
        "print(frcnn_cfg.MODEL.WEIGHTS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY-WVClD5asD",
        "outputId": "e362eac9-f8f1-4804-f9e1-f7df0cb2d2d5"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'ubteacher.modeling.roi_heads.roi_heads.StandardROIHeadsPseudoLab'>\n",
            "<class 'detectron2.modeling.roi_heads.roi_heads.StandardROIHeads'>\n",
            "detectron2://ImageNetPretrained/MSRA/R-50.pkl\n",
            "/content/drive/MyDrive/PyPSA_Africa_images/models/2021-11-29_frcnn_180000_dukeset/model_final.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frcnn = 'faster_rcnn_R_101_FPN_3x.yaml'\n",
        "\n",
        "test_cfg = get_cfg() # Model Config\n",
        "test_cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/\"+frcnn))\n",
        "\n",
        "test_cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
        "model_path = os.path.join('/content', 'drive', 'MyDrive', 'PyPSA_Africa_images', 'models', \n",
        "                            '2021-11-29_frcnn_180000_dukeset', 'model_final.pth')\n",
        "\n",
        "test_cfg.MODEL.WEIGHTS = model_path\n",
        "\n",
        "test_cfg.MODEL.META_ARCHITECTURE = 'MaxarPseudoLabGeneralizedRCNN'\n",
        "test_cfg.MODEL.PROPOSAL_GENERATOR.RPN = 'PseudoLabRPN'\n",
        "test_cfg.MODEL.ROI_HEADS.NAME = 'MaxarROIHeads'\n",
        "\n",
        "test_model = build_model(test_cfg)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IMaBxW3B9U8h"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = build_detection_test_loader(cfg, 'manual')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "KnBRSw4d-a6i",
        "outputId": "a79121ce-40f5-42ef-c688-35074c4bc4c9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-80f5d1a673ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_detection_test_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/config/config.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_called_with_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                     \u001b[0mexplicit_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_args_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0morig_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mexplicit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/config/config.py\u001b[0m in \u001b[0;36m_get_args_from_config\u001b[0;34m(from_config_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msupported_arg_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0mextra_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_config_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;31m# forward the other arguments to __init__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: _test_loader_from_config() missing 1 required positional argument: 'dataset_name'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0NZq_Ll8Kg8d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}