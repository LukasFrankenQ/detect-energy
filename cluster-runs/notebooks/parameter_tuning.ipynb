{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parameter_tuning.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtV2NphAJN_9",
        "outputId": "1bbe0e0a-26a0-4c6d-ac1c-5e2466023ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml==5.1\n",
        "#!pip uninstall torch\n",
        "!pip uninstall detectron2\n",
        "!pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html"
      ],
      "metadata": {
        "id": "uSfIMEGbJaue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install attrdict"
      ],
      "metadata": {
        "id": "Fo598FsSJ8ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup paths"
      ],
      "metadata": {
        "id": "m_xPTTh9L50c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/PyPSA_Africa_images/detect-energy')\n",
        "from dotenv import find_dotenv, load_dotenv\n",
        "load_dotenv(find_dotenv())\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path.append(os.environ.get('PROJECT_ROOT'))\n",
        "data_path = os.environ.get('PROJECT_DATASETS')"
      ],
      "metadata": {
        "id": "Ejzx2lA-KANP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register datasets"
      ],
      "metadata": {
        "id": "lCkg0JlXL4nc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "from detectron2.data import DatasetCatalog\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.data.datasets import register_coco_instances \n",
        "from dotenv import find_dotenv, load_dotenv\n",
        "\n",
        "load_dotenv(find_dotenv())\n",
        "DATASETS_PATH = os.environ.get('PROJECT_DATASETS')\n",
        "\n",
        "def register_all():\n",
        "    # register used datasets\n",
        "    ds_names = ['fake_maxar', 'duke', 'duke_512']\n",
        "    modes = ['train', 'val']\n",
        "\n",
        "    for name, mode in product(ds_names, modes):\n",
        "\n",
        "        ds_name = f'{name}_{mode}'\n",
        "        json_path = os.path.join(DATASETS_PATH, f'{ds_name}/labels.json')\n",
        "        ds_path = os.path.join(DATASETS_PATH, f'{ds_name}/data/')\n",
        "\n",
        "        if ds_name in DatasetCatalog.list():\n",
        "            DatasetCatalog.remove(ds_name)\n",
        "            MetadataCatalog.remove(ds_name)\n",
        "\n",
        "        register_coco_instances(ds_name, {}, json_path, ds_path)\n",
        "\n",
        "    ds_name = 'manual_maxar_val'\n",
        "    json_path = os.path.join(DATASETS_PATH, f'{ds_name}/labels.json')\n",
        "    ds_path = os.path.join(DATASETS_PATH, f'{ds_name}/data/')\n",
        "\n",
        "    if ds_name in DatasetCatalog.list():\n",
        "        DatasetCatalog.remove(ds_name)\n",
        "        MetadataCatalog.remove(ds_name)\n",
        "\n",
        "    register_coco_instances(ds_name, {}, json_path, ds_path)\n",
        "\n",
        "register_all()"
      ],
      "metadata": {
        "id": "FwvDJdbhKgu0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Trainer"
      ],
      "metadata": {
        "id": "_CaYES6RuDDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader, DatasetMapper\n",
        "\n",
        "\n",
        "class EvalTrainer(DefaultTrainer):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__(cfg)\n",
        "\n",
        "        if isinstance(cfg.DATASETS.EVAL, str):\n",
        "            self.eval_datasets = [cfg.DATASETS.EVAL]\n",
        "        else:\n",
        "            self.eval_datasets = cfg.DATASETS.EVAL\n",
        "\n",
        "        # prepare evaluation\n",
        "        self.eval_loaders = []\n",
        "        self.evaluators = []\n",
        "        for dataset in self.eval_datasets:\n",
        "\n",
        "            loader = build_detection_test_loader(DatasetCatalog.get(dataset), \n",
        "                                                 mapper=DatasetMapper(cfg, is_train=False))\n",
        "\n",
        "            self.eval_loaders.append(loader)\n",
        "            self.evaluators.append(COCOEvaluator(dataset))\n",
        "\n",
        "\n",
        "    def after_step(self):\n",
        "        super().after_step()\n",
        "\n",
        "        if (self.iter+1) % self.cfg.TEST.INTERVAL == 0:                                   \n",
        "\n",
        "            for dataset, loader, evaluator in zip(self.DATASETS.EVAL, \n",
        "                                                  self.eval_loaders,\n",
        "                                                  self.evaluators):\n",
        "\n",
        "                results = inference_on_dataset(self.model,\n",
        "                                              loader,\n",
        "                                              evaluator)\n",
        "                with open(\n",
        "                    os.path.join(\n",
        "                        self.cfg.OUTPUT_DIR,\n",
        "                        'eval_'+dataset+'_iter_'+str(self.iter)+'.json'),\n",
        "                        'w') as out:\n",
        "                    json.dump(results, out)"
      ],
      "metadata": {
        "id": "oziPtPuaRnXr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to test parameters"
      ],
      "metadata": {
        "id": "i8RBAmVNuFeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from attrdict import AttrDict\n",
        "\n",
        "\n",
        "def run_parameters(params):\n",
        "    print(f'Starting run for parameters: {params}')\n",
        "    params = AttrDict(params)\n",
        "\n",
        "    cfg = get_cfg()\n",
        "\n",
        "    # From Detectron2 Model Zoo\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/\" + params.model_type))\n",
        "\n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "\n",
        "    cfg.DATASETS.TRAIN = ('duke_512_train')\n",
        "    cfg.DATASETS.TRAIN = ('manual_maxar_val')\n",
        "    cfg.DATASETS.EVAL = ['manual_maxar_val', 'duke_512_val', 'duke_512_train']\n",
        "\n",
        "    cfg.TEST.INTERVAL = 5_000\n",
        "    cfg.SOLVER.MAX_ITER = 100_000\n",
        "    cfg.SOLVER.STEPS = (70_000, 85_000)\n",
        "\n",
        "    # setup current parameters\n",
        "    cfg.SOLVER.IMS_PER_BATCH = params['SOLVER.IMS_PER_BATCH']\n",
        "    cfg.SOLVER.BASE_LR = params['SOLVER.BASE_LR']\n",
        "    cfg.SOLVER.MOMENTUM = params['SOLVER.MOMENTUM']\n",
        "    cfg.SOLVER.WEIGHT_DECAY = params['SOLVER.WEIGHT_DECAY']\n",
        "\n",
        "    model_name = f\"LR_{cfg.SOLVER.BASE_LR}_ \\\n",
        "                   IMSPERBATCH_{cfg.SOLVER.IMS_PER_BATCH} \\\n",
        "                   MOM_{cfg.SOLVER.MOMENTUM} \\\n",
        "                   WEIGHTDECAY_{cfg.SOLVER.WEIGHT_DECAY}\"\n",
        "    cfg.OUTPUT_DIR = '/content/drive/MyDrive/PyPSA_Africa_images/models/' + model_name\n",
        "\n",
        "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "    trainer = EvalTrainer(cfg) \n",
        "    trainer.resume_or_load(resume=False)\n",
        "\n",
        "    trainer.train()"
      ],
      "metadata": {
        "id": "Tk9ZvpWBQrmL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define parameter grid and run"
      ],
      "metadata": {
        "id": "SNUZ3ZApuN9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "parameters = {\n",
        "    'model_type': ['faster_rcnn_R_50_FPN_3x.yaml', 'faster_rcnn_R_101_FPN_3x.yaml'],\n",
        "    'SOLVER.BASE_LR': [1e-4, 1e-3, 1e-2],\n",
        "    'SOLVER.MOMENTUM': [0.9],           # default\n",
        "    'SOLVER.IMS_PER_BATCH': [16],       # default\n",
        "    'SOLVER.WEIGHT_DECAY': [0.0001],    # default\n",
        "    }\n",
        "\n",
        "parameter_sweep = list(ParameterGrid(parameters))\n",
        "\n",
        "for params in parameter_sweep:\n",
        "    run_parameters(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4-ut3x3iKEC",
        "outputId": "4f15d7d9-a631-4dff-96ab-85a530a906da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting run for parameters: {'SOLVER.BASE_LR': 0.0001, 'SOLVER.IMS_PER_BATCH': 16, 'SOLVER.MOMENTUM': 0.9, 'SOLVER.WEIGHT_DECAY': 0.0001, 'model_type': 'faster_rcnn_R_50_FPN_3x.yaml'}\n",
            "\u001b[32m[03/19 15:14:34 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 15:14:34 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[03/19 15:14:34 d2.data.datasets.coco]: \u001b[0mLoaded 855 images in COCO format from /content/drive/MyDrive/PyPSA_Africa_images/datasets/manual_maxar_val/labels.json\n",
            "\u001b[32m[03/19 15:14:34 d2.data.build]: \u001b[0mRemoved 254 images with no usable annotations. 601 images left.\n",
            "\u001b[32m[03/19 15:14:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[03/19 15:14:34 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[03/19 15:14:34 d2.data.common]: \u001b[0mSerializing 601 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/19 15:14:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.19 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 15:14:34 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[03/19 15:14:34 d2.data.datasets.coco]: \u001b[0mLoaded 855 images in COCO format from /content/drive/MyDrive/PyPSA_Africa_images/datasets/manual_maxar_val/labels.json\n",
            "\u001b[32m[03/19 15:14:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[03/19 15:14:34 d2.data.common]: \u001b[0mSerializing 855 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/19 15:14:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.23 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 15:14:35 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[03/19 15:14:35 d2.data.datasets.coco]: \u001b[0mLoaded 2414 images in COCO format from /content/drive/MyDrive/PyPSA_Africa_images/datasets/duke_512_val/labels.json\n",
            "\u001b[32m[03/19 15:14:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[03/19 15:14:35 d2.data.common]: \u001b[0mSerializing 2414 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/19 15:14:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.09 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 15:14:35 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[03/19 15:14:35 d2.data.datasets.coco]: \u001b[0mLoaded 6133 images in COCO format from /content/drive/MyDrive/PyPSA_Africa_images/datasets/duke_512_train/labels.json\n",
            "\u001b[32m[03/19 15:14:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[03/19 15:14:35 d2.data.common]: \u001b[0mSerializing 6133 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[03/19 15:14:35 d2.data.common]: \u001b[0mSerialized dataset takes 2.67 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "R-50.pkl: 102MB [00:03, 32.5MB/s]                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[03/19 15:14:39 d2.checkpoint.c2_model_loading]: \u001b[0mRenaming Caffe2 weights ......\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[03/19 15:14:39 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with submodule backbone.bottom_up:\n",
            "| Names in Model    | Names in Checkpoint      | Shapes                                          |\n",
            "|:------------------|:-------------------------|:------------------------------------------------|\n",
            "| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
            "| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
            "| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
            "| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
            "| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
            "| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
            "| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
            "| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
            "| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
            "| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
            "| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
            "| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |\n",
            "| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some model parameters or buffers are not found in the checkpoint:\n",
            "\u001b[34mbackbone.fpn_lateral2.{bias, weight}\u001b[0m\n",
            "\u001b[34mbackbone.fpn_lateral3.{bias, weight}\u001b[0m\n",
            "\u001b[34mbackbone.fpn_lateral4.{bias, weight}\u001b[0m\n",
            "\u001b[34mbackbone.fpn_lateral5.{bias, weight}\u001b[0m\n",
            "\u001b[34mbackbone.fpn_output2.{bias, weight}\u001b[0m\n",
            "\u001b[34mbackbone.fpn_output3.{bias, weight}\u001b[0m\n",
            "\u001b[34mbackbone.fpn_output4.{bias, weight}\u001b[0m\n",
            "\u001b[34mbackbone.fpn_output5.{bias, weight}\u001b[0m\n",
            "\u001b[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}\u001b[0m\n",
            "\u001b[34mproposal_generator.rpn_head.conv.{bias, weight}\u001b[0m\n",
            "\u001b[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_head.fc1.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_head.fc2.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
            "The checkpoint state_dict contains keys that are not used by the model:\n",
            "  \u001b[35mfc1000.{bias, weight}\u001b[0m\n",
            "  \u001b[35mstem.conv1.bias\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[03/19 15:14:39 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[03/19 15:15:26 d2.utils.events]: \u001b[0m eta: 2 days, 14:51:15  iter: 19  total_loss: 1.554  loss_cls: 0.8526  loss_box_reg: 0.005869  loss_rpn_cls: 0.6823  loss_rpn_loc: 0.01072  time: 2.2973  data_time: 0.9024  lr: 1.9981e-06  max_mem: 11286M\n",
            "\u001b[32m[03/19 15:16:08 d2.utils.events]: \u001b[0m eta: 2 days, 13:43:58  iter: 39  total_loss: 1.265  loss_cls: 0.5603  loss_box_reg: 0.004868  loss_rpn_cls: 0.6798  loss_rpn_loc: 0.01094  time: 2.2171  data_time: 0.7132  lr: 3.9961e-06  max_mem: 11286M\n",
            "\u001b[32m[03/19 15:16:39 d2.utils.events]: \u001b[0m eta: 2 days, 11:12:57  iter: 59  total_loss: 0.9619  loss_cls: 0.2711  loss_box_reg: 0.004275  loss_rpn_cls: 0.6748  loss_rpn_loc: 0.01147  time: 1.9760  data_time: 0.0810  lr: 5.9941e-06  max_mem: 11286M\n",
            "\u001b[32m[03/19 15:17:09 d2.utils.events]: \u001b[0m eta: 1 day, 18:43:32  iter: 79  total_loss: 0.8175  loss_cls: 0.1355  loss_box_reg: 0.00479  loss_rpn_cls: 0.6657  loss_rpn_loc: 0.01078  time: 1.8603  data_time: 0.0776  lr: 7.9921e-06  max_mem: 11286M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uMDekQuvueiS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}